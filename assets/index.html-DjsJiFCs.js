import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,a as r,o as a}from"./app-W6ac-OwH.js";const i={};function n(s,e){return a(),t("div",null,[...e[0]||(e[0]=[r('<h1 id="zab-协议" tabindex="-1"><a class="header-anchor" href="#zab-协议"><span>ZAB 协议</span></a></h1><blockquote><p>ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。<strong><em>ZAB 协议不是 Paxos 算法</em></strong>，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。</p><p>ZAB 协议是 Zookeeper 专门设计的一种<strong>支持故障恢复的原子广播协议</strong>。</p><p>ZAB 协议是 ZooKeeper 的数据一致性和高可用解决方案。</p></blockquote><p>ZAB 协议定义了两个可以<strong>无限循环</strong>的流程：</p><ul><li><strong><code>选举 Leader</code></strong> - 用于故障恢复，从而保证高可用。</li><li><strong><code>原子广播</code></strong> - 用于主从同步，从而保证数据一致性。</li></ul><h2 id="选举-leader" tabindex="-1"><a class="header-anchor" href="#选举-leader"><span>选举 Leader</span></a></h2><h3 id="故障恢复" tabindex="-1"><a class="header-anchor" href="#故障恢复"><span>故障恢复</span></a></h3><p>ZooKeeper 集群采用一主（称为 Leader）多从（称为 Follower）模式，主从节点通过副本机制保证数据一致。</p><ul><li><strong>如果 Follower 节点挂了</strong> - ZooKeeper 集群中的每个节点都会单独在内存中维护自身的状态，并且各节点之间都保持着通讯，<strong>只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务</strong>。</li><li><strong>如果 Leader 节点挂了</strong> - 如果 Leader 节点挂了，系统就不能正常工作了。此时，需要通过 ZAB 协议的选举 Leader 机制来进行故障恢复。</li></ul><p>ZAB 协议的选举 Leader 机制简单来说，就是：基于过半选举机制产生新的 Leader，之后其他机器将从新的 Leader 上同步状态，当有过半机器完成状态同步后，就退出选举 Leader 模式，进入原子广播模式。</p><h3 id="术语" tabindex="-1"><a class="header-anchor" href="#术语"><span>术语</span></a></h3><ul><li><strong>myid</strong> - 每个 Zookeeper 服务器，都需要在数据文件夹下创建一个名为 myid 的文件，该文件包含整个 Zookeeper 集群唯一的 ID（整数）。</li><li><strong>zxid</strong> - 类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal ID。为了保证顺序性，该 zxid 必须单调递增。因此 Zookeeper 使用一个 64 位的数来表示，高 32 位是 Leader 的 epoch，从 1 开始，每次选出新的 Leader，epoch 加一。低 32 位为该 epoch 内的序号，每次 epoch 变化，都将低 32 位的序号重置。这样保证了 zxid 的全局递增性。</li></ul><h3 id="服务器状态" tabindex="-1"><a class="header-anchor" href="#服务器状态"><span>服务器状态</span></a></h3><ul><li><strong><em>LOOKING</em></strong> - 不确定 Leader 状态。该状态下的服务器认为当前集群中没有 Leader，会发起 Leader 选举</li><li><strong><em>FOLLOWING</em></strong> - 跟随者状态。表明当前服务器角色是 Follower，并且它知道 Leader 是谁</li><li><strong><em>LEADING</em></strong> - 领导者状态。表明当前服务器角色是 Leader，它会维护与 Follower 间的心跳</li><li><strong><em>OBSERVING</em></strong> - 观察者状态。表明当前服务器角色是 Observer，与 Folower 唯一的不同在于不参与选举，也不参与集群写操作时的投票</li></ul><h3 id="选票数据结构" tabindex="-1"><a class="header-anchor" href="#选票数据结构"><span>选票数据结构</span></a></h3><p>每个服务器在进行领导选举时，会发送如下关键信息</p><ul><li><strong><em>logicClock</em></strong> - 每个服务器会维护一个自增的整数，名为 logicClock，它表示这是该服务器发起的第多少轮投票</li><li><strong><em>state</em></strong> - 当前服务器的状态</li><li><strong><em>self_id</em></strong> - 当前服务器的 myid</li><li><strong><em>self_zxid</em></strong> - 当前服务器上所保存的数据的最大 zxid</li><li><strong><em>vote_id</em></strong> - 被推举的服务器的 myid</li><li><strong><em>vote_zxid</em></strong> - 被推举的服务器上所保存的数据的最大 zxid</li></ul><h3 id="投票流程" tabindex="-1"><a class="header-anchor" href="#投票流程"><span>投票流程</span></a></h3><p>（1）<strong>自增选举轮次</strong> - Zookeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作。</p><p>（2）<strong>初始化选票</strong> - 每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器 2 投票给服务器 3，服务器 3 投票给服务器 1，则服务器 1 的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。</p><p>（3）<strong>发送初始化选票</strong> - 每个服务器最开始都是通过广播把票投给自己。</p><p>（4）<strong>接收外部投票</strong> - 服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。</p><p>（5）<strong>判断选举轮次</strong> - 收到外部投票后，首先会根据投票信息中所包含的 logicClock 来进行不同处理</p><ul><li>外部投票的 logicClock 大于自己的 logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的 logicClock 更新为收到的 logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。</li><li>外部投票的 logicClock 小于自己的 logicClock。当前服务器直接忽略该投票，继续处理下一个投票。</li><li>外部投票的 logickClock 与自己的相等。当时进行选票 PK。</li></ul><p>（6）<strong>选票 PK</strong> - 选票 PK 是基于<code>(self_id, self_zxid)</code> 与 <code>(vote_id, vote_zxid)</code> 的对比</p><ul><li>外部投票的 logicClock 大于自己的 logicClock，则将自己的 logicClock 及自己的选票的 logicClock 变更为收到的 logicClock</li><li>若 logicClock 一致，则对比二者的 vote_zxid，若外部投票的 vote_zxid 比较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖</li><li>若二者 vote_zxid 一致，则比较二者的 vote_myid，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱</li></ul><p>（7）<strong>统计选票</strong> - 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。</p><p>（8）<strong>更新服务器状态</strong> - 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 LEADING，否则将自己的状态更新为 FOLLOWING</p><p>通过以上流程分析，我们不难看出：要使 Leader 获得多数 Server 的支持，则 <strong>ZooKeeper 集群节点数必须是奇数。且存活的节点数目不得少于 <code>N + 1</code></strong> 。</p><p>每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。</p><h2 id="原子广播-atomic-broadcast" tabindex="-1"><a class="header-anchor" href="#原子广播-atomic-broadcast"><span>原子广播（Atomic Broadcast）</span></a></h2><p><strong>ZooKeeper 通过副本机制来实现高可用</strong>。</p><p>那么，ZooKeeper 是如何实现副本机制的呢？答案是：ZAB 协议的原子广播。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_3.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>ZAB 协议的原子广播要求：</p><p><strong><em>所有的写请求都会被转发给 Leader，Leader 会以原子广播的方式通知 Follow。当半数以上的 Follow 已经更新状态持久化后，Leader 才会提交这个更新，然后客户端才会收到一个更新成功的响应</em></strong>。这有些类似数据库中的两阶段提交协议。</p><p>在整个消息的广播过程中，Leader 服务器会每个事务请求生成对应的 Proposal，并为其分配一个全局唯一的递增的事务 ID(ZXID)，之后再对其进行广播。</p><blockquote><p>ZAB 是通过“一切以领导者为准”的强领导者模型和严格按照顺序提交日志，来实现操作的顺序性的，这一点和 Raft 是一样的。</p></blockquote><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><ul><li><a href="https://diyhpl.us/~bryan/papers2/distributed/distributed-systems/zab.totally-ordered-broadcast-protocol.2008.pdf" target="_blank" rel="noopener noreferrer"><strong>A Simple Totally Ordered Broadcast Protocol</strong></a> - 概述 ZooKeeper 的全序广播协议（Zab）</li><li><a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Zookeeper%E7%AE%80%E4%BB%8B%E5%8F%8A%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5.md" target="_blank" rel="noopener noreferrer">ZooKeeper 简介及核心概念</a></li><li><a href="https://draveness.me/zookeeper-chubby" target="_blank" rel="noopener noreferrer">详解分布式协调服务 ZooKeeper</a></li><li><a href="https://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper" target="_blank" rel="noopener noreferrer">Introduction to Apache ZooKeeper</a></li></ul>',39)])])}const d=o(i,[["render",n]]),c=JSON.parse('{"path":"/pages/6f4382d3/","title":"ZAB 协议","lang":"zh-CN","frontmatter":{"title":"ZAB 协议","date":"2024-04-28T16:41:07.000Z","categories":["分布式","分布式理论"],"tags":["分布式","算法","共识","ZAB"],"permalink":"/pages/6f4382d3/","description":"ZAB 协议 ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。ZAB 协议不是 Paxos 算法，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。 ZAB 协议是 Zookeepe...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ZAB 协议\\",\\"image\\":[\\"https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_3.png\\"],\\"datePublished\\":\\"2024-04-28T16:41:07.000Z\\",\\"dateModified\\":\\"2025-09-15T00:29:21.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"钝悟\\",\\"url\\":\\"https://dunwu.github.io/waterdrop\\"}]}"],["meta",{"property":"og:url","content":"https://dunwu.github.io/waterdrop/waterdrop/pages/6f4382d3/"}],["meta",{"property":"og:site_name","content":"钝悟"}],["meta",{"property":"og:title","content":"ZAB 协议"}],["meta",{"property":"og:description","content":"ZAB 协议 ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。ZAB 协议不是 Paxos 算法，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。 ZAB 协议是 Zookeepe..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_3.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-09-15T00:29:21.000Z"}],["meta",{"property":"article:tag","content":"ZAB"}],["meta",{"property":"article:tag","content":"共识"}],["meta",{"property":"article:tag","content":"算法"}],["meta",{"property":"article:tag","content":"分布式"}],["meta",{"property":"article:published_time","content":"2024-04-28T16:41:07.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-15T00:29:21.000Z"}]]},"git":{"createdTime":1714315873000,"updatedTime":1757896161000,"contributors":[{"name":"dunwu","username":"dunwu","email":"forbreak@163.com","commits":7,"url":"https://github.com/dunwu"}]},"readingTime":{"minutes":7.26,"words":2179},"filePathRelative":"15.分布式/分布式理论/Zab.md","excerpt":"\\n<blockquote>\\n<p>ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。<strong><em>ZAB 协议不是 Paxos 算法</em></strong>，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。</p>\\n<p>ZAB 协议是 Zookeeper 专门设计的一种<strong>支持故障恢复的原子广播协议</strong>。</p>\\n<p>ZAB 协议是 ZooKeeper 的数据一致性和高可用解决方案。</p>\\n</blockquote>","autoDesc":true}');export{d as comp,c as data};
