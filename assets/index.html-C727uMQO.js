import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a as n,o as a}from"./app-DSy_mEQu.js";const t={};function l(r,s){return a(),e("div",null,[...s[0]||(s[0]=[n(`<h1 id="redis-面试之应用篇" tabindex="-1"><a class="header-anchor" href="#redis-面试之应用篇"><span>Redis 面试之应用篇</span></a></h1><h2 id="缓存" tabindex="-1"><a class="header-anchor" href="#缓存"><span>缓存</span></a></h2><h3 id="【中等】如何避免缓存雪崩、缓存击穿、缓存穿透" tabindex="-1"><a class="header-anchor" href="#【中等】如何避免缓存雪崩、缓存击穿、缓存穿透"><span>【中等】如何避免缓存雪崩、缓存击穿、缓存穿透？</span></a></h3><ul><li><strong>缓存击穿</strong>：指某个热点数据在缓存中失效，导致大量请求直接访问数据库。此时，由于瞬间的高并发，可能导致数据库崩溃。 <ul><li><strong>加锁</strong>：使用互斥锁，确保同一时间只有一个请求可以去数据库查询并更新缓存。</li><li><strong>永久缓存</strong>：热点数据永不过期。</li></ul></li><li><strong>缓存穿透</strong>：指查询一个不存在的数据，缓存中没有相应的记录，每次请求都会去数据库查询，造成数据库负担加重。 <ul><li><strong>布隆过滤器</strong>：使用布隆过滤器，过滤掉不存在的请求，避免直接访问数据库。</li><li><strong>缓存空值</strong>：对查询结果进行缓存，即使是不存在的数据，也可以缓存一个标识，以减少对数据库的请求。<br><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151115189.png" alt="" loading="lazy"></li></ul></li><li><strong>缓存雪崩</strong>：指多个缓存数据在同一时间过期，导致大量请求同时访问数据库，从而造成数据库瞬间负载激增。 <ul><li><strong>随机过期时间</strong>：采用随机过期时间策略，避免多个数据同时过期。</li><li><strong>多级缓存</strong>：使用双缓存策略，将数据同时存储在两层缓存中，减少数据库直接请求。</li></ul></li></ul><h3 id="【中等】如何保证缓存与数据库的数据一致性" tabindex="-1"><a class="header-anchor" href="#【中等】如何保证缓存与数据库的数据一致性"><span>【中等】如何保证缓存与数据库的数据一致性？</span></a></h3><h4 id="cache-aside-旁路缓存" tabindex="-1"><a class="header-anchor" href="#cache-aside-旁路缓存"><span>Cache Aside（旁路缓存）</span></a></h4><ul><li>原理 <ul><li>读流程：应用先查缓存，未命中则读数据库并回源</li><li>写流程：先更新数据库，再删缓存</li></ul></li><li>优点：简单易用，缓存与数据库解耦</li><li>缺点：首次访问可能较慢，需处理缓存与数据库一致性问题（如双写不一致）</li></ul><p><strong>为什么不是先删除缓存，再更新数据库</strong>？</p><ul><li>并发脏读风险 <ul><li>在缓存删除后、数据库更新前，其他线程可能读到旧数据并回填缓存，导致长期不一致</li><li>先更新数据库，再删缓存也存在一致性问题，但由于缓存操作远快于数据库操作，概率小很多</li></ul></li><li>缓存击穿：高并发时，大量请求因缓存缺失直接打到数据库</li></ul><p><strong>为什么不是先更新数据库，再更新缓存</strong>？</p><p>并发写入导致脏数据</p><p>示例</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>线程 1 更新数据库（A → B）</span></span>
<span class="line"><span>线程 2 更新数据库（B → C）</span></span>
<span class="line"><span>线程 2 先更新缓存（C）</span></span>
<span class="line"><span>线程 1 后更新缓存（B）</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>先更新数据库，再删除缓存可以避免这种竞争，因为：即使多个线程并发更新，最终缓存会被删除，后续读取会重新加载正确数据</p><h4 id="read-write-through-读写穿透" tabindex="-1"><a class="header-anchor" href="#read-write-through-读写穿透"><span>Read/Write Through（读写穿透）</span></a></h4><ul><li>原理：缓存层代理所有读写，未命中时缓存从数据库回源</li><li>优点：对应用透明，减少代码侵入性</li><li>缺点：缓存系统需支持复杂逻辑，实现成本较高</li></ul><h4 id="write-behind-异步回写" tabindex="-1"><a class="header-anchor" href="#write-behind-异步回写"><span>Write Behind（异步回写）</span></a></h4><ul><li>原理：写操作先更新缓存，异步批量写入数据库</li><li>优点：写入性能高，适合写多读少场景</li><li>缺点：数据可能丢失（缓存宕机），一致性弱（异步延迟）</li></ul><h4 id="refresh-ahead-预刷新" tabindex="-1"><a class="header-anchor" href="#refresh-ahead-预刷新"><span>Refresh Ahead（预刷新）</span></a></h4><ul><li>原理：缓存过期前主动刷新，避免用户等待</li><li>优点：减少延迟，体验更平滑</li><li>缺点：可能浪费资源（预刷新未访问的数据）</li></ul><h3 id="【中等】有哪些常见的内存淘汰算法" tabindex="-1"><a class="header-anchor" href="#【中等】有哪些常见的内存淘汰算法"><span>【中等】有哪些常见的内存淘汰算法？</span></a></h3><p>缓存淘汰的类型：</p><ul><li><strong>基于空间</strong> - 设置缓存空间大小。</li><li><strong>基于容量</strong> - 设置缓存存储记录数。</li><li>基于时间 <ul><li>TTL（Time To Live，即存活期）缓存数据从创建到过期的时间。</li><li>TTI（Time To Idle，即空闲期）缓存数据多久没被访问的时间。</li></ul></li></ul><p>缓存淘汰算法：</p><ul><li><strong>FIFO</strong> - <strong>先进先出</strong>。在这种淘汰算法中，先进入缓存的会先被淘汰。这种可谓是最简单的了，但是会导致我们命中率很低。试想一下我们如果有个访问频率很高的数据是所有数据第一个访问的，而那些不是很高的是后面再访问的，那这样就会把我们的首个数据但是他的访问频率很高给挤出。</li><li><strong>LRU</strong> - <strong>最近最少使用算法</strong>。在这种算法中避免了上面的问题，每次访问数据都会将其放在我们的队尾，如果需要淘汰数据，就只需要淘汰队首即可。但是这个依然有个问题，如果有个数据在 1 个小时的前 59 分钟访问了 1 万次（可见这是个热点数据）, 再后一分钟没有访问这个数据，但是有其他的数据访问，就导致了我们这个热点数据被淘汰。</li><li><strong>LFU</strong> - <strong>最近最少频率使用</strong>。在这种算法中又对上面进行了优化，利用额外的空间记录每个数据的使用频率，然后选出频率最低进行淘汰。这样就避免了 LRU 不能处理时间段的问题。</li></ul><p>这三种缓存淘汰算法，实现复杂度一个比一个高，同样的命中率也是一个比一个好。而我们一般来说选择的方案居中即可，即实现成本不是太高，而命中率也还行的 LRU。</p><h2 id="分布式锁" tabindex="-1"><a class="header-anchor" href="#分布式锁"><span>分布式锁</span></a></h2><h3 id="【中等】实现分布式锁需要解决哪些问题" tabindex="-1"><a class="header-anchor" href="#【中等】实现分布式锁需要解决哪些问题"><span>【中等】实现分布式锁需要解决哪些问题？</span></a></h3><p>分布式锁的解决方案大致有以下几种：</p><ul><li>基于数据库实现</li><li>基于缓存（Redis，Memcached 等）实现</li><li>基于 Zookeeper 实现</li></ul><p>分布式锁的实现要点大同小异，仅在实现细节上有所不同。</p><p>实现分布式锁需要解决以下目标：</p><ul><li><strong>互斥</strong> - <strong>分布式锁必须是独一无二的</strong>，表现形式为：向数据存储插入一个唯一的 key，一旦有一个线程插入这个 key，其他线程就不能再插入了。</li><li><strong>避免死锁</strong> - 在分布式锁的场景中，部分失败和异步网络这两个问题是同时存在的。如果一个进程获得了锁，但是这个进程与锁服务之间的网络出现了问题，导致无法通信，那么这个情况下，如果锁服务让它一直持有锁，就会导致死锁的发生。 <ul><li>常见的解决思路是引入<strong>超时机制</strong>，即成功申请锁后，超过一定时间，锁失效（删除 key）。</li><li>超时机制解锁了死锁问题，但又引入了一个新问题：如果应用加锁时，对于操作共享资源的时长估计不足，可能会出现：操作尚未执行完，但是锁没了的尴尬情况。为了解决这个问题，需要引入<strong>锁续期</strong>机制：当持有锁的线程尚未执行完操作前，不断周期性检测锁的超时时间，一旦发现快要过期，就自动为锁续期。</li><li>ZooKeeper 分布式锁避免死锁采用了另外一种思路—— Watch 机制。</li></ul></li><li><strong>可重入</strong> - <strong>可重入</strong>指的是：<strong>同一个线程在没有释放锁之前，能否再次获得该锁</strong>。其实现方案是：只需在加锁的时候，<strong>记录好当前获取锁的节点 + 线程组合的唯一标识</strong>，然后在后续的加锁请求时，如果当前请求的节点 + 线程的唯一标识和当前持有锁的相同，那么就直接返回加锁成功；如果不相同，则按正常加锁流程处理。</li><li><strong>公平性</strong> - 当多个线程请求同一锁时，它们必须按照请求的顺序来获取锁，即先来先得的原则。锁的公平性的实现也非常简单，对于被阻塞的加锁请求，我们只要先记录好它们的顺序，在锁被释放后，按顺序颁发就可以了。</li><li><strong>重试</strong> - 有时候，加锁失败可能只是由于网络波动、请求超时等原因，稍候就可以成功获取锁。为了应对这种情况，加锁操作需要支持重试机制。常见的做法是，设置一个加锁超时时间，在该时间范围内，不断自旋重试加锁操作，超时后再判定加锁失败。</li><li><strong>容错</strong> - 分布式锁若存储在单一节点，一旦该节点宕机或失联，就会导致锁失效。将分布式锁存储在多数据库实例中，加锁时并发写入 <code>N</code> 个节点，只要 <code>N / 2 + 1</code> 个节点写入成功即视为加锁成功。代表有：Redis 官方提供的 RedLock。</li></ul><h3 id="【中等】redis-中如何实现分布式锁" tabindex="-1"><a class="header-anchor" href="#【中等】redis-中如何实现分布式锁"><span>【中等】Redis 中如何实现分布式锁？</span></a></h3><p><strong>基础实现</strong></p><ul><li><strong>加锁</strong>：<code>SET key val NX PX 30000</code>（<code>NX</code>：仅当 key 不存在时写入，<code>PX</code>：超时时间，毫秒）。</li><li><strong>解锁</strong>：<code>DEL key</code>（直接删除 key 释放锁）。</li></ul><p><strong>避免死锁</strong></p><ul><li><strong>问题</strong>：节点宕机或异常导致锁无法释放。</li><li><strong>方案</strong>：加锁时设置<strong>超时时间</strong>（<code>PX/EX</code>），到期自动删除。</li><li><strong>原子性</strong>：使用 <code>SET key val NX PX</code> 替代 <code>setnx + expire</code>，避免组合命令非原子性问题。</li></ul><p><strong>超时续期（WatchDog）</strong></p><ul><li><strong>问题</strong>：业务未执行完，锁已过期。</li><li><strong>方案</strong>：启动<strong>定时任务</strong>检测锁剩余时间，自动续期（如 Redisson 的 WatchDog 机制）。</li></ul><p><strong>安全解锁</strong></p><ul><li><strong>问题</strong>：其他节点误删锁。</li><li><strong>方案</strong>： <ul><li>加锁时写入<strong>唯一标识</strong>（如 UUID）。</li><li>解锁时校验标识，<strong>匹配才删除</strong>（使用 Lua 脚本保证原子性）：<div class="language-lua line-numbers-mode" data-highlighter="shiki" data-ext="lua" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-lua"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> redis</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">call</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;get&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">KEYS</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]) == </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">ARGV</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">then</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> redis</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">call</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;del&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">KEYS</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">else</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">end</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li></ul><p><strong>自旋重试</strong></p><ul><li><strong>问题</strong>：网络波动导致加锁失败。</li><li><strong>方案</strong>：在超时时间内<strong>循环重试</strong>加锁（伪代码示例见原内容）。</li></ul><p><strong>其他问题</strong></p><ul><li><strong>不可重入</strong>：同一线程无法重复获取同一把锁（可通过 Redisson 等客户端支持）。</li><li><strong>单点问题</strong>：主从切换可能导致锁失效（可用 <strong>RedLock 算法</strong>，但存在争议）。</li></ul><h3 id="【中等】red-lock-分布式锁的原理是什么" tabindex="-1"><a class="header-anchor" href="#【中等】red-lock-分布式锁的原理是什么"><span>【中等】Red Lock 分布式锁的原理是什么？</span></a></h3><p><strong>核心机制</strong>：</p><ul><li><strong>多节点写入</strong>：同时向多个 Redis 主节点（≥5 个）加锁</li><li><strong>多数派原则</strong>：半数以上节点加锁成功才算成功</li><li><strong>耗时控制</strong>：总加锁时间必须小于锁的过期时间</li><li><strong>强制清理</strong>：解锁时向所有节点发起请求</li></ul><p><strong>注意事项</strong></p><ul><li><strong>网络延迟</strong>：多节点操作会增加耗时风险</li><li><strong>性能代价</strong>：相比单节点锁性能更低</li><li><strong>实现复杂度</strong>：需要精确控制时间和节点状态</li></ul><h3 id="【中等】redisson-分布式锁的原理是什么" tabindex="-1"><a class="header-anchor" href="#【中等】redisson-分布式锁的原理是什么"><span>【中等】Redisson 分布式锁的原理是什么？</span></a></h3><p><a href="https://github.com/redisson/redisson" target="_blank" rel="noopener noreferrer">Redisson</a> 是一个流行的 Redis Java 客户端，它基于 Netty 开发，并提供了丰富的扩展功能，如：<a href="https://redisson.org/docs/data-and-services/counters/" target="_blank" rel="noopener noreferrer">分布式计数器</a>、<a href="https://redisson.org/docs/data-and-services/collections/" target="_blank" rel="noopener noreferrer">分布式集合</a>、<a href="https://redisson.org/docs/data-and-services/locks-and-synchronizers/" target="_blank" rel="noopener noreferrer">分布式锁</a> 等。</p><p>Redisson 支持的分布式锁有多种：Lock, FairLock, MultiLock, RedLock, ReadWriteLock, Semaphore, PermitExpirableSemaphore, CountDownLatch，可以根据场景需要去选择，非常方便。一般而言，使用 Redis 分布式锁，推荐直接使用 Redisson 提供的 API，功能全面且较为可靠。</p><p><strong>Redisson 分布式锁的实现要点</strong>：</p><ul><li><strong>锁的获取</strong>：Redisson 使用 Lua 脚本，利用 <code>exists + hexists + hincrby</code> 命令来保证只有一个线程能成功设置键（表示获得锁）。同时，Redisson 会通过 <code>pexpire</code> 命令为锁设置过期时间，防止因宕机等原因导致锁无法释放（即死锁问题）。</li><li><strong>锁的续期</strong>：为了防止锁在持有过程中过期导致其他线程抢占锁，Redisson 实现了一种叫做 <strong>Watch Dog（看门狗）</strong> 的锁自动续期的功能。持有锁的线程会定期续期，即更新锁的过期时间，确保任务没有完成时锁不会失效。</li><li><strong>锁的释放</strong>：锁释放时，Redisson 也是通过 Lua 脚本保证释放操作的原子性。利用 <code>hexists + del</code> 确保只有持有锁的线程才能释放锁，防止误释放锁的情况。Lua 脚本同时利用 publish 命令，广播唤醒其它等待的线程。</li><li><strong>可重入锁</strong>：Redisson 支持可重入锁，持有锁的线程可以多次获取同一把锁而不会被阻塞。具体是利用 Redis 中的哈希结构，哈希中的 key 为线程 ID，如果重入则 value +1，如果释放则 value -1，减到 0 说明锁被释放了，则 del 锁。</li></ul><h2 id="消息队列" tabindex="-1"><a class="header-anchor" href="#消息队列"><span>消息队列</span></a></h2><h3 id="【中等】redis-如何实现消息队列" tabindex="-1"><a class="header-anchor" href="#【中等】redis-如何实现消息队列"><span>【中等】Redis 如何实现消息队列？</span></a></h3><blockquote><p>Redis 可以做消息队列吗？</p><p>Redis 有哪些实现消息队列的方式？</p></blockquote><p>先说结论：<strong>可以是可以，但不建议使用 Redis 来做消息队列。和专业的消息队列相比，还是有很多欠缺的地方。</strong></p><h4 id="基于-list-实现消息队列" tabindex="-1"><a class="header-anchor" href="#基于-list-实现消息队列"><span>基于 List 实现消息队列</span></a></h4><p><strong>Redis 2.0 之前，如果想要使用 Redis 来做消息队列的话，只能通过 List 来实现。</strong></p><p>通过 <code>RPUSH/LPOP</code> 或者 <code>LPUSH/RPOP</code>即可实现简易版消息队列：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 生产者生产消息</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; RPUSH myList msg1 msg2</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">integer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">2</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; RPUSH myList msg3</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">integer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">3</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 消费者消费消息</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; LPOP myList</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">&quot;msg1&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>不过，通过 <code>RPUSH/LPOP</code> 或者 <code>LPUSH/RPOP</code>这样的方式存在性能问题，我们需要不断轮询去调用 <code>RPOP</code> 或 <code>LPOP</code> 来消费消息。当 List 为空时，大部分的轮询的请求都是无效请求，这种方式大量浪费了系统资源。</p><p>因此，Redis 还提供了 <code>BLPOP</code>、<code>BRPOP</code> 这种阻塞式读取的命令（带 B-Blocking 的都是阻塞式），并且还支持一个超时参数。如果 List 为空，Redis 服务端不会立刻返回结果，它会等待 List 中有新数据后再返回或者是等待最多一个超时时间后返回空。如果将超时时间设置为 0 时，即可无限等待，直到弹出消息</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 超时时间为 10s</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 如果有数据立刻返回，否则最多等待 10 秒</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; BRPOP myList 10</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">null</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>List 实现消息队列功能太简单，像消息确认机制等功能还需要我们自己实现，最要命的是没有广播机制，消息也只能被消费一次。</strong></p><h4 id="基于发布订阅功能实现消息队列" tabindex="-1"><a class="header-anchor" href="#基于发布订阅功能实现消息队列"><span>基于发布订阅功能实现消息队列</span></a></h4><p><strong>Redis 2.0 引入了发布订阅 (pub/sub) 功能，解决了 List 实现消息队列没有广播机制的问题。</strong></p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272225857.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Redis 发布订阅 (pub/sub) 功能</p><p>pub/sub 中引入了一个概念叫 <strong>channel（频道）</strong>，发布订阅机制的实现就是基于这个 channel 来做的。</p><p>pub/sub 涉及发布者（Publisher）和订阅者（Subscriber，也叫消费者）两个角色：</p><ul><li>发布者通过 <code>PUBLISH</code> 投递消息给指定 channel。</li><li>订阅者通过<code>SUBSCRIBE</code>订阅它关心的 channel。并且，订阅者可以订阅一个或者多个 channel。</li></ul><p>pub/sub 既能单播又能广播，还支持 channel 的简单正则匹配。不过，消息丢失（客户端断开连接或者 Redis 宕机都会导致消息丢失）、消息堆积（发布者发布消息的时候不会管消费者的具体消费能力如何）等问题依然没有一个比较好的解决办法。</p><h4 id="基于-stream-实现消息队列" tabindex="-1"><a class="header-anchor" href="#基于-stream-实现消息队列"><span>基于 Stream 实现消息队列</span></a></h4><p>为此，Redis 5.0 新增加的一个数据结构 <code>Stream</code> 来做消息队列。<code>Stream</code> 支持：</p><ul><li>发布 / 订阅模式</li><li>按照消费者组进行消费（借鉴了 Kafka 消费者组的概念）</li><li>消息持久化（ RDB 和 AOF）</li><li>ACK 机制（通过确认机制来告知已经成功处理了消息）</li><li>阻塞式获取消息</li></ul><p><code>Stream</code> 的结构如下：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503270823833.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>这是一个有序的消息链表，每个消息都有一个唯一的 ID 和对应的内容。ID 是一个时间戳和序列号的组合，用来保证消息的唯一性和递增性。内容是一个或多个键值对（类似 Hash 基本数据类型），用来存储消息的数据。</p><p>这里再对图中涉及到的一些概念，进行简单解释：</p><ul><li><code>Consumer Group</code>：消费者组用于组织和管理多个消费者。消费者组本身不处理消息，而是再将消息分发给消费者，由消费者进行真正的消费</li><li><code>last_delivered_id</code>：标识消费者组当前消费位置的游标，消费者组中任意一个消费者读取了消息都会使 last_delivered_id 往前移动。</li><li><code>pending_ids</code>：记录已经被客户端消费但没有 ack 的消息的 ID。</li></ul><p><code>Stream</code> 使用起来相对要麻烦一些，这里就不演示了。</p><p>总的来说，<code>Stream</code> 已经可以满足一个消息队列的基本要求了。不过，<code>Stream</code> 在实际使用中依然会有一些小问题不太好解决比如在 Redis 发生故障恢复后不能保证消息至少被消费一次。</p><p>综上，和专业的消息队列相比，使用 Redis 来实现消息队列还是有很多欠缺的地方比如消息丢失和堆积问题不好解决。因此，我们通常建议不要使用 Redis 来做消息队列，你完全可以选择市面上比较成熟的一些消息队列比如 RocketMQ、Kafka。不过，如果你就是想要用 Redis 来做消息队列的话，那我建议你优先考虑 <code>Stream</code>，这是目前相对最优的 Redis 消息队列实现。</p><p>相关阅读：<a href="https://mp.weixin.qq.com/s/gCUT5TcCQRAxYkTJfTRjJw" target="_blank" rel="noopener noreferrer">Redis 消息队列发展历程 - 阿里开发者 - 2022</a></p><h2 id="延时任务" tabindex="-1"><a class="header-anchor" href="#延时任务"><span>延时任务</span></a></h2><h3 id="【中等】如何基于-redis-实现延时任务" tabindex="-1"><a class="header-anchor" href="#【中等】如何基于-redis-实现延时任务"><span>【中等】如何基于 Redis 实现延时任务？</span></a></h3><p>基于 Redis 实现延时任务的功能无非就下面两种方案：</p><ol><li>Redis 过期事件监听</li><li>Redisson 内置的延时队列</li></ol><p>Redis 过期事件监听的存在时效性较差、丢消息、多服务实例下消息重复消费等问题，不被推荐使用。</p><p>Redisson 内置的延时队列具备下面这些优势：</p><ol><li><strong>减少了丢消息的可能</strong>：DelayedQueue 中的消息会被持久化，即使 Redis 宕机了，根据持久化机制，也只可能丢失一点消息，影响不大。当然了，你也可以使用扫描数据库的方法作为补偿机制。</li><li><strong>消息不存在重复消费问题</strong>：每个客户端都是从同一个目标队列中获取任务的，不存在重复消费的问题。</li></ol><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ul><li><a href="https://juejin.im/post/5ad6e4066fb9a028d82c4b66" target="_blank" rel="noopener noreferrer">面试中关于 Redis 的问题看这篇就够了</a></li><li><a href="https://github.com/doocs/advanced-java#%E7%BC%93%E5%AD%98" target="_blank" rel="noopener noreferrer">advanced-java</a></li><li><a href="https://xiaolincoding.com/redis/base/redis_interview.html" target="_blank" rel="noopener noreferrer">Redis 常见面试题</a></li></ul>`,97)])])}const h=i(t,[["render",l]]),p=JSON.parse('{"path":"/pages/9145dbc8/","title":"Redis 面试之应用篇","lang":"zh-CN","frontmatter":{"icon":"logos:redis","title":"Redis 面试之应用篇","cover":"https://raw.githubusercontent.com/dunwu/images/master/snap/202503110803916.jpg","date":"2020-07-13T17:03:42.000Z","categories":["数据库","KV数据库","Redis"],"tags":["数据库","KV 数据库","Redis","面试"],"permalink":"/pages/9145dbc8/","description":"Redis 面试之应用篇 缓存 【中等】如何避免缓存雪崩、缓存击穿、缓存穿透？ 缓存击穿：指某个热点数据在缓存中失效，导致大量请求直接访问数据库。此时，由于瞬间的高并发，可能导致数据库崩溃。 加锁：使用互斥锁，确保同一时间只有一个请求可以去数据库查询并更新缓存。 永久缓存：热点数据永不过期。 缓存穿透：指查询一个不存在的数据，缓存中没有相应的记录，每次...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Redis 面试之应用篇\\",\\"image\\":[\\"https://raw.githubusercontent.com/dunwu/images/master/202506151115189.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503272225857.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503270823833.png\\"],\\"datePublished\\":\\"2020-07-13T17:03:42.000Z\\",\\"dateModified\\":\\"2025-09-23T15:53:48.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"钝悟\\",\\"url\\":\\"https://dunwu.github.io/waterdrop\\"}]}"],["meta",{"property":"og:url","content":"https://dunwu.github.io/waterdrop/waterdrop/pages/9145dbc8/"}],["meta",{"property":"og:site_name","content":"钝悟"}],["meta",{"property":"og:title","content":"Redis 面试之应用篇"}],["meta",{"property":"og:description","content":"Redis 面试之应用篇 缓存 【中等】如何避免缓存雪崩、缓存击穿、缓存穿透？ 缓存击穿：指某个热点数据在缓存中失效，导致大量请求直接访问数据库。此时，由于瞬间的高并发，可能导致数据库崩溃。 加锁：使用互斥锁，确保同一时间只有一个请求可以去数据库查询并更新缓存。 永久缓存：热点数据永不过期。 缓存穿透：指查询一个不存在的数据，缓存中没有相应的记录，每次..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dunwu/images/master/snap/202503110803916.jpg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-09-23T15:53:48.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://raw.githubusercontent.com/dunwu/images/master/snap/202503110803916.jpg"}],["meta",{"name":"twitter:image:alt","content":"Redis 面试之应用篇"}],["meta",{"property":"article:tag","content":"面试"}],["meta",{"property":"article:tag","content":"Redis"}],["meta",{"property":"article:tag","content":"KV 数据库"}],["meta",{"property":"article:tag","content":"数据库"}],["meta",{"property":"article:published_time","content":"2020-07-13T17:03:42.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-23T15:53:48.000Z"}]]},"git":{"createdTime":1743031896000,"updatedTime":1758642828000,"contributors":[{"name":"dunwu","username":"dunwu","email":"forbreak@163.com","commits":10,"url":"https://github.com/dunwu"}]},"readingTime":{"minutes":15.44,"words":4633},"filePathRelative":"12.数据库/KV数据库/Redis/Redis_面试_应用.md","excerpt":"\\n<h2>缓存</h2>\\n<h3>【中等】如何避免缓存雪崩、缓存击穿、缓存穿透？</h3>\\n<ul>\\n<li><strong>缓存击穿</strong>：指某个热点数据在缓存中失效，导致大量请求直接访问数据库。此时，由于瞬间的高并发，可能导致数据库崩溃。\\n<ul>\\n<li><strong>加锁</strong>：使用互斥锁，确保同一时间只有一个请求可以去数据库查询并更新缓存。</li>\\n<li><strong>永久缓存</strong>：热点数据永不过期。</li>\\n</ul>\\n</li>\\n<li><strong>缓存穿透</strong>：指查询一个不存在的数据，缓存中没有相应的记录，每次请求都会去数据库查询，造成数据库负担加重。\\n<ul>\\n<li><strong>布隆过滤器</strong>：使用布隆过滤器，过滤掉不存在的请求，避免直接访问数据库。</li>\\n<li><strong>缓存空值</strong>：对查询结果进行缓存，即使是不存在的数据，也可以缓存一个标识，以减少对数据库的请求。<br>\\n<img src=\\"https://raw.githubusercontent.com/dunwu/images/master/202506151115189.png\\" alt=\\"\\" loading=\\"lazy\\"></li>\\n</ul>\\n</li>\\n<li><strong>缓存雪崩</strong>：指多个缓存数据在同一时间过期，导致大量请求同时访问数据库，从而造成数据库瞬间负载激增。\\n<ul>\\n<li><strong>随机过期时间</strong>：采用随机过期时间策略，避免多个数据同时过期。</li>\\n<li><strong>多级缓存</strong>：使用双缓存策略，将数据同时存储在两层缓存中，减少数据库直接请求。</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{h as comp,p as data};
