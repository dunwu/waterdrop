import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a as t,o as n}from"./app-DliBoNQn.js";const l={};function r(a,i){return n(),e("div",null,[...i[0]||(i[0]=[t(`<h1 id="redis-面试" tabindex="-1"><a class="header-anchor" href="#redis-面试"><span>Redis 面试</span></a></h1><div class="hint-container tip"><p class="hint-container-title">扩展</p><ul><li><a href="https://juejin.im/post/5ad6e4066fb9a028d82c4b66" target="_blank" rel="noopener noreferrer">面试中关于 Redis 的问题看这篇就够了</a></li><li><a href="https://github.com/doocs/advanced-java#%E7%BC%93%E5%AD%98" target="_blank" rel="noopener noreferrer">advanced-java</a></li><li><a href="https://xiaolincoding.com/redis/base/redis_interview.html" target="_blank" rel="noopener noreferrer">Redis 常见面试题</a></li></ul></div><h2 id="redis-简介" tabindex="-1"><a class="header-anchor" href="#redis-简介"><span>Redis 简介</span></a></h2><h3 id="【简单】什么是-redis" tabindex="-1"><a class="header-anchor" href="#【简单】什么是-redis"><span>【简单】什么是 Redis？</span></a></h3><div class="hint-container info"><p class="hint-container-title">什么是 Redis？</p></div><p><strong>Redis 是一个开源的、数据存于内存中的 K-V 数据库</strong>。由于，Redis 的读写操作都是在内存中完成，因此其<strong>读写速度非常快</strong>。</p><ul><li><strong>高性能</strong>：由于，Redis 的读写操作都是在内存中完成，因此性能极高。</li><li><strong>高并发</strong>：Redis 单机 QPS 能达到 10w+，将近是 Mysql 的 10 倍。</li></ul><p>Redis 常被用于<strong>缓存，消息队列、分布式锁等场景</strong>。</p><div class="hint-container info"><p class="hint-container-title">Redis 有什么功能和特性？</p></div><p>Redis 的功能和特性：</p><ul><li><strong>Redis 支持多种数据类型</strong>。如：String（字符串）、Hash（哈希）、 List （列表）、Set（集合）、Zset（有序集合）、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理空间）、Stream（流）。</li><li><strong>Redis 的读写采用“单线程”模型</strong>，因此，其操作天然就具有<strong>原子性</strong>。需要注意的是，Redis 6.0 后在其网络模块中引入了多线程 I/O 机制。</li><li>Redis 支持两种<strong>持久化策略</strong>：<strong>RDB</strong> 和 <strong>AOF</strong>。</li><li>Redis 有多种<strong>高可用方案</strong>：<strong>主从复制</strong>模式、<strong>哨兵</strong>模式、<strong>集群</strong>模式。</li><li>Redis 支持很多丰富的特性，如：<strong>事务</strong> 、<strong>Lua 脚本</strong>、<strong>发布订阅</strong>、<strong>过期删除</strong>、<strong>内存淘汰</strong>等等。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202411231010326.png" alt="图来自 Redis Explained" tabindex="0" loading="lazy"><figcaption>图来自 <a href="https://architecturenotes.co/p/redis" target="_blank" rel="noopener noreferrer">Redis Explained</a></figcaption></figure><h3 id="【简单】redis-有哪些应用场景" tabindex="-1"><a class="header-anchor" href="#【简单】redis-有哪些应用场景"><span>【简单】Redis 有哪些应用场景？</span></a></h3><p>Redis 常见应用场景如下：</p><ul><li><strong>缓存</strong>：将热点数据放到内存中，设置内存的最大使用量以及过期淘汰策略来保证缓存的命中率。</li><li><strong>计数器</strong>：Redis 这种内存数据库能支持计数器频繁的读写操作。</li><li><strong>应用限流</strong>：限制一个网站访问流量。</li><li><strong>消息队列</strong>：使用 List 数据类型，它是双向链表。</li><li><strong>查找表</strong>：使用 HASH 数据类型。</li><li><strong>聚合运算</strong>：使用 SET 类型，例如求两个用户的共同好友。</li><li><strong>排行榜</strong>：使用 ZSET 数据类型。</li><li><strong>分布式 Session</strong>：多个应用服务器的 Session 都存储到 Redis 中来保证 Session 的一致性。</li><li><strong>分布式锁</strong>：除了可以使用 SETNX 实现分布式锁之外，还可以使用官方提供的 RedLock 分布式锁实现。</li></ul><h3 id="【简单】redis-有哪些里程碑版本" tabindex="-1"><a class="header-anchor" href="#【简单】redis-有哪些里程碑版本"><span>【简单】Redis 有哪些里程碑版本？</span></a></h3><p>Redis 里程碑版本如下：</p><ul><li><strong>Redis 1.0（2010 年）</strong>：Redis 1.0 发布，采用单机架构，一般作为业务应用的缓存。但是 Redis 的数据是存在内存中的，重启 Redis 时，数据会全部丢失，流量直接打到数据库。</li><li><strong>Redis 2.8（2013 年）</strong><ul><li><strong>持久化</strong>：Redis 引入了 RDB 内存快照来持久化数据。它还支持 AOF（仅追加文件），其中每个写入命令都写入 AOF 文件。</li><li><strong>复制</strong>：添加了复制功能以提高可用性。主实例处理实时读写请求，而副本同步主实例的数据。</li><li><strong>哨兵</strong>：引入了 Sentinel 来实时监控 Redis 实例。Sentinel 是一个旨在帮助管理 Redis 实例的系统。它执行以下四个任务：监控、通知、自动故障转移和共享配置。</li></ul></li><li><strong>Redis 3.0（2015 年）</strong>：官方提供了 <strong>redis-cluster</strong>。redis-cluster 是一种分布式数据库解决方案，通过分片管理数据。数据被分成 16384 个槽，每个节点负责槽的一部分。</li><li><strong>Redis 5.0（2017 年）</strong>：新增 <strong>Stream</strong> 数据类型。</li><li><strong>Redis 6.0（2020 年）</strong>：在网络模块中引入了<strong>多线程 I/O</strong>。Redis 模型分为网络模块和主处理模块。特别注意：Redis 不再完全是单线程架构。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503270820508.gif" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【简单】对比一下-redis-和-memcached" tabindex="-1"><a class="header-anchor" href="#【简单】对比一下-redis-和-memcached"><span>【简单】对比一下 Redis 和 Memcached？</span></a></h3><blockquote><ul><li>Redis 和 Memcached 有什么相同点？</li><li>Redis 和 Memcached 有什么差异？</li><li>分布式缓存技术选型，选 Redis 还是 Memcached，为什么？</li></ul></blockquote><p>Redis 与 Memcached 的<strong>共性</strong>：</p><ul><li>都是内存数据库，因此性能都很高。</li><li>都有过期策略。</li></ul><p>因为以上两点，所以常被作为缓存使用。</p><p>Redis 与 Memcached 的<strong>差异</strong>：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202504010716308.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>核心差异对比：</p><table><thead><tr><th></th><th>Memcached</th><th>Redis</th></tr></thead><tbody><tr><td>数据类型</td><td>只支持 String 类型</td><td>支持多种数据类型：String、Hash、List、Set、ZSet 等</td></tr><tr><td>持久化</td><td>不支持持久化，一旦重启或宕机就会丢失数据</td><td>支持两种持久化策略：RDB 和 AOF</td></tr><tr><td>分布式</td><td>本身不支持分布式，只能通过在客户端使用像一致性哈希这样的分布式算法来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点</td><td>支持分布式</td></tr><tr><td>线程模型</td><td>采用多线程+IO 多路复用。在 100k 以上的数据中，Memcached 性能要高于 Redis</td><td>读写采用单线程+IO 多路复用。因此存储小数据时比 Memcached 性能更高</td></tr><tr><td>其他功能</td><td>不支持</td><td>支持发布订阅模型、Lua 脚本、事务等功能</td></tr></tbody></table><p>通过以上分析，可以看出，Redis 在很多方面都占有优势。因此，绝大多数情况下，优先选择 Redis 作为分布式缓存。</p><div class="hint-container tip"><p class="hint-container-title">扩展</p><p><a href="https://www.imooc.com/article/23549" target="_blank" rel="noopener noreferrer">《脚踏两只船的困惑 - Memcached 与 Redis》</a></p></div><h3 id="【简单】redis-有哪些-java-客户端-各有什么优劣" tabindex="-1"><a class="header-anchor" href="#【简单】redis-有哪些-java-客户端-各有什么优劣"><span>【简单】Redis 有哪些 Java 客户端？各有什么优劣？</span></a></h3><p>Redis 的主流 Java 客户端有三种，对比如下：</p><table><thead><tr><th style="text-align:left;">客户端</th><th style="text-align:left;">线程安全</th><th style="text-align:left;">自动重连</th><th style="text-align:left;">编程模型</th><th style="text-align:left;">适用场景</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Jedis</strong></td><td style="text-align:left;">❌</td><td style="text-align:left;">❌</td><td style="text-align:left;">同步</td><td style="text-align:left;">简单应用、快速开发</td></tr><tr><td style="text-align:left;"><strong>Lettuce</strong></td><td style="text-align:left;">✔️</td><td style="text-align:left;">✔️</td><td style="text-align:left;">同步/异步/响应式</td><td style="text-align:left;">高并发、Spring Boot 项目</td></tr><tr><td style="text-align:left;"><strong>Redisson</strong></td><td style="text-align:left;">✔️</td><td style="text-align:left;">✔️</td><td style="text-align:left;">同步/异步</td><td style="text-align:left;">分布式系统、高级功能需求</td></tr></tbody></table><p><strong>推荐选择</strong>：</p><ul><li><strong>基础需求</strong> → Jedis（简单直接）。</li><li><strong>高并发/Spring 项目</strong> → Lettuce（默认选择）。</li><li><strong>分布式锁/队列等</strong> → Redisson（功能强大）。</li></ul><div class="hint-container info"><p class="hint-container-title">Jedis</p></div><p><strong>✔️ 优点</strong></p><ul><li><strong>简单易用</strong>：API 直观，适合快速上手。</li><li><strong>广泛使用</strong>：社区支持丰富，文档齐全。</li><li><strong>性能良好</strong>：常规操作高效。</li><li><strong>功能全面</strong>：支持字符串、哈希、列表等基础数据结构。</li></ul><p><strong>❌ 缺点</strong></p><ul><li><strong>非线程安全</strong>：需为每个线程创建独立实例。</li><li><strong>无自动重连</strong>：网络异常需手动处理。</li><li><strong>同步阻塞</strong>：高并发时可能成为性能瓶颈。</li></ul><div class="hint-container info"><p class="hint-container-title">Lettuce</p></div><p><strong>✔️ 优点</strong></p><ul><li><strong>线程安全</strong>：多线程共享同一连接。</li><li><strong>高性能</strong>：基于 Netty 实现，支持高并发。</li><li><strong>自动重连</strong>：网络中断后自动恢复。</li><li><strong>多编程模型</strong>：支持同步、异步、响应式（如 Reactive API）。</li></ul><p><strong>❌ 缺点</strong></p><ul><li><strong>API 较复杂</strong>：学习成本高于 Jedis。</li><li><strong>资源消耗</strong>：异步模式可能占用更多内存/CPU。</li></ul><div class="hint-container info"><p class="hint-container-title">Redisson</p></div><p><strong>✔️ 优点</strong></p><ul><li><strong>分布式支持</strong>：内置分布式锁、队列、缓存等高级功能。</li><li><strong>线程安全</strong>：天然适配多线程场景。</li><li><strong>集群友好</strong>：完善支持 Redis 集群模式。</li><li><strong>稳定性高</strong>：企业级应用验证。</li></ul><p><strong>❌ 缺点</strong></p><ul><li><strong>学习曲线陡峭</strong>：需掌握分布式概念。</li><li><strong>依赖兼容性</strong>：可能与其他库冲突需调优。</li></ul><h2 id="redis-内存管理" tabindex="-1"><a class="header-anchor" href="#redis-内存管理"><span>Redis 内存管理</span></a></h2><h3 id="【中等】redis-支持哪些过期删除策略-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-支持哪些过期删除策略-⭐⭐"><span>【中等】Redis 支持哪些过期删除策略？⭐⭐</span></a></h3><blockquote><ul><li>Redis 支持哪些过期删除策略？</li><li>常见的过期策略有哪些，Redis 的选择考量是什么？</li></ul></blockquote><p>Redis 采用的过期策略是：<strong>定期删除+惰性删除</strong>。</p><ul><li><strong>定时删除</strong>：在设置 key 的过期时间的同时，创建一个定时器，让定时器在 key 的过期时间来临时，立即执行 key 的删除操作。 <ul><li><strong>优点</strong>：保证过期 key 被尽可能快的删除，释放内存。</li><li><strong>缺点</strong>：<strong>如果过期 key 较多，可能会占用相当一部分的 CPU，从而影响服务器的吞吐量和响应时延</strong>。</li></ul></li><li><strong>惰性删除</strong>：放任 key 过期不管，但是每次访问 key 时，都检查 key 是否过期，如果过期的话，就删除该 key ；如果没有过期，就返回该 key。 <ul><li><strong>优点</strong>：占用 CPU 最少。程序只会在读写键时，对当前键进行过期检查，因此不会有额外的 CPU 开销。</li><li><strong>缺点</strong>：<strong>过期的 key 可能因为没有被访问，而一直无法释放，造成内存的浪费，有内存泄漏的风险</strong>。</li></ul></li><li><strong>定期删除</strong>：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期 key。至于要删除多少过期 key ，以及要检查多少个数据库，则由算法决定。定期删除是前两种策略的一种折中方案。定期删除策略的难点是删除操作执行的时长和频率。 <ul><li>执行太频或执行时间过长，就会出现和定时删除相同的问题；</li><li>执行太少或执行时间过短，就会出现和惰性删除相同的问题；</li></ul></li></ul><h3 id="【中等】redis-有哪些内存淘汰策略-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-有哪些内存淘汰策略-⭐⭐⭐"><span>【中等】Redis 有哪些内存淘汰策略？⭐⭐⭐</span></a></h3><blockquote><ul><li>Redis 内存不足时，怎么办？</li><li>Redis 有哪些内存淘汰策略？</li><li>如何选择内存淘汰策略？</li></ul></blockquote><div class="hint-container info"><p class="hint-container-title">Redis 内存淘汰要点</p></div><ul><li><strong>失效时间</strong>：作为一种定期清理无效数据的重要机制，在 Redis 提供的诸多命令中，<code>EXPIRE</code>、<code>EXPIREAT</code>、<code>PEXPIRE</code>、<code>PEXPIREAT</code> 以及 <code>SETEX</code> 和 <code>PSETEX</code> 均可以用来设置一条键值对的失效时间。而一条键值对一旦被关联了失效时间就会在到期后自动删除（或者说变得无法访问更为准确）。</li><li><strong>最大缓存</strong>：Redis 允许通过 <code>maxmemory</code> 参数来设置内存最大值。当内存达设定的阀值，就会触发<strong>内存淘汰</strong>。</li><li><strong>内存淘汰</strong>：内存淘汰是为了更好的利用内存——清理部分缓存，以此换取内存的利用率，即尽量保证 Redis 缓存中存储的是热点数据。</li></ul><div class="hint-container info"><p class="hint-container-title">Redis 内存淘汰策略</p></div><ul><li><strong>不淘汰</strong><ul><li><strong><code>noeviction</code></strong>：当内存使用达到阈值的时候，所有引起申请内存的命令会报错。这是 Redis 默认的策略。</li></ul></li><li><strong>在过期键中进行淘汰</strong><ul><li><strong><code>volatile-random</code></strong>：在设置了过期时间的键空间中，随机移除某个 key。</li><li><strong><code>volatile-ttl</code></strong>：在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除。</li><li><strong><code>volatile-lru</code></strong>：在设置了过期时间的键空间中，优先移除最近未使用的 key。</li><li><strong><code>volatile-lfu</code></strong> （Redis 4.0 新增）- 淘汰所有设置了过期时间的键值中，最少使用的键值。</li></ul></li><li><strong>在所有键中进行淘汰</strong><ul><li><strong><code>allkeys-random</code></strong>：在主键空间中，随机移除某个 key。</li><li><strong><code>allkeys-lru</code></strong>：在主键空间中，优先移除最近未使用的 key。</li><li><strong><code>allkeys-lfu</code></strong> (Redis 4.0 新增） - 淘汰整个键值中最少使用的键值。</li></ul></li></ul><div class="hint-container info"><p class="hint-container-title">如何选择内存淘汰策略</p></div><ul><li>如果数据呈现正态分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 <code>allkeys-lru</code> 或 <code>allkeys-lfu</code>。</li><li>如果数据呈现平均分布，也就是所有的数据访问频率都相同，则使用 <code>allkeys-random</code>。</li><li>若 Redis 既用于缓存，也用于持久化存储时，适用 <code>volatile-lru</code> 、<code>volatile-lfu</code>、<code>volatile-random</code>。但是，这种情况下，也可以部署两个 Redis 集群来达到同样目的。</li><li>为 key 设置过期时间实际上会消耗更多的内存。因此，如果条件允许，建议使用 <code>allkeys-lru</code> 或 <code>allkeys-lfu</code>，从而更高效的使用内存。</li></ul><h3 id="【中等】redis-持久化时-对过期键会如何处理" tabindex="-1"><a class="header-anchor" href="#【中等】redis-持久化时-对过期键会如何处理"><span>【中等】Redis 持久化时，对过期键会如何处理？</span></a></h3><p><strong>RDB 持久化</strong></p><ul><li><strong>RDB 文件生成阶段</strong>：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键“不会”被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</li><li><strong>RDB 加载阶段</strong>：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况： <ul><li><strong>如果 Redis 是“主服务器”运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键“不会”被载入到数据库中</strong>。所以过期键不会对载入 RDB 文件的主服务器造成影响；</li><li><strong>如果 Redis 是“从服务器”运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。</li></ul></li></ul><p><strong>AOF 持久化</strong></p><ul><li><strong>AOF 文件写入阶段</strong>：当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li><li><strong>AOF 重写阶段</strong>：执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响。</li></ul><h3 id="【中等】redis-主从复制时-对过期键会如何处理" tabindex="-1"><a class="header-anchor" href="#【中等】redis-主从复制时-对过期键会如何处理"><span>【中等】Redis 主从复制时，对过期键会如何处理？</span></a></h3><p>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</p><p>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p><h3 id="【中等】redis-中的内存碎片化是什么-如何进行优化" tabindex="-1"><a class="header-anchor" href="#【中等】redis-中的内存碎片化是什么-如何进行优化"><span>【中等】Redis 中的内存碎片化是什么？如何进行优化？</span></a></h3><p>Redis 内存碎片化是指已分配的内存无法被有效利用，导致内存浪费的现象。</p><p>可以通过 Redis 的 <code>INFO memory</code> 命令查看：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">mem_fragmentation_ratio:</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1.86</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 大于 1.5 表示碎片较多</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>内存碎片的原因</strong>：</p><ul><li><strong>内存分配器机制</strong>：Redis 使用 Jemalloc 或 glibc 的 malloc 等内存分配器，这些分配器为了性能不会总是精确分配请求的大小，可能分配稍大的块。</li><li><strong>键值对频繁修改</strong>：当键值对被频繁修改（特别是大小变化时），旧的内存空间可能无法重用。例如：字符串值从 128B 改为 256B，原空间不够需要新分配。</li><li><strong>键过期/删除</strong>：删除键释放的内存块可能无法与相邻空闲块合并，这些碎片空间可能无法满足新的大内存请求。</li><li><strong>不同大小的数据混合存储</strong>：Redis 存储各种大小的键值对，导致内存中出现大小不一的空闲块。</li></ul><p><strong>内存碎片的影响</strong>：</p><ul><li><strong>内存分配策略</strong>：不同的分配器 (Jemalloc/libc 等）碎片率不同</li><li><strong>工作负载模式</strong>：频繁修改和删除操作会增加碎片</li><li><strong>数据大小分布</strong>：大小差异大的数据混合存储更容易产生碎片</li></ul><p><strong>内存碎片的解决</strong>：</p><ul><li>重启 Redis（会丢失数据）</li><li>使用 <code>MEMORY PURGE</code> 命令（需要特定分配器支持）</li><li>配置合理的 maxmemory 和淘汰策略</li><li>对于高碎片环境，可考虑使用 Redis 4.0+ 的主动碎片整理功能</li></ul><h2 id="redis-持久化" tabindex="-1"><a class="header-anchor" href="#redis-持久化"><span>Redis 持久化</span></a></h2><h3 id="【中等】redis-支持哪些持久化方式-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-支持哪些持久化方式-⭐⭐⭐"><span>【中等】Redis 支持哪些持久化方式？⭐⭐⭐</span></a></h3><p>为了追求性能，Redis 的读写都是在内存中完成的。一旦重启，内存中的数据就会清空，为了保证数据不丢失，Redis 支持持久化机制。</p><p>Redis 有三种持久化方式</p><ul><li>RDB 快照</li><li>AOF 日志</li><li>混合持久化</li></ul><div class="hint-container info"><p class="hint-container-title">RDB</p></div><blockquote><ul><li>RDB 的实现原理是什么？</li><li>生成 RDB 快照时，Redis 可以响应请求吗？</li></ul></blockquote><p>有两个 Redis 命令可以用于生成 RDB 文件：<a href="https://redis.io/commands/save" target="_blank" rel="noopener noreferrer"><strong><code>SAVE</code></strong></a> 和 <a href="https://redis.io/commands/bgsave" target="_blank" rel="noopener noreferrer"><strong><code>BGSAVE</code></strong></a>。</p><p><a href="https://redis.io/commands/save" target="_blank" rel="noopener noreferrer"><strong><code>SAVE</code></strong></a> 命令由服务器进程直接执行保存操作，直到 RDB 创建完成为止。所以<strong>该命令“会阻塞”服务器</strong>，在阻塞期间，服务器不能响应任何命令请求。</p><p><a href="https://redis.io/commands/bgsave" target="_blank" rel="noopener noreferrer"><strong><code>BGSAVE</code></strong></a> 命令会<strong>派生</strong>（fork）一个子进程，由子进程负责创建 RDB 文件，服务器进程继续处理命令请求，所以<strong>该命令“不会阻塞”服务器</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272238061.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><blockquote><p>🔔 <strong>【注意】</strong></p><p><code>BGSAVE</code> 命令的实现采用的是写时复制技术（Copy-On-Write，缩写为 CoW）。</p><p><code>BGSAVE</code> 命令执行期间，<code>SAVE</code>、<code>BGSAVE</code>、<code>BGREWRITEAOF</code> 三个命令会被拒绝，以免与当前的 <code>BGSAVE</code> 操作产生竞态条件，降低性能。</p></blockquote><div class="hint-container info"><p class="hint-container-title">AOF</p></div><blockquote><ul><li>AOF 的实现原理是什么？</li><li>为什么先执行命令，再把数据写入日志呢？</li></ul></blockquote><p><strong>Redis 命令请求会先保存到 AOF 缓冲区，再定期写入并同步到 AOF 文件</strong>。</p><p>AOF 的实现可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤。</p><ul><li><strong>命令追加</strong>：当 Redis 服务器开启 AOF 功能时，服务器在执行完一个写命令后，会以 Redis 命令协议格式将被执行的写命令追加到 AOF 缓冲区的末尾。</li><li><strong>文件写入</strong>和<strong>文件同步</strong><ul><li>Redis 的服务器进程就是一个事件循环，这个循环中的文件事件负责接收客户端的命令请求，以及向客户端发送命令回复。而时间事件则负责执行想 <code>serverCron</code> 这样的定时运行的函数。</li><li>因为服务器在处理文件事件时可能会执行写命令，这些写命令会被追加到 AOF 缓冲区，服务器每次结束事件循环前，都会根据 <code>appendfsync</code> 选项来判断 AOF 缓冲区内容是否需要写入和同步到 AOF 文件中。</li></ul></li></ul><p>先执行命令，再把数据写入 AOF 日志有两个好处：</p><ul><li><strong>避免额外的检查开销</strong></li><li><strong>不会阻塞当前写操作命令的执行</strong></li></ul><p>当然，这样做也会有弊端：</p><ul><li><strong>数据可能会丢失：</strong></li><li><strong>可能阻塞其他操作：</strong></li></ul><p><strong>Redis 命令请求会先保存到 AOF 缓冲区，再定期写入并同步到 AOF 文件</strong>。</p><p><code>appendfsync</code> 不同选项决定了不同的持久化行为：</p><ul><li><strong><code>always</code></strong>：将 AOF 缓冲区中所有内容写入并同步到 AOF 文件。这种方式是最数据最安全的，但也是性能最差的。</li><li><strong><code>no</code></strong>：将 AOF 缓冲区所有内容写入到 AOF 文件，但并不对 AOF 文件进行同步，何时同步由操作系统决定。这种方式是数据最不安全的，一旦出现故障，未来得及同步的所有数据都会丢失。</li><li><strong><code>everysec</code></strong>：<code>appendfsync</code> 默认选项。将 AOF 缓冲区所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟，那么再次对 AOF 文件进行同步，这个同步操作是有一个线程专门负责执行的。这张方式是前面两种的这种方案——性能足够好，且即使出现故障，仅丢失一秒钟内的数据。</li></ul><p><code>appendfsync</code> 选项的不同值对 AOF 持久化功能的安全性、以及 Redis 服务器的性能有很大的影响。</p><div class="hint-container info"><p class="hint-container-title">混合持久化</p></div><p>Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p><p><strong>混合持久化的工作机制</strong></p><ul><li><strong>触发时机</strong>：在 AOF 重写过程中启用。</li><li><strong>执行流程</strong>： <ol><li><strong>子进程</strong>将共享内存数据以 <strong>RDB 格式</strong>写入 AOF 文件（全量数据）。</li><li><strong>主线程</strong>将操作命令记录到重写缓冲区，再以 <strong>AOF 格式</strong>追加到 AOF 文件（增量数据）。</li><li>替换旧 AOF 文件，新文件包含 <strong>RDB（前半部分） + AOF（后半部分）</strong>。</li></ol></li></ul><p><strong>混合持久化的优点</strong></p><ul><li><strong>重启速度快</strong>：优先加载 RDB 部分（全量数据恢复快）。</li><li><strong>数据丢失少</strong>：后续加载 AOF 部分（增量数据补充）。</li></ul><p><strong>混合持久化的缺点</strong></p><ul><li><strong>可读性差</strong>：AOF 文件包含二进制 RDB 数据，不易阅读。</li><li><strong>兼容性差</strong>：仅支持 Redis 4.0+ 版本，旧版本无法识别。</li></ul><h3 id="【中等】aof-的重写机制是怎样的-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】aof-的重写机制是怎样的-⭐⭐⭐"><span>【中等】AOF 的重写机制是怎样的？⭐⭐⭐</span></a></h3><ul><li>AOF 日志过大时，怎么办？</li><li>AOF 重写流程是怎样的？</li><li>AOF 重写时，可以处理请求吗？</li></ul><p><strong>知识点</strong></p><p>当 AOF 日志过大时，恢复过程就会很久。为了避免此问题，Redis 提供了 AOF 重写机制，即 AOF 日志大小超过所设阈值后，启动 AOF 重写，压缩 AOF 文件。</p><p>AOF 重写机制是，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到新的 AOF 日志中，等到全部记录完成后，就使用新的 AOF 日志替换现有的 AOF 日志。</p><p>作为一种辅助性功能，显然 Redis 并不想在 AOF 重写时阻塞 Redis 服务接收其他命令。因此，Redis 决定通过 <code>BGREWRITEAOF</code> 命令创建一个子进程，然后由子进程负责对 AOF 文件进行重写，这与 <code>BGSAVE</code> 原理类似。</p><ul><li>在执行 <code>BGREWRITEAOF</code> 命令时，Redis 服务器会维护一个 AOF 重写缓冲区。当 AOF 重写子进程开始工作后，Redis 每执行完一个写命令，会同时将这个命令发送给 AOF 缓冲区和 AOF 重写缓冲区。</li><li>由于彼此不是在同一个进程中工作，AOF 重写不影响 AOF 写入和同步。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。</li><li>最后，服务器用新的 AOF 文件替换就的 AOF 文件，以此来完成 AOF 重写操作。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272248959.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="redis-批处理" tabindex="-1"><a class="header-anchor" href="#redis-批处理"><span>Redis 批处理</span></a></h2><h3 id="【中等】redis-支持事务吗-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-支持事务吗-⭐⭐"><span>【中等】Redis 支持事务吗？⭐⭐</span></a></h3><div class="hint-container info"><p class="hint-container-title">Redis 支持事务吗？</p></div><p>Redis 支持非严格的事务，其事务不支持回滚。<a href="https://redis.io/commands/multi" target="_blank" rel="noopener noreferrer"><code>MULTI</code></a>、<a href="https://redis.io/commands/exec" target="_blank" rel="noopener noreferrer"><code>EXEC</code></a>、<a href="https://redis.io/commands/discard" target="_blank" rel="noopener noreferrer"><code>DISCARD</code></a> 和 <a href="https://redis.io/commands/watch" target="_blank" rel="noopener noreferrer"><code>WATCH</code></a> 是 Redis 事务相关的命令。</p><p><strong><a href="https://redis.io/commands/multi" target="_blank" rel="noopener noreferrer"><code>MULTI</code></a> 命令用于开启一个事务，它总是返回 OK。</strong><code>MULTI</code> 执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当 EXEC 命令被调用时，所有队列中的命令才会被执行。</p><p><strong><a href="https://redis.io/commands/exec" target="_blank" rel="noopener noreferrer"><code>EXEC</code></a> 命令负责触发并执行事务中的所有命令。</strong></p><ul><li>如果客户端在使用 <code>MULTI</code> 开启了一个事务之后，却因为断线而没有成功执行 <code>EXEC</code> ，那么事务中的所有命令都不会被执行。</li><li>另一方面，如果客户端成功在开启事务之后执行 <code>EXEC</code> ，那么事务中的所有命令都会被执行。</li></ul><p><strong>当执行 <a href="https://redis.io/commands/discard" target="_blank" rel="noopener noreferrer"><code>DISCARD</code></a> 命令时，事务会被放弃，事务队列会被清空，并且客户端会从事务状态中退出。</strong></p><p><strong><a href="https://redis.io/commands/watch" target="_blank" rel="noopener noreferrer"><code>WATCH</code></a> 命令可以为 Redis 事务提供 check-and-set （CAS）行为</strong>。被 <code>WATCH</code> 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 <code>EXEC</code> 执行之前被修改了，那么整个事务都会被取消，<code>EXEC</code> 返回 <code>nil-reply</code> 来表示事务已经失败。</p><p><code>WATCH</code> 可以用于创建 Redis 没有内置的原子操作。</p><p>举个例子，以下代码实现了原创的 <code>ZPOP</code> 命令，它可以原子地弹出有序集合中分值（<code>score</code>）最小的元素：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">WATCH</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> zset</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">element</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> =</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ZRANGE</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> zset</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">MULTI</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">ZREM</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> zset</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> element</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">EXEC</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container info"><p class="hint-container-title">Redis 事务是严格意义的事务吗？</p></div><p>ACID 是数据库事务正确执行的四个基本要素。</p><ul><li><strong>原子性（Atomicity）</strong><ul><li>事务被视为不可分割的最小单元，事务中的所有操作<strong>要么全部提交成功，要么全部失败回滚</strong>。</li><li>回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。</li></ul></li><li><strong>一致性（Consistency）</strong><ul><li>数据库在事务执行前后都保持一致性状态。</li><li>在一致性状态下，所有事务对一个数据的读取结果都是相同的。</li></ul></li><li><strong>隔离性（Isolation）</strong><ul><li>一个事务所做的修改在最终提交以前，对其它事务是不可见的。</li></ul></li><li><strong>持久性（Durability）</strong><ul><li>一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。</li><li>可以通过数据库备份和恢复来实现，在系统发生奔溃时，使用备份的数据库进行数据恢复。</li></ul></li></ul><p><strong>一个支持事务（Transaction）中的数据库系统，必需要具有这四种特性，否则在事务过程（Transaction processing）当中无法保证数据的正确性。</strong></p><p><strong>Redis 仅支持“非严格”的事务</strong>。所谓“非严格”是指：</p><ul><li><strong>Redis 事务保证全部执行命令</strong>：Redis 事务中的多个命令会被打包到事务队列中，然后按先进先出（FIFO）的顺序执行。事务在执行过程中不会被中断，当事务队列中的所有命令都被执行完毕之后，事务才会结束。</li><li><strong>Redis 事务不支持回滚</strong>：如果命令执行失败不会回滚，而是会继续执行下去。</li></ul><p>Redis 官方的 <a href="https://redis.io/docs/interact/transactions/" target="_blank" rel="noopener noreferrer">事务特性文档</a> 给出的不支持回滚的理由是：</p><ul><li>Redis 命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面。</li><li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。</li></ul><h3 id="【中等】redis-pipeline-能保证原子性吗-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-pipeline-能保证原子性吗-⭐⭐"><span>【中等】Redis Pipeline 能保证原子性吗？⭐⭐</span></a></h3><p>先说结论：<strong>Redis Pipeline 不保证原子性</strong>。</p><p>Redis Pipeline（管道）是一种<strong>客户端技术</strong>，用于将多个 Redis 命令批量发送到服务器，减少网络往返时间（RTT），提高吞吐量。</p><ul><li><strong>传统模式</strong>：客户端发送一条命令 → 等待响应 → 再发送下一条（高延迟）。</li><li><strong>Pipeline 模式</strong>：客户端一次性发送多条命令 → 服务器按顺序执行 → 一次性返回所有结果（低延迟）。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272224006.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>核心特性</strong></p><table><thead><tr><th style="text-align:left;"><strong>特性</strong></th><th style="text-align:left;"><strong>说明</strong></th></tr></thead><tbody><tr><td style="text-align:left;"><strong>批量发送</strong></td><td style="text-align:left;">客户端打包多条命令，一次性发送，减少网络开销</td></tr><tr><td style="text-align:left;"><strong>非原子性</strong></td><td style="text-align:left;">Pipeline 只是批量发送，不保证所有命令连续执行（可能被其他客户端命令打断）</td></tr><tr><td style="text-align:left;"><strong>高性能</strong></td><td style="text-align:left;">相比单条命令模式，吞吐量可提升 5~10 倍</td></tr><tr><td style="text-align:left;"><strong>无回滚</strong></td><td style="text-align:left;">如果某条命令失败，不会影响其他命令的执行</td></tr></tbody></table><p><strong>注意事项</strong></p><ul><li><strong>命令数量控制</strong>：避免单次 Pipeline 发送过多命令（建议每批 ≤ 1 万条），否则可能阻塞 Redis。</li><li><strong>集群模式限制</strong>：Redis Cluster 要求 Pipeline 的所有 Key 必须在<strong>同一个 Slot</strong>（可用 <code>{hash_tag}</code> 确保，如 <code>user:{123}:name</code>）。</li><li><strong>错误处理</strong>：Pipeline 返回的是一个列表，需逐条检查命令是否成功。</li><li><strong>与事务的区别</strong>：Pipeline 不保证原子性。</li></ul><p><strong>适用场景</strong></p><p>✔️ <strong>适合</strong>：</p><ul><li>批量写入（如日志上报、缓存预热）</li><li>批量查询（如获取多个 Key 的值）</li><li>对原子性无要求的高并发场景</li></ul><p>❌ <strong>不适合</strong>：</p><ul><li>需要事务保证原子性的操作（改用 <code>MULTI/EXEC</code>）</li><li>命令之间有依赖关系（如后一条命令依赖前一条的结果）</li></ul><h3 id="【中等】redis-lua-脚本有什么用-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-lua-脚本有什么用-⭐⭐"><span>【中等】Redis Lua 脚本有什么用？⭐⭐</span></a></h3><p>Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。Redis 的 Lua 脚本提供了一种<strong>原子性执行多个命令</strong>的方式。也就是说，一段 <strong>Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行</strong>，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。</p><p>并且，Lua 脚本中支持一些简单的逻辑处理比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。</p><p>不过， Lua 脚本依然存在下面这些缺陷：</p><ul><li><strong>如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销</strong>，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。</li><li><strong>Redis Cluster 下 Lua 脚本的原子操作也无法保证</strong>，原因同样是无法保证所有的 key 都在同一个 hash slot（哈希槽）上。</li></ul><p>另外，Redis 7.0 新增了 <a href="https://redis.io/docs/manual/programmability/functions-intro/" target="_blank" rel="noopener noreferrer">Redis functions</a> 特性，你可以将 Redis functions 看作是比 Lua 更强大的脚本。</p><h2 id="redis-高可用" tabindex="-1"><a class="header-anchor" href="#redis-高可用"><span>Redis 高可用</span></a></h2><h3 id="【中等】redis-如何实现主从复制-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-如何实现主从复制-⭐⭐⭐"><span>【中等】Redis 如何实现主从复制？⭐⭐⭐</span></a></h3><blockquote><ul><li>Redis 复制的工作原理？Redis 旧版复制和新版复制有何不同？</li><li>Redis 主从节点间如何复制数据？</li><li>Redis 的数据一致性是强一致性吗？</li></ul></blockquote><p>Redis 的主从复制过程主要分为<strong>建立连接、数据同步、命令传播</strong>三个阶段。</p><div class="hint-container info"><p class="hint-container-title">建立连接</p></div><p>通过 <code>SLAVEOF</code> 命令或 <code>slaveof</code> 选项，建立两个节点的主从关系。</p><ul><li>从节点启动后，会向主节点发送一个 <code>PSYNC</code> 命令，请求同步数据。</li><li><code>PSYNC</code> 命令格式为：<code>PSYNC runid（运行 ID） offset（复制偏移量）</code></li></ul><div class="hint-container info"><p class="hint-container-title">数据同步</p></div><p>主节点根据从节点发送的信息，决定进行<strong>完整重同步</strong>还是<strong>部分重同步</strong>。</p><p><strong>完整重同步（full resychronization）</strong></p><ol><li>从节点第一次复制主节点时，发送 <code>PSYNC ? -1</code> 给主节点</li><li>主节点执行 <code>BGSAVE</code> 命令，在<strong>后台生成一个 RDB 快照文件</strong>。</li><li>在生成 RDB 文件期间，主节点会将新的写命令记录到<strong>复制缓冲区（Replication Buffer）</strong> 中。</li><li>RDB 文件生成后，主节点将其发送给从节点。</li><li>从节点<strong>清空旧数据</strong>，然后加载这个 RDB 文件到内存，将自身状态更新至主节点执行 <code>BGSAVE</code> 时的状态。</li><li>主节点再将<strong>复制缓冲区</strong>中记录的写命令发送给从节点，从节点执行这些命令，最终达到与主节点一致的状态。</li></ol><p><strong>部分重同步（partial resychronization）</strong></p><ul><li><strong>触发条件</strong>：从节点断线重连后，如果它之前复制的主节点 <code>runid</code> 未变，并且其 <code>offset</code> 之后的数据仍然存在于主节点的<strong>复制积压缓冲区（Replication Backlog）</strong> 中。</li><li><strong>过程</strong>：主节点只需要将复制积压缓冲区里从 <code>offset</code> 之后的数据发送给从节点即可。</li></ul><div class="hint-container info"><p class="hint-container-title">命令传播</p></div><p>完成同步后，复制进入<strong>命令传播阶段</strong>。</p><ul><li>主节点将自己执行的<strong>每一条写命令</strong>，都异步地发送给所有从节点。</li><li>从节点接收并执行这些命令，从而保证主从数据的<strong>最终一致性</strong>。</li></ul><h3 id="【中等】redis-哨兵是如何工作的-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-哨兵是如何工作的-⭐⭐⭐"><span>【中等】Redis 哨兵是如何工作的？⭐⭐⭐</span></a></h3><blockquote><ul><li>Redis 哨兵的功能？</li><li>Redis 哨兵的原理？</li><li>Redis 哨兵如何选举 Leader？</li><li>Redis 如何实现故障转移？</li></ul></blockquote><p><strong>Redis 哨兵（Sentinel）<strong>是一个</strong>高可用性（High Availability）解决方案</strong>，用于管理 Redis 主从架构。它是一个<strong>独立的分布式进程</strong>，通过一系列心跳检测和投票机制，<strong>自动完成故障发现（Failure Detection）和故障转移（Failover）</strong>，从而实现服务的无人值守不间断运行。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503282134261.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Redis 哨兵主要有三个功能：监控、故障转移、通知</p><div class="hint-container info"><p class="hint-container-title">监控</p></div><p>Redis 哨兵每十秒一次发送 <code>INFO</code>，获取所有主从服务器信息。</p><p>此外，Redis 哨兵通过心跳 <code>PING</code> 探测节点是否下线。</p><ul><li><strong>主观下线</strong>：每秒一次，向所知的所有节点发送 <code>PING</code>；超时未响应的节点会被判定为主观下线。</li><li><strong>客观下线</strong>：<strong>只有主节点才有客观下线</strong>。哨兵向其他哨兵发起确认：是否认同该主节点下线。如果 quorum 数的哨兵判断主节点下线，则视为客观下线。</li></ul><div class="hint-container info"><p class="hint-container-title">故障转移</p></div><p><strong>主节点客观下线后，哨兵集群通过 Raft 算法选举一个哨兵 Leader，由哨兵 Leader 负责该主节点的故障转移</strong>。</p><p>每个哨兵优先投票给最先发起投票请求的节点，得票超过半数的哨兵成为 Leader。</p><p>故障转移流程如下：</p><ul><li>排除下线从节点</li><li>排除和哨兵、主节点断连的从节点</li><li>根据优先级、复制偏移量、运行 ID 排序，从中选出主节点</li><li>将其余从节点从属于新主节点</li><li>当旧主节点恢复，将其从属于新主节点</li></ul><div class="hint-container info"><p class="hint-container-title">通知</p></div><p>故障转移完成后，哨兵 Leader 会通知其余从节点认主。</p><p>此外，哨兵 Leader 向所有从服务器发送 <code>SLAVEOF</code> 命令，让它们去复制新的主服务器。</p><div class="hint-container info"><p class="hint-container-title">脑裂</p></div><p><strong>脑裂</strong>是指：在分布式系统中，因网络分区导致集群中同时存在多个主节点，这些主节点都可能接收写请求，造成数据不一致。</p><p>Redis 哨兵应对脑裂，有以下措施：</p><ul><li><strong>通过多数派原则判定下线（主观下线 + 客观下线）</strong><ul><li>主节点故障需多数哨兵确认（超过半数）</li><li>防止因单个哨兵误判或网络抖动触发故障转移</li></ul></li><li><strong>通过多数派原则选举哨兵 Leader</strong><ul><li>哨兵节点数应为奇数</li><li>quorum 大于集群半数</li></ul></li><li><strong>故障转移集中式管理</strong><ul><li>故障转移由唯一领导者哨兵执行</li><li>确保同一时间只有一个哨兵执行切换，避免多个哨兵同时提升不同从节点</li></ul></li><li><strong>旧主强制降级</strong><ul><li>故障转移后，哨兵 Leader 将旧的主服务器标记为从服务器。当旧的主服务器重新上线，Sentinel 会向它发送 <code>SLAVEOF</code> 命令，让其成为从服务器。</li><li>即使旧主节点恢复，也会被降级为从节点，无法继续接收写请求</li></ul></li><li><strong>客户端重定向</strong><ul><li>客户端仅信任哨兵集群提供的主节点地址</li><li>客户端不会同时连接两个“主节点”，自动切换到新主</li></ul></li><li><strong>写入保护</strong><ul><li>主节在失去所有从节点或从节点延迟过高时拒绝写入</li><li>少数派分区的主节点 → 自动拒绝写入</li><li>多数派分区的主节点正常服务 → 从节点提升为新主继续写入</li><li>客户端写入失败，但数据一致性得到保障</li><li>相关配置：min-slaves-to-write（最小从节点数）、min-slaves-max-lag（从节点复制延迟）</li></ul></li></ul><h3 id="【中等】redis-集群是如何工作的-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-集群是如何工作的-⭐⭐⭐"><span>【中等】Redis 集群是如何工作的？⭐⭐⭐</span></a></h3><p><strong><a href="https://redis.io/topics/cluster-tutorial" target="_blank" rel="noopener noreferrer">Redis 集群（Redis Cluster）</a> 是 Redis 官方提供的分布式方案</strong>。</p><p>Redis Cluster 既然被设计分布式系统，自然需要具备分布式系统的基本特性：伸缩性、高可用、一致性。</p><ul><li><strong>伸缩性</strong> - Redis Cluster 通过划分虚拟 hash 槽来进行“分区”，以实现集群的伸缩性。</li><li><strong>高可用</strong> - Redis Cluster 采用主从架构，支持“复制”和“自动故障转移”，以保证 Redis Cluster 的高可用。</li><li><strong>一致性</strong> - 根据 CAP 理论，Consistency、Availability、Partition tolerance 三者不可兼得。而 Redis Cluster 的选择是 AP，即不保证“强一致性”，尽力达到“最终一致性”。</li></ul><p>Redis Cluster 应用了 <a href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf" target="_blank" rel="noopener noreferrer">Raft 协议</a> 协议和 Gossip 协议。</p><p><strong>Redis Cluster = 虚拟哈希槽分区（数据分布） + 主从复制（数据冗余） + Raft 式故障转移（高可用） + 多数派防脑裂（一致性）</strong></p><div class="hint-container info"><p class="hint-container-title">集群架构</p></div><p>Redis Cluster 节点分为主节点（master）和从节点（slave）：</p><ul><li>主节点用于处理槽。</li><li>从节点用于复制主节点。</li></ul><p>Redis 集群中每个节点会保存集群的完整拓扑信息，包括每个节点的 ID、IP、端口、负责的哈希槽范围。</p><p><strong>节点间使用 Gossip 协议 (<code>PING</code> / <code>PONG</code> 消息）相互通信</strong>。</p><div class="hint-container info"><p class="hint-container-title">虚拟哈希槽分区</p></div><p><strong>虚拟哈希槽分区规则</strong></p><p><strong>Redis Cluster 将整个数据库规划为 “16384” 个虚拟的哈希槽</strong>，数据库中的每个键都属于其中一个槽。<strong>每个节点都会记录哪些槽指派给了自己， 而哪些槽又被指派给了其他节点</strong>。</p><p><strong>如果数据库中有任何一个槽没有得到分配，那么集群处于“下线”状态</strong>。</p><p>通过向节点发送 <a href="https://redis.io/commands/cluster-addslots" target="_blank" rel="noopener noreferrer"><code>CLUSTER ADDSLOTS</code></a> 命令，可以将一个或多个槽指派给节点负责。</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; CLUSTER ADDSLOTS 1 2 3</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">OK</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>集群中的每个节点负责一部分哈希槽，比如集群中有３个节点，则：</p><ul><li>节点Ａ存储的哈希槽范围是：0 – 5500</li><li>节点Ｂ存储的哈希槽范围是：5501 – 11000</li><li>节点Ｃ存储的哈希槽范围是：11001 – 16384</li></ul><p><strong>重分区</strong></p><p>对 Redis Cluster 的重新分片工作是由客户端（redis-trib）执行的， <strong>重新分片的关键是将属于某个槽的所有键值对从一个节点转移至另一个节点</strong>。</p><p>重新分区操作可以“<strong>在线</strong>”进行，在重新分区的过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求。</p><p>重新分区的实现原理如下图所示：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-cluster-trib.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><div class="hint-container info"><p class="hint-container-title">重定向</p></div><p><strong>路由（计算哈希槽）</strong></p><p>决定一个 key 应该分配到那个槽的算法是：<strong>计算该 key 的 CRC16 结果再模 16834</strong>。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>HASH_SLOT = CRC16(KEY) mod 16384</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>MOVED 错误重定向（永久重定向）</strong></p><p>当客户端向节点发送与数据库键有关的命令时，接受命令的节点会<strong>计算出命令要处理的数据库属于哪个槽</strong>，并<strong>检查这个槽是否指派给了自己</strong>：</p><ul><li>如果键所在的槽正好指派给了当前节点，那么当前节点直接执行命令。</li><li>如果键所在的槽没有指派给当前节点，那么节点会向客户端返回一个 <strong><code>MOVED</code> 错误</strong>，指引客户端重定向至正确的节点。</li></ul><p><strong>ASK 错误重定向（临时重定向，迁移过程中使用）</strong></p><p>如果节点 A 正在迁移槽 <code>i</code> 至节点 B ， 那么当节点 A 没能在自己的数据库中找到命令指定的数据库键时， 节点 A 会向客户端返回一个 <code>ASK</code> 错误， 指引客户端到节点 B 继续查找指定的数据库键。</p><p><code>ASK</code> 错误与 <code>MOVED</code> 的区别在于：</p><ul><li><code>MOVED</code> 错误表示槽的负责权已经从一个节点转移到了另一个节点；</li><li>而 <code>ASK</code> 错误只是两个节点在迁移槽的过程中使用的一种临时措施。</li></ul><p>判断 ASK 错误的过程如下图所示：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-ask.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><div class="hint-container info"><p class="hint-container-title">故障转移</p></div><p><strong>故障检测</strong></p><p><strong>集群中每个节点都会定期向集群中的其他节点发送 <code>PING</code> 消息，以此来检测对方是否在线</strong>。</p><p>节点的状态信息可以分为：</p><ul><li>在线状态；</li><li>疑似下线状态（<code>PFAIL</code>） - 即在规定的时间内，没有应答 <code>PING</code> 消息</li><li>已下线状态（<code>FAIL</code>） - 半数以上负责处理槽的主节点都将某个主节点视为“疑似下线”，则这个主节点将被标记为“已下线”</li></ul><p><strong>故障转移</strong></p><ol><li>下线主节点的所有从节点中，会有一个从节点被选中。</li><li>被选中的从节点会执行 <code>SLAVEOF no one</code> 命令，成为新的主节点。</li><li>新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己。</li><li>新的主节点向集群广播一条 <code>PONG</code> 消息，告知其他节点这个从节点已变成主节点。</li><li>新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。</li></ol><p><strong>选主</strong></p><blockquote><p>Redis Sentinel 和 Redis Cluster 的选主流程非常相似，二者都基于 <a href="https://ramcloud.atlassian.net/wiki/download/attachments/6586375/raft.pdf" target="_blank" rel="noopener noreferrer">Raft 协议</a> 实现。</p></blockquote><ol><li>从节点发现自己的主节点状态为 <code>FAIL</code>。</li><li>从节点将自己记录的纪元（<code>epoch</code>）加 1，并广播消息，要求所有收到消息且有投票权的主节点都为自己投票。——这里的纪元（<code>epoch</code>），相当于 Raft 协议中的选期（<code>term</code>）。因个人习惯，后面统一将纪元描述为选期。</li><li>如果某主节点具有投票权（它正在负责处理槽），并且这个主节点尚未投票，那么主节点就返回一条确认消息，表示支持该从节点成为新的主节点。</li><li>每个参与选举的从节点都会根据收到的确认消息，统计自己所得的选票。</li><li>假设集群中存在 N 个具有投票权的主节点，那么<strong>当某从节点得到“半数以上”（<code>N / 2 + 1</code>）的选票，则该从节点当选为新的主节点</strong>。</li><li>由于每个选期中，任意具有投票权的主节点“只能投一票”，所以获得“半数以上”选票的从节点只能有一个。</li><li>如果在一个选期中，没有从节点能获得“半数以上”投票，则本次选期作废，开始进入下一个选期，直到选出新的主节点为止。</li></ol><div class="hint-container info"><p class="hint-container-title">Redis 集群功能限制</p></div><p>Redis Cluster 相对 <strong>单机</strong>，存在一些功能限制，需要 <strong>开发人员</strong> 提前了解，在使用时做好规避。</p><ul><li><code>key</code> <strong>批量操作</strong> 支持有限：类似 <code>mset</code>、<code>mget</code> 操作，目前只支持对具有相同 <code>slot</code> 值的 <code>key</code> 执行 <strong>批量操作</strong>。对于 <strong>映射为不同</strong> <code>slot</code> 值的 <code>key</code> 由于执行 <code>mget</code>、<code>mget</code> 等操作可能存在于多个节点上，因此不被支持。</li><li><code>key</code> <strong>事务操作</strong> 支持有限：只支持 <strong>多</strong> <code>key</code> 在 <strong>同一节点上</strong> 的 <strong>事务操作</strong>，当多个 <code>key</code> 分布在 <strong>不同</strong> 的节点上时 <strong>无法</strong> 使用事务功能。</li><li><code>key</code> 作为 <strong>数据分区</strong> 的最小粒度，不能将一个 <strong>大的键值</strong> 对象如 <code>hash</code>、<code>list</code> 等映射到 <strong>不同的节点</strong>。</li><li>不支持 <strong>多数据库空间</strong>：<strong>单机</strong> 下的 Redis 可以支持 <code>16</code> 个数据库（<code>db0 ~ db15</code>），<strong>集群模式</strong> 下只能使用 <strong>一个</strong> 数据库空间，即 <code>db0</code>。</li><li><strong>复制结构</strong> 只支持一层：<strong>从节点</strong> 只能复制 <strong>主节点</strong>，不支持 <strong>嵌套树状复制</strong> 结构。</li></ul><div class="hint-container info"><p class="hint-container-title">Redis 集群规模限制</p></div><p><strong>Redis Cluster 非常适合构建中小规模 Redis 集群</strong>，这里的中小规模指的是，大概几个到几十个节点这样规模的 Redis 集群。</p><p>但是 Redis Cluster 不太适合构建超大规模集群，主要原因是，它采用了去中心化的设计。</p><p>Redis 的每个节点上，都保存了所有槽和节点的映射关系表，客户端可以访问任意一个节点，再通过重定向命令，找到数据所在的那个节点。那么，这个映射关系表是如何更新的呢？Redis Cluster 采用了一种去中心化的流言 (Gossip) 协议来传播集群配置的变化。</p><p>Gossip 协议的优点是去中心化；缺点是传播速度慢，并且是集群规模越大，传播的越慢。</p><ul><li>适合中小规模集群（几个到几十个节点）</li><li>Gossip 协议在大规模集群中传播效率低</li></ul><h3 id="【困难】redis-中的脑裂问题是如何产生的-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【困难】redis-中的脑裂问题是如何产生的-⭐⭐"><span>【困难】Redis 中的脑裂问题是如何产生的？⭐⭐</span></a></h3><p>Redis 脑裂问题是指因网络分区导致集群中同时存在两个主节点，网络恢复后旧主节点降级为从节点并进行全量数据同步，造成客户端在此期间写入旧主的数据丢失。</p><p><strong>产生过程：</strong></p><ol><li>主节点与从节点网络中断，但与客户端连接正常</li><li>客户端继续向旧主节点写入数据（无法同步到从节点）</li><li>哨兵/集群模式下，选举出新主节点，形成双主局面</li><li>网络恢复后，旧主节点被降级为从节点</li><li>旧主节点清空数据与新主进行全量同步，导致期间写入的数据丢失</li></ol><p><strong>核心原因：</strong></p><ul><li>网络分区导致集群分裂</li><li>异步复制机制的数据延迟</li><li>故障切换期间客户端仍可向旧主写入数据</li><li>数据同步机制中从节点会清空旧数据</li></ul><p><strong>解决方案</strong>：通过合理配置（如 min-replicas-to-write 等参数）限制主节点在连接足够多从节点时才可写入，防止脑裂期间数据不一致。</p><h3 id="【困难】如何解决-redis-中的脑裂问题-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【困难】如何解决-redis-中的脑裂问题-⭐⭐"><span>【困难】如何解决 Redis 中的脑裂问题？⭐⭐</span></a></h3><p>Redis 解决脑裂的思路： 通过配置限制主节点的写操作条件，防止在网络分区期间客户端向即将失效的旧主节点写入数据，从而避免数据丢失。</p><p><strong>Redis 避免脑裂机制</strong></p><ul><li><code>min-replicas-to-write</code>：主节点在至少有指定数量的从节点确认写操作的情况下才执行写操作。通常，这个值设为集群的半数以上。</li><li><code>min-replicas-max-lag</code>：主从复制延迟（单位为秒），如果从节点的延迟超过配置值，不会被计入 <code>min-replicas-to-write</code> 统计。</li></ul><p><strong>Redis 能完全避免脑裂吗？</strong></p><p>并不能。假设在极限条件下，某主节点发生临时故障，哨兵判断其下线，开始发起选举。选举进行中，主节点恢复，此时它还有半数以上的从节点，仍能持续写入。当哨兵选举完毕，并选出新的主节点，旧主节点需要被强制认主新主节点，其在选举过程中写入的数据会被覆盖，导致了数据不一致。</p><h2 id="redis-架构" tabindex="-1"><a class="header-anchor" href="#redis-架构"><span>Redis 架构</span></a></h2><h3 id="【中等】redis-为什么快-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-为什么快-⭐⭐"><span>【中等】Redis 为什么快？⭐⭐</span></a></h3><p>根据 <a href="https://redis.io/docs/management/optimization/benchmarks/" target="_blank" rel="noopener noreferrer">Redis 官方 Benchmark</a> 文档的描述，Redis 单机 QPS 能达到 10w+，将近是 Mysql 的 10 倍。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503270821660.png" alt="Redis 官方 Benchmark QPS 图" tabindex="0" loading="lazy"><figcaption>Redis 官方 Benchmark QPS 图</figcaption></figure><p>Redis 是单线程模型（Redis 6.0 已经支持多线程模型），为什么还能有这么高的并发？</p><ul><li><strong>Redis 读写基于内存</strong></li><li><strong>IO 多路复用</strong> + <strong>读写单线程模型</strong><ul><li>IO 多路复用是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。</li><li>单线程模型避免了由于并发而产生的线程切换、锁竞争等开销。</li><li>由于，Redis 读写基于内存，性能很高，所以 CPU 并不是制约 Redis 性能表现的瓶颈所在。更多情况下是受到内存大小和网络 I/O 的限制，所以 Redis 核心网络模型使用单线程并没有什么问题。</li></ul></li><li><strong>高效的数据结构</strong></li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272229177.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>图来自 <a href="https://blog.bytebytego.com/p/why-is-redis-so-fast" target="_blank" rel="noopener noreferrer">Why is redis so fast?</a></p><blockquote><p><strong>扩展</strong>：<a href="https://www.youtube.com/shorts/x8lcdDbKZto" target="_blank" rel="noopener noreferrer">【视频】Why is Redis so FAST</a></p></blockquote><h3 id="【中等】redis-单线程模式是怎样的-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】redis-单线程模式是怎样的-⭐⭐"><span>【中等】Redis 单线程模式是怎样的？⭐⭐</span></a></h3><p>Redis 单线程模式指的是其核心网络模型为单线程模式。这个模式为 IO 多路复用+单线程读写请求，其中，IO 多路复用使得 Redis 可以同时处理多个客户端连接。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309241133046.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><blockquote><p>Redis 真的只有单线程吗？</p></blockquote><p>Redis 并非真的只有单线。</p><ul><li>Redis 的主要工作包括接收客户端请求、解析请求和进行数据读写等操作，是由单线程来执行的，这也是常说 Redis 是单线程程序的原因。</li><li>Redis 还启动了 3 个线程来执行<strong>文件关闭</strong>、<strong>AOF 同步写</strong>和<strong>惰性删除</strong>等操作。</li><li>此外，Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）。</li></ul><h3 id="【中等】redis-6-0-之后为什么引入了多线程" tabindex="-1"><a class="header-anchor" href="#【中等】redis-6-0-之后为什么引入了多线程"><span>【中等】Redis 6.0 之后为什么引入了多线程？</span></a></h3><p>随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 IO 的处理上，也就是说，<strong>单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</strong></p><p>为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。但是，对于命令的执行，Redis 仍然使用单线程来处理。</p><p>Redis 官方表示，<strong>Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309241148273.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【中等】什么是-redis-模块-有什么用" tabindex="-1"><a class="header-anchor" href="#【中等】什么是-redis-模块-有什么用"><span>【中等】什么是 Redis 模块？有什么用？</span></a></h3><p>Redis 从 4.0 版本开始，支持通过 Module 来扩展其功能以满足特殊的需求。这些 Module 以动态链接库（so 文件）的形式被加载到 Redis 中，这是一种非常灵活的动态扩展功能的实现方式，值得借鉴学习！</p><p>我们每个人都可以基于 Redis 去定制化开发自己的 Module，比如实现搜索引擎功能、自定义分布式锁和分布式限流。</p><p>目前，被 Redis 官方推荐的 Module 有：</p><ul><li><a href="https://github.com/RediSearch/RediSearch" target="_blank" rel="noopener noreferrer">RediSearch</a>：用于实现搜索引擎的模块。</li><li><a href="https://github.com/RedisJSON/RedisJSON" target="_blank" rel="noopener noreferrer">RedisJSON</a>：用于处理 JSON 数据的模块。</li><li><a href="https://github.com/RedisGraph/RedisGraph" target="_blank" rel="noopener noreferrer">RedisGraph</a>：用于实现图形数据库的模块。</li><li><a href="https://github.com/RedisTimeSeries/RedisTimeSeries" target="_blank" rel="noopener noreferrer">RedisTimeSeries</a>：用于处理时间序列数据的模块。</li><li><a href="https://github.com/RedisBloom/RedisBloom" target="_blank" rel="noopener noreferrer">RedisBloom</a>：用于实现布隆过滤器的模块。</li><li><a href="https://github.com/RedisAI/RedisAI" target="_blank" rel="noopener noreferrer">RedisAI</a>：用于执行深度学习/机器学习模型并管理其数据的模块。</li><li><a href="https://github.com/brandur/redis-cell" target="_blank" rel="noopener noreferrer">RedisCell</a>：用于实现分布式限流的模块。</li></ul><p>关于 Redis 模块的详细介绍，可以查看官方文档：<a href="https://redis.io/modules%E3%80%82" target="_blank" rel="noopener noreferrer">https://redis.io/modules。</a></p><h3 id="【困难】redis-有哪些巧妙的设计-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【困难】redis-有哪些巧妙的设计-⭐⭐"><span>【困难】Redis 有哪些巧妙的设计？⭐⭐</span></a></h3><p>Redis 的巧妙设计体现在：</p><ul><li><strong>单线程 + 非阻塞 I/O</strong> → 高吞吐、低延迟。</li><li><strong>精细优化的数据结构</strong> → 节省内存，提升访问速度。</li><li><strong>异步化处理</strong>（持久化、删除、复制）→ 减少主线程阻塞。</li><li><strong>扩展性设计</strong>（模块化、集群）→ 适应不同场景需求。</li></ul><p>Redis 作为高性能的内存数据库，有许多巧妙的设计理念和实现细节，使其在性能、简洁性和功能性之间取得平衡。以下是 Redis 的一些巧妙设计：</p><div class="hint-container info"><p class="hint-container-title">单线程模型（核心命令处理）</p></div><p>Redis 采用<strong>单线程处理命令</strong>（6.0+ 后支持多线程 I/O，但核心逻辑仍单线程），避免了锁竞争和上下文切换的开销，同时利用以下优化：</p><ul><li><strong>非阻塞 I/O</strong>：基于 <code>epoll/kqueue</code> 实现高效事件驱动模型。</li><li><strong>纯内存操作</strong>：绝大多数操作在内存中完成，单线程即可高效处理。</li><li><strong>原子性保证</strong>：单线程天然支持原子操作，简化了事务、Lua 脚本等实现。</li></ul><p><strong>巧妙点</strong>：牺牲多线程并行性换取无锁设计的简单性和高性能。</p><div class="hint-container info"><p class="hint-container-title">高效数据结构实现</p></div><p>Redis 的核心数据结构经过高度优化：</p><ul><li><strong>SDS (Simple Dynamic String)</strong>： <ul><li>预分配内存、惰性释放，减少内存重分配。</li><li>二进制安全（可存储任意数据，不像 C 字符串以 <code>\\0</code> 结尾）。</li></ul></li><li><strong>压缩列表 (ziplist)</strong>： <ul><li>对小数据（如短列表、小哈希）使用紧凑存储，节省内存。</li></ul></li><li><strong>快速列表 (quicklist)</strong>： <ul><li>结合 <code>ziplist</code> 和双向链表，优化 <code>List</code> 的内存和访问效率。</li></ul></li><li><strong>跳跃表 (skiplist)</strong>： <ul><li>实现 <code>ZSET</code>，支持 <code>O(logN)</code> 范围查询和高效插入。</li></ul></li><li><strong>渐进式 Rehash</strong>： <ul><li><code>Hash</code> 扩容时不阻塞服务，分批次迁移数据。</li></ul></li></ul><p><strong>巧妙点</strong>：针对不同场景选择最优底层结构，平衡内存和速度。</p><div class="hint-container info"><p class="hint-container-title">异步持久化</p></div><p>Redis 提供两种持久化方式：</p><ul><li><strong>RDB （快照）</strong>： <ul><li><code>fork()</code> 子进程生成快照，主进程继续服务。</li><li>使用 <code>Copy-On-Write (COW)</code> 机制减少内存开销。</li></ul></li><li><strong>AOF （日志追加）</strong>： <ul><li>先执行命令再记录日志，避免日志错误影响数据。</li><li>支持 <code>AOF Rewrite</code> 压缩日志（类似 RDB 的快照逻辑）。</li></ul></li></ul><p><strong>巧妙点</strong>：通过 <code>fork()</code> + <code>COW</code> 实现后台持久化，避免阻塞主线程。</p><div class="hint-container info"><p class="hint-container-title">多路复用+零拷贝</p></div><ul><li><strong>I/O 多路复用</strong>： <ul><li>使用 <code>epoll/kqueue</code> 监听大量连接，避免线程/进程切换。</li></ul></li><li><strong>零拷贝优化</strong>： <ul><li>网络发送数据时，直接引用内存缓冲区，减少拷贝（如 <code>sendfile</code>）。</li></ul></li></ul><p><strong>巧妙点</strong>：最大化利用系统调用，减少 CPU 和内存开销。</p><div class="hint-container info"><p class="hint-container-title">惰性删除 (Lazy Free)</p></div><ul><li><strong>DEL 命令不立即释放内存</strong>，而是异步回收（避免大 Key 删除卡住主线程）。</li><li>适用于 <code>UNLINK</code>、<code>FLUSHDB ASYNC</code> 等场景。</li></ul><p><strong>巧妙点</strong>：用空间换时间，避免同步删除导致服务延迟。</p><div class="hint-container info"><p class="hint-container-title">过期键的混合淘汰策略</p></div><ul><li><strong>定期删除</strong>：随机抽查部分 Key，清理已过期的。</li><li><strong>惰性删除</strong>：访问 Key 时检查是否过期，再决定删除。</li></ul><p><strong>巧妙点</strong>：平衡 CPU 和内存，避免全局扫描影响性能。</p><div class="hint-container info"><p class="hint-container-title">模块化设计 (Redis Modules)</p></div><ul><li>支持动态加载模块（如 <code>RedisSearch</code>、<code>RedisGraph</code>），扩展功能而不改核心代码。</li></ul><p><strong>巧妙点</strong>：保持核心精简，通过插件机制扩展能力。</p><div class="hint-container info"><p class="hint-container-title">集群分片的无中心化设计</p></div><ul><li><strong>Gossip 协议</strong>：节点间自动发现和状态同步。</li><li><strong>哈希槽 (Hash Slot)</strong>：数据分片到 16384 个槽，而非一致性哈希，简化迁移。</li></ul><p><strong>巧妙点</strong>：去中心化设计，避免单点瓶颈，支持动态扩缩容。</p><h2 id="redis-优化" tabindex="-1"><a class="header-anchor" href="#redis-优化"><span>Redis 优化</span></a></h2><h3 id="【中等】为什么会有慢查询命令" tabindex="-1"><a class="header-anchor" href="#【中等】为什么会有慢查询命令"><span>【中等】为什么会有慢查询命令？</span></a></h3><p>一个 Redis 命令的执行可以简化为以下 4 步：</p><ol><li>发送命令</li><li>命令排队</li><li>命令执行</li><li>返回结果</li></ol><p>Redis 慢查询统计的是命令执行这一步骤的耗时，慢查询命令也就是那些命令执行时间较长的命令。</p><p>Redis 为什么会有慢查询命令呢？</p><p>Redis 中的大部分命令都是 O(1) 时间复杂度，但也有少部分 O(n) 时间复杂度的命令，例如：</p><ul><li><code>KEYS *</code>：会返回所有符合规则的 key。</li><li><code>HGETALL</code>：会返回一个 Hash 中所有的键值对。</li><li><code>LRANGE</code>：会返回 List 中指定范围内的元素。</li><li><code>SMEMBERS</code>：返回 Set 中的所有元素。</li><li><code>SINTER</code>/<code>SUNION</code>/<code>SDIFF</code>：计算多个 Set 的交集/并集/差集。</li><li>……</li></ul><p>由于这些命令时间复杂度是 O(n)，有时候也会全表扫描，随着 n 的增大，执行耗时也会越长。不过，这些命令并不是一定不能使用，但是需要明确 N 的值。另外，有遍历的需求可以使用 <code>HSCAN</code>、<code>SSCAN</code>、<code>ZSCAN</code> 代替。</p><p>除了这些 O(n) 时间复杂度的命令可能会导致慢查询之外，还有一些时间复杂度可能在 O(N) 以上的命令，例如：</p><ul><li><code>ZRANGE</code>/<code>ZREVRANGE</code>：返回指定 Sorted Set 中指定排名范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量，m 为返回的元素数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。</li><li><code>ZREMRANGEBYRANK</code>/<code>ZREMRANGEBYSCORE</code>：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量，m 被删除元素的数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。</li><li>……</li></ul><h3 id="【中等】如何找到慢查询命令" tabindex="-1"><a class="header-anchor" href="#【中等】如何找到慢查询命令"><span>【中等】如何找到慢查询命令？</span></a></h3><p>在 <code>redis.conf</code> 文件中，我们可以使用 <code>slowlog-log-slower-than</code> 参数设置耗时命令的阈值，并使用 <code>slowlog-max-len</code> 参数设置耗时命令的最大记录条数。</p><p>当 Redis 服务器检测到执行时间超过 <code>slowlog-log-slower-than</code>阈值的命令时，就会将该命令记录在慢查询日志 (slow log) 中，这点和 MySQL 记录慢查询语句类似。当慢查询日志超过设定的最大记录条数之后，Redis 会把最早的执行命令依次舍弃。</p><p>⚠️注意：由于慢查询日志会占用一定内存空间，如果设置最大记录条数过大，可能会导致内存占用过高的问题。</p><p><code>slowlog-log-slower-than</code>和<code>slowlog-max-len</code>的默认配置如下（可以自行修改）：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># The following time is expressed in microseconds, so 1000000 is equivalent</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># to one second. Note that a negative number disables the slow log, while</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># a value of zero forces the logging of every command.</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">slowlog-log-slower-than</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 10000</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># There is no limit to this length. Just be aware that it will consume memory.</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">slowlog-max-len</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 128</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>除了修改配置文件之外，你也可以直接通过 <code>CONFIG</code> 命令直接设置：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 命令执行耗时超过 10000 微妙（即 10 毫秒）就会被记录</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">CONFIG</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> SET</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> slowlog-log-slower-than</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 10000</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 只保留最近 128 条耗时命令</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">CONFIG</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> SET</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> slowlog-max-len</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 128</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>获取慢查询日志的内容很简单，直接使用<code>SLOWLOG GET</code> 命令即可。</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">127.0.0.1:6379</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">SLOWLOG</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> GET</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> #慢日志查询</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> 1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) 1) (</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">integer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) 5</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">   2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) (</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">integer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) 1684326682</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">   3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) (</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">integer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) 12000</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">   4</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) 1) </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;KEYS&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">      2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;*&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">   5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;172.17.0.1:61152&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">   6</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">  //</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ...</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>慢查询日志中的每个条目都由以下六个值组成：</p><ol><li>唯一渐进的日志标识符。</li><li>处理记录命令的 Unix 时间戳。</li><li>执行所需的时间量，以微秒为单位。</li><li>组成命令参数的数组。</li><li>客户端 IP 地址和端口。</li><li>客户端名称。</li></ol><p><code>SLOWLOG GET</code> 命令默认返回最近 10 条的的慢查询命令，你也自己可以指定返回的慢查询命令的数量 <code>SLOWLOG GET N</code>。</p><p>下面是其他比较常用的慢查询相关的命令：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 返回慢查询命令的数量</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">127.0.0.1:6379</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">SLOWLOG</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> LEN</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">integer</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">128</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 清空慢查询命令</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">127.0.0.1:6379</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">SLOWLOG</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> RESET</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">OK</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="【中等】redis-中的-big-key-问题是什么-如何解决" tabindex="-1"><a class="header-anchor" href="#【中等】redis-中的-big-key-问题是什么-如何解决"><span>【中等】Redis 中的 Big Key 问题是什么？如何解决？</span></a></h3><div class="hint-container info"><p class="hint-container-title">什么是 Redis Big Key？</p></div><p>Big Key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p><p>一般而言，下面这两种情况被称为 Big Key：</p><ul><li>String 类型的值大于 10 KB；</li><li>Hash、List、Set、ZSet 类型的元素的个数超过 5000 个，或总大小超过 10MB</li></ul><div class="hint-container info"><p class="hint-container-title">Big Key 会造成什么问题？</p></div><p>Big Key 会带来以下四种影响：</p><ul><li><strong>内存分布不均</strong>：集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有 Big Key 的 Redis 节点占用内存多，QPS 也会比较大。</li><li><strong>命令阻塞</strong>：Redis 单线程模型，操作大 Key 耗时，阻塞其他命令。</li><li><strong>网络传输压力</strong>：每次获取 Big Key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li><strong>客户端超时</strong>：由于 Redis 执行命令是单线程处理，然后在操作 Big Key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li></ul><div class="hint-container info"><p class="hint-container-title">Big Key 解决方案</p></div><p><strong>（1）开发优化</strong></p><ul><li><strong>数据压缩</strong>：存储前压缩 Value（如 Gzip、Snappy）。</li><li><strong>拆分大对象</strong>：将单个大 Key 拆分为多个小 Key（如 <code>user:1000:info</code> → <code>user:1000:basic</code> + <code>user:1000:details</code>）。</li><li><strong>优化数据结构</strong>： <ul><li>避免巨型 String，改用 Hash、List 等分片存储。</li><li>使用 <code>ziplist</code>、<code>quicklist</code> 等紧凑结构。</li></ul></li></ul><p><strong>（2）业务调整</strong></p><ul><li><strong>精简存储数据</strong>：仅保留高频访问字段（如不存用户全部信息，只存 ID + 核心字段）。</li><li><strong>逻辑优化</strong>：避免业务层生成大 Key（如限制缓存数据大小、分页查询）。</li></ul><p><strong>（3）数据分布优化</strong></p><ul><li><strong>集群分片</strong>：通过 Redis Cluster 分散大 Key 到不同节点。</li><li><strong>本地缓存</strong>：对冷数据使用本地缓存（如 Caffeine），减少 Redis 压力。</li></ul><p><strong>关键点</strong></p><ul><li><strong>预防优于治理</strong>：在设计和开发阶段规避大 Key。</li><li><strong>监控与巡检</strong>：通过 <code>redis-cli --bigkeys</code> 或自定义脚本定期检测大 Key。</li></ul><div class="hint-container info"><p class="hint-container-title">如何查找 Redis Big Key？</p></div><p><strong>（1）使用 <code>redis-cli --bigkeys</code></strong></p><p><strong>命令</strong>：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">redis-cli</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -h</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 127.0.0.1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -p</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 6379</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -a</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;password&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --bigkeys</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>注意事项</strong>：</p><ul><li><strong>推荐在从节点执行</strong>（主节点执行可能阻塞业务）</li><li><strong>低峰期执行</strong> 或 <strong>加 <code>-i</code> 参数控制扫描间隔</strong>（如 <code>-i 0.1</code> 表示每 100ms 扫描一次）</li></ul><p><strong>缺点</strong>：</p><ul><li>只能返回<strong>每种数据类型最大的 1 个 Key</strong>（无法获取 Top N）</li><li>对集合类型<strong>只统计元素个数</strong>，而非实际内存占用</li></ul><p><strong>（2）使用 <code>SCAN</code> + 内存分析命令</strong></p><p><strong>遍历所有 Key</strong>（避免 <code>KEYS *</code> 阻塞 Redis）：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">redis-cli</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --scan</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --pattern</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;*&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">while</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> read</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> key</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">; </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">do</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> ...</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">; </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">done</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>分析 Key 大小</strong>：</p><ul><li><strong>String</strong>：<code>STRLEN $key</code>（字节数）</li><li><strong>集合类型</strong>（List/Hash/Set/ZSet）： <ul><li><strong>方法 1</strong>：<code>LLEN</code>/<code>HLEN</code>/<code>SCARD</code>/<code>ZCARD</code>（元素个数 × 预估元素大小）</li><li><strong>方法 2</strong>（Redis 4.0+）：<code>MEMORY USAGE $key</code>（精确内存占用）</li></ul></li></ul><p><strong>优点</strong>：</p><ul><li>可自定义筛选条件（如大小 Top 10）</li><li>精确计算内存占用</li></ul><p><strong>（3）使用 <code>RdbTools</code> 分析 RDB 文件</strong></p><p><strong>命令</strong>：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">rdb</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dump.rdb</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -c</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> memory</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --bytes</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 10240</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> redis.csv</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 导出 &gt;10KB 的 Key 到 CSV</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>适用场景</strong>：</p><ul><li>离线分析，不影响线上 Redis</li><li>精准统计<strong>所有 Key 的内存分布</strong></li></ul><p><strong>缺点</strong>：需要 Redis 生成 RDB 快照</p><p><strong>总结：3 种方法对比</strong></p><table><thead><tr><th>方法</th><th>适用场景</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td><strong><code>--bigkeys</code></strong></td><td>快速找出最大 Key</td><td>简单易用</td><td>结果不全面</td></tr><tr><td><strong><code>SCAN</code>+命令</strong></td><td>精确分析内存</td><td>可定制化</td><td>需脚本支持</td></tr><tr><td><strong><code>RdbTools</code></strong></td><td>离线全面分析</td><td>精准无遗漏</td><td>依赖 RDB 文件</td></tr></tbody></table><p><strong>推荐组合</strong>：</p><ul><li>日常监控用 <code>--bigkeys</code>（低峰期执行）</li><li>深度分析用 <code>RdbTools</code>（定期检查 RDB）</li><li>排查问题时用 <code>SCAN</code>+<code>MEMORY USAGE</code>（实时精准定位）</li></ul><h3 id="【中等】如何解决-redis-中的热点-key-问题" tabindex="-1"><a class="header-anchor" href="#【中等】如何解决-redis-中的热点-key-问题"><span>【中等】如何解决 Redis 中的热点 key 问题？</span></a></h3><p>解决 Redis 中的热点 key 问题的方法：</p><ul><li><p><strong>热点 Key 拆分</strong></p><ul><li><strong>垂直分片</strong>：<code>user:123</code> → <code>user:123:base</code> + <code>user:123:detail</code></li><li><strong>水平分片</strong>：<code>product:views</code> → <code>product:views:shard1</code>/<code>shard2</code></li></ul></li><li><p><strong>多级缓存</strong>：CDN → 本地缓存（Caffeine/Guava） → Redis → DB</p></li><li><p><strong>读写分离</strong>：读请求分流到从节点（配置 <code>replica-read-only yes</code>）</p></li><li><p><strong>流量控制</strong>：</p><ul><li><strong>Sentinel / Hystrix 等流控中间件</strong></li><li><strong>Redis + Lua 限流</strong></li></ul><div class="language-lua line-numbers-mode" data-highlighter="shiki" data-ext="lua" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-lua"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 示例：每秒限 100 次访问</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">local</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> count</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> = </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">redis</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">call</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;INCR&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">KEYS</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">])</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> count</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> == </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> then</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> redis</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">call</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;EXPIRE&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">KEYS</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">end</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">return</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> count</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;= </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">100</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>数据预热</strong>：定时任务提前加载热点数据到缓存</p></li><li><p><strong>负载均衡</strong>：</p><ul><li><strong>Redis Cluster</strong>：分散热点 Key 到不同节点</li><li><strong>代理层</strong>：Twemproxy / Redis Proxy / Nginx 实现负载均衡</li></ul></li></ul>`,396)])])}const g=s(l,[["render",r]]),p=JSON.parse('{"path":"/pages/7bf27e8c/","title":"Redis 面试","lang":"zh-CN","frontmatter":{"icon":"logos:redis","title":"Redis 面试","cover":"https://raw.githubusercontent.com/dunwu/images/master/snap/202503110803916.jpg","date":"2020-07-13T17:03:42.000Z","categories":["数据库","KV 数据库","Redis"],"tags":["数据库","KV 数据库","Redis","面试"],"permalink":"/pages/7bf27e8c/","description":"Redis 面试 扩展 面试中关于 Redis 的问题看这篇就够了 advanced-java Redis 常见面试题 Redis 简介 【简单】什么是 Redis？ 什么是 Redis？ Redis 是一个开源的、数据存于内存中的 K-V 数据库。由于，Redis 的读写操作都是在内存中完成，因此其读写速度非常快。 高性能：由于，Redis 的读写操...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Redis 面试\\",\\"image\\":[\\"https://architecturenotes.co/p/redis\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503270820508.gif\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202504010716308.jpg\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503272238061.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503272248959.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503272224006.jpg\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503282134261.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-cluster-trib.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/cs/database/redis/redis-ask.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503270821660.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202503272229177.jpg\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202309241133046.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/202309241148273.png\\"],\\"datePublished\\":\\"2020-07-13T17:03:42.000Z\\",\\"dateModified\\":\\"2026-01-25T23:26:36.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"钝悟\\",\\"url\\":\\"https://dunwu.github.io/waterdrop\\"}]}"],["meta",{"property":"og:url","content":"https://dunwu.github.io/waterdrop/waterdrop/pages/7bf27e8c/"}],["meta",{"property":"og:site_name","content":"钝悟"}],["meta",{"property":"og:title","content":"Redis 面试"}],["meta",{"property":"og:description","content":"Redis 面试 扩展 面试中关于 Redis 的问题看这篇就够了 advanced-java Redis 常见面试题 Redis 简介 【简单】什么是 Redis？ 什么是 Redis？ Redis 是一个开源的、数据存于内存中的 K-V 数据库。由于，Redis 的读写操作都是在内存中完成，因此其读写速度非常快。 高性能：由于，Redis 的读写操..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dunwu/images/master/snap/202503110803916.jpg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-25T23:26:36.000Z"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://raw.githubusercontent.com/dunwu/images/master/snap/202503110803916.jpg"}],["meta",{"name":"twitter:image:alt","content":"Redis 面试"}],["meta",{"property":"article:tag","content":"面试"}],["meta",{"property":"article:tag","content":"Redis"}],["meta",{"property":"article:tag","content":"KV 数据库"}],["meta",{"property":"article:tag","content":"数据库"}],["meta",{"property":"article:published_time","content":"2020-07-13T17:03:42.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-25T23:26:36.000Z"}]]},"git":{"createdTime":1697125600000,"updatedTime":1769383596000,"contributors":[{"name":"dunwu","username":"dunwu","email":"forbreak@163.com","commits":22,"url":"https://github.com/dunwu"}]},"readingTime":{"minutes":51.36,"words":15409},"filePathRelative":"12.数据库/KV数据库/Redis/Redis_面试.md","excerpt":"\\n<div class=\\"hint-container tip\\">\\n<p class=\\"hint-container-title\\">扩展</p>\\n<ul>\\n<li><a href=\\"https://juejin.im/post/5ad6e4066fb9a028d82c4b66\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">面试中关于 Redis 的问题看这篇就够了</a></li>\\n<li><a href=\\"https://github.com/doocs/advanced-java#%E7%BC%93%E5%AD%98\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">advanced-java</a></li>\\n<li><a href=\\"https://xiaolincoding.com/redis/base/redis_interview.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Redis 常见面试题</a></li>\\n</ul>\\n</div>","autoDesc":true}');export{g as comp,p as data};
