import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as e,o as n}from"./app-D9ZsBuuN.js";const h={};function l(t,i){return n(),a("div",null,[...i[0]||(i[0]=[e(`<h1 id="hive-表" tabindex="-1"><a class="header-anchor" href="#hive-表"><span>Hive 表</span></a></h1><h2 id="分区表" tabindex="-1"><a class="header-anchor" href="#分区表"><span>分区表</span></a></h2><h3 id="概念" tabindex="-1"><a class="header-anchor" href="#概念"><span>概念</span></a></h3><p>Hive 中的表对应为 HDFS 上的指定目录，在查询数据时候，默认会对全表进行扫描，这样时间和性能的消耗都非常大。</p><p><strong>分区为 HDFS 上表目录的子目录</strong>，数据按照分区存储在子目录中。如果查询的 <code>where</code> 子句中包含分区条件，则直接从该分区去查找，而不是扫描整个表目录，合理的分区设计可以极大提高查询速度和性能。</p><p>分区表并非 Hive 独有的概念，实际上这个概念非常常见。通常，在管理大规模数据集的时候都需要进行分区，比如将日志文件按天进行分区，从而保证数据细粒度的划分，使得查询性能得到提升。比如，在我们常用的 Oracle 数据库中，当表中的数据量不断增大，查询数据的速度就会下降，这时也可以对表进行分区。表进行分区后，逻辑上表仍然是一张完整的表，只是将表中的数据存放到多个表空间（物理文件上），这样查询数据时，就不必要每次都扫描整张表，从而提升查询性能。</p><h3 id="创建分区表" tabindex="-1"><a class="header-anchor" href="#创建分区表"><span>创建分区表</span></a></h3><p>在 Hive 中可以使用 <code>PARTITIONED BY</code> 子句创建分区表。表可以包含一个或多个分区列，程序会为分区列中的每个不同值组合创建单独的数据目录。下面的我们创建一张雇员表作为测试：</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sql"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> CREATE</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> EXTERNAL</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> TABLE</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> emp_partition(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    empno </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ename STRING,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    job STRING,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    mgr </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    hiredate </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">TIMESTAMP</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    sal </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">DECIMAL</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    comm </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">DECIMAL</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    PARTITIONED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (deptno </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)   </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">-- 按照部门编号进行分区</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    ROW</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FORMAT DELIMITED FIELDS TERMINATED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;\\t&quot;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    LOCATION</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;/Hive/emp_partition&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="加载数据到分区表" tabindex="-1"><a class="header-anchor" href="#加载数据到分区表"><span>加载数据到分区表</span></a></h3><p>加载数据到分区表时候必须要指定数据所处的分区：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 加载部门编号为 20 的数据到表中</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">LOAD</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> DATA</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> LOCAL</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> INPATH</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;/usr/file/emp20.txt&quot;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> OVERWRITE</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> INTO</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> TABLE</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> emp_partition</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> PARTITION</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (deptno=20)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 加载部门编号为 30 的数据到表中</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">LOAD</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> DATA</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> LOCAL</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> INPATH</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;/usr/file/emp30.txt&quot;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> OVERWRITE</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> INTO</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> TABLE</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> emp_partition</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> PARTITION</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (deptno=30)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="查看分区目录" tabindex="-1"><a class="header-anchor" href="#查看分区目录"><span>查看分区目录</span></a></h3><p>这时候我们直接查看表目录，可以看到表目录下存在两个子目录，分别是 <code>deptno=20</code> 和 <code>deptno=30</code>, 这就是分区目录，分区目录下才是我们加载的数据文件。</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Hadoop fs -ls  hdfs://hadoop001:8020/Hive/emp_partition/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这时候当你的查询语句的 <code>where</code> 包含 <code>deptno=20</code>，则就去对应的分区目录下进行查找，而不用扫描全表。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/archive/2026/02/98a57cefe20f492e9d9f213a355bb541.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="分桶表" tabindex="-1"><a class="header-anchor" href="#分桶表"><span>分桶表</span></a></h2><h3 id="简介" tabindex="-1"><a class="header-anchor" href="#简介"><span>简介</span></a></h3><p>分区提供了一个隔离数据和优化查询的可行方案，但是并非所有的数据集都可以形成合理的分区，分区的数量也不是越多越好，过多的分区条件可能会导致很多分区上没有数据。同时 Hive 会限制动态分区可以创建的最大分区数，用来避免过多分区文件对文件系统产生负担。鉴于以上原因，Hive 还提供了一种更加细粒度的数据拆分方案：分桶表 (bucket Table)。</p><p>分桶表会将指定列的值进行哈希散列，并对 bucket（桶数量）取余，然后存储到对应的 bucket（桶）中。</p><h3 id="理解分桶表" tabindex="-1"><a class="header-anchor" href="#理解分桶表"><span>理解分桶表</span></a></h3><p>单从概念上理解分桶表可能会比较晦涩，其实和分区一样，分桶这个概念同样不是 Hive 独有的，对于 Java 开发人员而言，这可能是一个每天都会用到的概念，因为 Hive 中的分桶概念和 Java 数据结构中的 HashMap 的分桶概念是一致的。</p><p>当调用 HashMap 的 put() 方法存储数据时，程序会先对 key 值调用 hashCode() 方法计算出 hashcode，然后对数组长度取模计算出 index，最后将数据存储在数组 index 位置的链表上，链表达到一定阈值后会转换为红黑树 (JDK1.8+)。下图为 HashMap 的数据结构图：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/archive/2020/02/dac7b6fc5030463da82f8d8c4c530abe.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>图片引用自：<a href="http://www.itcuties.com/java/hashmap-hashtable/" target="_blank" rel="noopener noreferrer">HashMap vs. Hashtable</a></p><h3 id="创建分桶表" tabindex="-1"><a class="header-anchor" href="#创建分桶表"><span>创建分桶表</span></a></h3><p>在 Hive 中，我们可以通过 <code>CLUSTERED BY</code> 指定分桶列，并通过 <code>SORTED BY</code> 指定桶中数据的排序参考列。下面为分桶表建表语句示例：</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sql"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">  CREATE</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> EXTERNAL</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> TABLE</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> emp_bucket(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    empno </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ename STRING,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    job STRING,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    mgr </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    hiredate </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">TIMESTAMP</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    sal </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">DECIMAL</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    comm </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">DECIMAL</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">7</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">),</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    deptno </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    CLUSTERED</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(empno) SORTED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(empno </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">ASC</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INTO</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 4</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> BUCKETS  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--按照员工编号散列到四个 bucket 中</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    ROW</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FORMAT DELIMITED FIELDS TERMINATED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;\\t&quot;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    LOCATION</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;/Hive/emp_bucket&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="加载数据到分桶表" tabindex="-1"><a class="header-anchor" href="#加载数据到分桶表"><span>加载数据到分桶表</span></a></h3><p>这里直接使用 <code>Load</code> 语句向分桶表加载数据，数据时可以加载成功的，但是数据并不会分桶。</p><p>这是由于分桶的实质是对指定字段做了 hash 散列然后存放到对应文件中，这意味着向分桶表中插入数据是必然要通过 MapReduce，且 Reducer 的数量必须等于分桶的数量。由于以上原因，分桶表的数据通常只能使用 CTAS(CREATE TABLE AS SELECT) 方式插入，因为 CTAS 操作会触发 MapReduce。加载数据步骤如下：</p><h4 id="设置强制分桶" tabindex="-1"><a class="header-anchor" href="#设置强制分桶"><span>设置强制分桶</span></a></h4><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sql"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">set</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> hive</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">enforce</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.bucketing </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> true; </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--Hive 2.x 不需要这一步</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>在 Hive 0.x and 1.x 版本，必须使用设置 <code>hive.enforce.bucketing = true</code>，表示强制分桶，允许程序根据表结构自动选择正确数量的 Reducer 和 cluster by column 来进行分桶。</p><h4 id="ctas-导入数据" tabindex="-1"><a class="header-anchor" href="#ctas-导入数据"><span>CTAS 导入数据</span></a></h4><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sql"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INSERT INTO</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> TABLE</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> emp_bucket </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">SELECT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> *  </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">FROM</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> emp;  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">--这里的 emp 表就是一张普通的雇员表</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>可以从执行日志看到 CTAS 触发 MapReduce 操作，且 Reducer 数量和建表时候指定 bucket 数量一致：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/archive/2026/02/256dfe4e8b5f4f08a08d5e4c98b0f715.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="查看分桶文件" tabindex="-1"><a class="header-anchor" href="#查看分桶文件"><span>查看分桶文件</span></a></h3><p>bucket（桶） 本质上就是表目录下的具体文件：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/archive/2026/02/553e77f4bb7d4148861130ddb7281c2a.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="分区表和分桶表结合使用" tabindex="-1"><a class="header-anchor" href="#分区表和分桶表结合使用"><span>分区表和分桶表结合使用</span></a></h2><p>分区表和分桶表的本质都是将数据按照不同粒度进行拆分，从而使得在查询时候不必扫描全表，只需要扫描对应的分区或分桶，从而提升查询效率。两者可以结合起来使用，从而保证表数据在不同粒度上都能得到合理的拆分。下面是 Hive 官方给出的示例：</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-sql"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">CREATE</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> TABLE</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> page_view_bucketed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	viewTime </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    userid </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BIGINT</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    page_url STRING,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    referrer_url STRING,</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ip STRING )</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> PARTITIONED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(dt STRING)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> CLUSTERED</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(userid) SORTED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(viewTime) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">INTO</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 32</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> BUCKETS</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> ROW</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> FORMAT DELIMITED</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   FIELDS TERMINATED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;\\001&#39;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">   COLLECTION</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> ITEMS TERMINATED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;\\002&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   MAP KEYS TERMINATED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">BY</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;\\003&#39;</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> STORED </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">AS</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> SEQUENCEFILE;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>此时导入数据时需要指定分区：</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-shell"><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">INSERT</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> OVERWRITE</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> page_view_bucketed</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">PARTITION</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (dt=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;2009-02-25&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">SELECT</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> *</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> FROM</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> page_view</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> WHERE</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> dt=&#39;2009-02-25&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ul><li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables" target="_blank" rel="noopener noreferrer">LanguageManual DDL BucketedTables</a></li></ul>`,49)])])}const d=s(h,[["render",l]]),r=JSON.parse('{"path":"/pages/a5412afb/","title":"Hive 表","lang":"zh-CN","frontmatter":{"icon":"simple-icons:apachehive","title":"Hive 表","date":"2020-02-24T21:14:47.000Z","categories":["大数据","Hive"],"tags":["大数据","Hive"],"permalink":"/pages/a5412afb/","description":"Hive 表 分区表 概念 Hive 中的表对应为 HDFS 上的指定目录，在查询数据时候，默认会对全表进行扫描，这样时间和性能的消耗都非常大。 分区为 HDFS 上表目录的子目录，数据按照分区存储在子目录中。如果查询的 where 子句中包含分区条件，则直接从该分区去查找，而不是扫描整个表目录，合理的分区设计可以极大提高查询速度和性能。 分区表并非 ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Hive 表\\",\\"image\\":[\\"https://raw.githubusercontent.com/dunwu/images/master/archive/2026/02/98a57cefe20f492e9d9f213a355bb541.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/archive/2020/02/dac7b6fc5030463da82f8d8c4c530abe.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/archive/2026/02/256dfe4e8b5f4f08a08d5e4c98b0f715.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/archive/2026/02/553e77f4bb7d4148861130ddb7281c2a.png\\"],\\"datePublished\\":\\"2020-02-24T21:14:47.000Z\\",\\"dateModified\\":\\"2026-02-11T15:41:54.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"钝悟\\",\\"url\\":\\"https://dunwu.github.io/waterdrop\\"}]}"],["meta",{"property":"og:url","content":"https://dunwu.github.io/waterdrop/waterdrop/pages/a5412afb/"}],["meta",{"property":"og:site_name","content":"钝悟"}],["meta",{"property":"og:title","content":"Hive 表"}],["meta",{"property":"og:description","content":"Hive 表 分区表 概念 Hive 中的表对应为 HDFS 上的指定目录，在查询数据时候，默认会对全表进行扫描，这样时间和性能的消耗都非常大。 分区为 HDFS 上表目录的子目录，数据按照分区存储在子目录中。如果查询的 where 子句中包含分区条件，则直接从该分区去查找，而不是扫描整个表目录，合理的分区设计可以极大提高查询速度和性能。 分区表并非 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dunwu/images/master/archive/2026/02/98a57cefe20f492e9d9f213a355bb541.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-02-11T15:41:54.000Z"}],["meta",{"property":"article:tag","content":"Hive"}],["meta",{"property":"article:tag","content":"大数据"}],["meta",{"property":"article:published_time","content":"2020-02-24T21:14:47.000Z"}],["meta",{"property":"article:modified_time","content":"2026-02-11T15:41:54.000Z"}]]},"git":{"createdTime":1697125600000,"updatedTime":1770824514000,"contributors":[{"name":"dunwu","username":"dunwu","email":"forbreak@163.com","commits":8,"url":"https://github.com/dunwu"}]},"readingTime":{"minutes":5.51,"words":1654},"filePathRelative":"16.大数据/Hive/Hive_表.md","excerpt":"\\n<h2>分区表</h2>\\n<h3>概念</h3>\\n<p>Hive 中的表对应为 HDFS 上的指定目录，在查询数据时候，默认会对全表进行扫描，这样时间和性能的消耗都非常大。</p>\\n<p><strong>分区为 HDFS 上表目录的子目录</strong>，数据按照分区存储在子目录中。如果查询的 <code>where</code> 子句中包含分区条件，则直接从该分区去查找，而不是扫描整个表目录，合理的分区设计可以极大提高查询速度和性能。</p>\\n<p>分区表并非 Hive 独有的概念，实际上这个概念非常常见。通常，在管理大规模数据集的时候都需要进行分区，比如将日志文件按天进行分区，从而保证数据细粒度的划分，使得查询性能得到提升。比如，在我们常用的 Oracle 数据库中，当表中的数据量不断增大，查询数据的速度就会下降，这时也可以对表进行分区。表进行分区后，逻辑上表仍然是一张完整的表，只是将表中的数据存放到多个表空间（物理文件上），这样查询数据时，就不必要每次都扫描整张表，从而提升查询性能。</p>","autoDesc":true}');export{d as comp,r as data};
