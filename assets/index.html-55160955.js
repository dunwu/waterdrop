import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as r,c as a,a as e,b as s,d as i,e as t}from"./app-80cb5bc0.js";const d={},c=t('<h1 id="redis-面试" tabindex="-1"><a class="header-anchor" href="#redis-面试" aria-hidden="true">#</a> Redis 面试</h1><h2 id="redis-简介" tabindex="-1"><a class="header-anchor" href="#redis-简介" aria-hidden="true">#</a> Redis 简介</h2><h3 id="【简单】什么是-redis" tabindex="-1"><a class="header-anchor" href="#【简单】什么是-redis" aria-hidden="true">#</a> 【简单】什么是 Redis？</h3><blockquote><p>什么是 Redis？</p></blockquote><p><strong>Redis 是一个开源的、数据存于内存中的 K-V 数据库</strong>。由于，Redis 的读写操作都是在内存中完成，因此其<strong>读写速度非常快</strong>。</p><ul><li><strong>高性能</strong> - 由于，Redis 的读写操作都是在内存中完成，因此性能极高。</li><li><strong>高并发</strong> - Redis 单机 QPS 能达到 10w+，将近是 Mysql 的 10 倍。</li></ul><p>Redis 常被用于<strong>缓存，消息队列、分布式锁等场景</strong>。</p><blockquote><p>Redis 有什么功能和特性？</p></blockquote><p>Redis 的功能和特性：</p><ul><li><strong>Redis 支持多种数据类型</strong>。如：String（字符串）、Hash（哈希）、 List （列表）、Set（集合）、Zset（有序集合）、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理空间）、Stream（流）。</li><li><strong>Redis 的读写采用“单线程”模型</strong>，因此，其操作天然就具有<strong>原子性</strong>。需要注意的是，Redis 6.0 后在其网络模块中引入了多线程 I/O 机制。</li><li>Redis 支持两种持久化策略：RDB 和 AOF。</li><li>Redis 有多种高可用方案：<strong>主从复制</strong>模式、<strong>哨兵</strong>模式、<strong>集群</strong>模式。</li><li>Redis 支持很多丰富的特性，如：<strong>事务</strong> 、<strong>Lua 脚本</strong>、<strong>发布订阅</strong>、<strong>过期删除</strong>、<strong>内存淘汰</strong>等等。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202411231010326.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',11),g={href:"https://architecturenotes.co/p/redis",target:"_blank",rel:"noopener noreferrer"},p=t('<h3 id="【简单】redis-有哪些应用场景" tabindex="-1"><a class="header-anchor" href="#【简单】redis-有哪些应用场景" aria-hidden="true">#</a> 【简单】Redis 有哪些应用场景？</h3><p>Redis 常见应用场景如下：</p><ul><li><strong>缓存</strong> - 将热点数据放到内存中，设置内存的最大使用量以及过期淘汰策略来保证缓存的命中率。</li><li><strong>计数器</strong> - Redis 这种内存数据库能支持计数器频繁的读写操作。</li><li><strong>应用限流</strong> - 限制一个网站访问流量。</li><li><strong>消息队列</strong> - 使用 List 数据类型，它是双向链表。</li><li><strong>查找表</strong> - 使用 HASH 数据类型。</li><li><strong>聚合运算</strong> - 使用 SET 类型，例如求两个用户的共同好友。</li><li><strong>排行榜</strong> - 使用 ZSET 数据类型。</li><li><strong>分布式 Session</strong> - 多个应用服务器的 Session 都存储到 Redis 中来保证 Session 的一致性。</li><li><strong>分布式锁</strong> - 除了可以使用 SETNX 实现分布式锁之外，还可以使用官方提供的 RedLock 分布式锁实现。</li></ul><h3 id="【简单】redis-有哪些里程碑版本" tabindex="-1"><a class="header-anchor" href="#【简单】redis-有哪些里程碑版本" aria-hidden="true">#</a> 【简单】Redis 有哪些里程碑版本？</h3><p>Redis 里程碑版本如下：</p><ul><li>Redis 1.0（2010 年） - Redis 1.0 发布，采用单机架构，一般作为业务应用的缓存。但是 Redis 的数据是存在内存中的，重启 Redis 时，数据会全部丢失，流量直接打到数据库。</li><li>Redis 2.8（2013 年） <ul><li>持久化 - Redis 引入了 RDB 内存快照来持久化数据。它还支持 AOF（仅追加文件），其中每个写入命令都写入 AOF 文件。</li><li>复制 - 添加了复制功能以提高可用性。主实例处理实时读写请求，而副本同步主实例的数据。</li><li>哨兵 - 引入了 Sentinel 来实时监控 Redis 实例。Sentinel 是一个旨在帮助管理 Redis 实例的系统。它执行以下四个任务：监控、通知、自动故障转移和共享配置。</li></ul></li><li>Redis 3.0（2015 年） - 官方提供了 redis-cluster。redis-cluster 是一种分布式数据库解决方案，通过分片管理数据。数据被分成 16384 个槽，每个节点负责槽的一部分。</li><li>Redis 5.0（2017 年） - 新增 Stream 数据类型。</li><li>Redis 6.0（2020 年） - 在网络模块中引入了多线程 I/O。Redis 模型分为网络模块和主处理模块。特别注意：Redis 不再完全是单线程架构。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503270820508.gif" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【简单】对比一下-redis-和-memcached" tabindex="-1"><a class="header-anchor" href="#【简单】对比一下-redis-和-memcached" aria-hidden="true">#</a> 【简单】对比一下 Redis 和 Memcached？</h3><blockquote><ul><li>Redis 和 Memcached 有什么相同点？</li><li>Redis 和 Memcached 有什么差异？</li><li>分布式缓存技术选型，选 Redis 还是 Memcached，为什么？</li></ul></blockquote><p>Redis 与 Memcached 的<strong>共性</strong>：</p><ul><li>都是内存数据库，因此性能都很高。</li><li>都有过期策略。</li></ul><p>因为以上两点，所以常被作为缓存使用。</p><p>Redis 与 Memcached 的<strong>差异</strong>：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202504010716308.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>核心差异对比：</p><table><thead><tr><th></th><th>Memcached</th><th>Redis</th></tr></thead><tbody><tr><td>数据类型</td><td>只支持 String 类型</td><td>支持多种数据类型：String、Hash、List、Set、ZSet 等</td></tr><tr><td>持久化</td><td>不支持持久化，一旦重启或宕机就会丢失数据</td><td>支持两种持久化策略：RDB 和 AOF</td></tr><tr><td>分布式</td><td>本身不支持分布式，只能通过在客户端使用像一致性哈希这样的分布式算法来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点</td><td>支持分布式</td></tr><tr><td>线程模型</td><td>采用多线程+IO 多路复用。在 100k 以上的数据中，Memcached 性能要高于 Redis</td><td>读写采用单线程+IO 多路复用。因此存储小数据时比 Memcached 性能更高</td></tr><tr><td>其他功能</td><td>不支持</td><td>支持发布订阅模型、Lua 脚本、事务等功能</td></tr></tbody></table><p>通过以上分析，可以看出，Redis 在很多方面都占有优势。因此，绝大多数情况下，优先选择 Redis 作为分布式缓存。</p>',17),u=e("strong",null,"扩展",-1),h={href:"https://www.imooc.com/article/23549",target:"_blank",rel:"noopener noreferrer"},m=t(`<h3 id="【简单】redis-有哪些-java-客户端-各有什么优劣" tabindex="-1"><a class="header-anchor" href="#【简单】redis-有哪些-java-客户端-各有什么优劣" aria-hidden="true">#</a> 【简单】Redis 有哪些 Java 客户端？各有什么优劣？</h3><p>Redis 的主流 Java 客户端有三种，对比如下：</p><table><thead><tr><th style="text-align:left;">客户端</th><th style="text-align:left;">线程安全</th><th style="text-align:left;">自动重连</th><th style="text-align:left;">编程模型</th><th style="text-align:left;">适用场景</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>Jedis</strong></td><td style="text-align:left;">❌</td><td style="text-align:left;">❌</td><td style="text-align:left;">同步</td><td style="text-align:left;">简单应用、快速开发</td></tr><tr><td style="text-align:left;"><strong>Lettuce</strong></td><td style="text-align:left;">✅</td><td style="text-align:left;">✅</td><td style="text-align:left;">同步/异步/响应式</td><td style="text-align:left;">高并发、Spring Boot 项目</td></tr><tr><td style="text-align:left;"><strong>Redisson</strong></td><td style="text-align:left;">✅</td><td style="text-align:left;">✅</td><td style="text-align:left;">同步/异步</td><td style="text-align:left;">分布式系统、高级功能需求</td></tr></tbody></table><p><strong>推荐选择</strong>：</p><ul><li><strong>基础需求</strong> → Jedis（简单直接）。</li><li><strong>高并发/Spring 项目</strong> → Lettuce（默认选择）。</li><li><strong>分布式锁/队列等</strong> → Redisson（功能强大）。</li></ul><h4 id="jedis" tabindex="-1"><a class="header-anchor" href="#jedis" aria-hidden="true">#</a> Jedis</h4><p><strong>✅ 优点</strong></p><ul><li><strong>简单易用</strong>：API 直观，适合快速上手。</li><li><strong>广泛使用</strong>：社区支持丰富，文档齐全。</li><li><strong>性能良好</strong>：常规操作高效。</li><li><strong>功能全面</strong>：支持字符串、哈希、列表等基础数据结构。</li></ul><p><strong>❌ 缺点</strong></p><ul><li><strong>非线程安全</strong>：需为每个线程创建独立实例。</li><li><strong>无自动重连</strong>：网络异常需手动处理。</li><li><strong>同步阻塞</strong>：高并发时可能成为性能瓶颈。</li></ul><h4 id="lettuce" tabindex="-1"><a class="header-anchor" href="#lettuce" aria-hidden="true">#</a> Lettuce</h4><p><strong>✅ 优点</strong></p><ul><li><strong>线程安全</strong>：多线程共享同一连接。</li><li><strong>高性能</strong>：基于 Netty 实现，支持高并发。</li><li><strong>自动重连</strong>：网络中断后自动恢复。</li><li><strong>多编程模型</strong>：支持同步、异步、响应式（如 Reactive API）。</li></ul><p><strong>❌ 缺点</strong></p><ul><li><strong>API 较复杂</strong>：学习成本高于 Jedis。</li><li><strong>资源消耗</strong>：异步模式可能占用更多内存/CPU。</li></ul><h4 id="redisson" tabindex="-1"><a class="header-anchor" href="#redisson" aria-hidden="true">#</a> Redisson</h4><p><strong>✅ 优点</strong></p><ul><li><strong>分布式支持</strong>：内置分布式锁、队列、缓存等高级功能。</li><li><strong>线程安全</strong>：天然适配多线程场景。</li><li><strong>集群友好</strong>：完善支持 Redis 集群模式。</li><li><strong>稳定性高</strong>：企业级应用验证。</li></ul><p><strong>❌ 缺点</strong></p><ul><li><strong>学习曲线陡峭</strong>：需掌握分布式概念。</li><li><strong>依赖兼容性</strong>：可能与其他库冲突需调优。</li></ul><h2 id="redis-内存管理" tabindex="-1"><a class="header-anchor" href="#redis-内存管理" aria-hidden="true">#</a> Redis 内存管理</h2><h3 id="【中等】redis-支持哪些过期删除策略" tabindex="-1"><a class="header-anchor" href="#【中等】redis-支持哪些过期删除策略" aria-hidden="true">#</a> 【中等】Redis 支持哪些过期删除策略？</h3><blockquote><ul><li>Redis 支持哪些过期删除策略？</li><li>常见的过期策略有哪些，Redis 的选择考量是什么？</li></ul></blockquote><p>Redis 采用的过期策略是：<strong>定期删除+惰性删除</strong>。</p><ul><li><strong>定时删除</strong> - 在设置 key 的过期时间的同时，创建一个定时器，让定时器在 key 的过期时间来临时，立即执行 key 的删除操作。 <ul><li><strong>优点</strong> - 保证过期 key 被尽可能快的删除，释放内存。</li><li><strong>缺点</strong> - <strong>如果过期 key 较多，可能会占用相当一部分的 CPU，从而影响服务器的吞吐量和响应时延</strong>。</li></ul></li><li><strong>惰性删除</strong> - 放任 key 过期不管，但是每次访问 key 时，都检查 key 是否过期，如果过期的话，就删除该 key ；如果没有过期，就返回该 key。 <ul><li><strong>优点</strong> - 占用 CPU 最少。程序只会在读写键时，对当前键进行过期检查，因此不会有额外的 CPU 开销。</li><li><strong>缺点</strong> - <strong>过期的 key 可能因为没有被访问，而一直无法释放，造成内存的浪费，有内存泄漏的风险</strong>。</li></ul></li><li><strong>定期删除</strong> - 每隔一段时间，程序就对数据库进行一次检查，删除里面的过期 key。至于要删除多少过期 key ，以及要检查多少个数据库，则由算法决定。定期删除是前两种策略的一种折中方案。定期删除策略的难点是删除操作执行的时长和频率。 <ul><li>执行太频或执行时间过长，就会出现和定时删除相同的问题；</li><li>执行太少或执行时间过短，就会出现和惰性删除相同的问题；</li></ul></li></ul><h3 id="【中等】redis-有哪些内存淘汰策略" tabindex="-1"><a class="header-anchor" href="#【中等】redis-有哪些内存淘汰策略" aria-hidden="true">#</a> 【中等】Redis 有哪些内存淘汰策略？</h3><blockquote><ul><li>Redis 内存不足时，怎么办？</li><li>Redis 有哪些内存淘汰策略？</li><li>如何选择内存淘汰策略？</li></ul></blockquote><blockquote><p><strong>Redis 内存淘汰要点</strong></p></blockquote><ul><li><strong>失效时间</strong> - 作为一种定期清理无效数据的重要机制，在 Redis 提供的诸多命令中，<code>EXPIRE</code>、<code>EXPIREAT</code>、<code>PEXPIRE</code>、<code>PEXPIREAT</code> 以及 <code>SETEX</code> 和 <code>PSETEX</code> 均可以用来设置一条键值对的失效时间。而一条键值对一旦被关联了失效时间就会在到期后自动删除（或者说变得无法访问更为准确）。</li><li><strong>最大缓存</strong> - Redis 允许通过 <code>maxmemory</code> 参数来设置内存最大值。当内存达设定的阀值，就会触发<strong>内存淘汰</strong>。</li><li><strong>内存淘汰</strong> - 内存淘汰是为了更好的利用内存——清理部分缓存，以此换取内存的利用率，即尽量保证 Redis 缓存中存储的是热点数据。</li></ul><blockquote><p><strong>Redis 内存淘汰策略</strong></p></blockquote><ul><li><strong>不淘汰</strong><ul><li><strong><code>noeviction</code></strong> - 当内存使用达到阈值的时候，所有引起申请内存的命令会报错。这是 Redis 默认的策略。</li></ul></li><li><strong>在过期键中进行淘汰</strong><ul><li><strong><code>volatile-random</code></strong> - 在设置了过期时间的键空间中，随机移除某个 key。</li><li><strong><code>volatile-ttl</code></strong> - 在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除。</li><li><strong><code>volatile-lru</code></strong> - 在设置了过期时间的键空间中，优先移除最近未使用的 key。</li><li><strong><code>volatile-lfu</code></strong> （Redis 4.0 新增）- 淘汰所有设置了过期时间的键值中，最少使用的键值。</li></ul></li><li><strong>在所有键中进行淘汰</strong><ul><li><strong><code>allkeys-random</code></strong> - 在主键空间中，随机移除某个 key。</li><li><strong><code>allkeys-lru</code></strong> - 在主键空间中，优先移除最近未使用的 key。</li><li><strong><code>allkeys-lfu</code></strong> (Redis 4.0 新增） - 淘汰整个键值中最少使用的键值。</li></ul></li></ul><blockquote><p>如何选择内存淘汰策略</p></blockquote><ul><li>如果数据呈现正态分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 <code>allkeys-lru</code> 或 <code>allkeys-lfu</code>。</li><li>如果数据呈现平均分布，也就是所有的数据访问频率都相同，则使用 <code>allkeys-random</code>。</li><li>若 Redis 既用于缓存，也用于持久化存储时，适用 <code>volatile-lru</code> 、<code>volatile-lfu</code>、<code>volatile-random</code>。但是，这种情况下，也可以部署两个 Redis 集群来达到同样目的。</li><li>为 key 设置过期时间实际上会消耗更多的内存。因此，如果条件允许，建议使用 <code>allkeys-lru</code> 或 <code>allkeys-lfu</code>，从而更高效的使用内存。</li></ul><h3 id="【中等】redis-持久化时-对过期键会如何处理" tabindex="-1"><a class="header-anchor" href="#【中等】redis-持久化时-对过期键会如何处理" aria-hidden="true">#</a> 【中等】Redis 持久化时，对过期键会如何处理？</h3><p><strong>RDB 持久化</strong></p><ul><li><strong>RDB 文件生成阶段</strong> - 从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键“不会”被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</li><li><strong>RDB 加载阶段</strong> - RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况： <ul><li><strong>如果 Redis 是“主服务器”运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键“不会”被载入到数据库中</strong>。所以过期键不会对载入 RDB 文件的主服务器造成影响；</li><li><strong>如果 Redis 是“从服务器”运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。</li></ul></li></ul><p><strong>AOF 持久化</strong></p><ul><li><strong>AOF 文件写入阶段</strong> - 当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li><li><strong>AOF 重写阶段</strong> - 执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响。</li></ul><h3 id="【中等】redis-主从复制时-对过期键会如何处理" tabindex="-1"><a class="header-anchor" href="#【中等】redis-主从复制时-对过期键会如何处理" aria-hidden="true">#</a> 【中等】Redis 主从复制时，对过期键会如何处理？</h3><p>当 Redis 运行在主从模式下时，<strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</p><p>从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p><h3 id="【中等】redis-中的内存碎片化是什么-如何进行优化" tabindex="-1"><a class="header-anchor" href="#【中等】redis-中的内存碎片化是什么-如何进行优化" aria-hidden="true">#</a> 【中等】Redis 中的内存碎片化是什么？如何进行优化？</h3><p>Redis 内存碎片化是指已分配的内存无法被有效利用，导致内存浪费的现象。</p><p>可以通过 Redis 的 <code>INFO memory</code> 命令查看：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>mem_fragmentation_ratio: <span class="token number">1.86</span>  <span class="token comment"># 大于 1.5 表示碎片较多</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>内存碎片的原因</strong>：</p><ul><li><strong>内存分配器机制</strong> - Redis 使用 Jemalloc 或 glibc 的 malloc 等内存分配器，这些分配器为了性能不会总是精确分配请求的大小，可能分配稍大的块。</li><li><strong>键值对频繁修改</strong> - 当键值对被频繁修改（特别是大小变化时），旧的内存空间可能无法重用。例如：字符串值从 128B 改为 256B，原空间不够需要新分配。</li><li><strong>键过期/删除</strong> - 删除键释放的内存块可能无法与相邻空闲块合并，这些碎片空间可能无法满足新的大内存请求。</li><li><strong>不同大小的数据混合存储</strong> - Redis 存储各种大小的键值对，导致内存中出现大小不一的空闲块。</li></ul><p><strong>内存碎片的影响</strong>：</p><ul><li><strong>内存分配策略</strong>：不同的分配器 (Jemalloc/libc 等）碎片率不同</li><li><strong>工作负载模式</strong>：频繁修改和删除操作会增加碎片</li><li><strong>数据大小分布</strong>：大小差异大的数据混合存储更容易产生碎片</li></ul><p><strong>内存碎片的解决</strong>：</p><ul><li>重启 Redis（会丢失数据）</li><li>使用 <code>MEMORY PURGE</code> 命令（需要特定分配器支持）</li><li>配置合理的 maxmemory 和淘汰策略</li><li>对于高碎片环境，可考虑使用 Redis 4.0+ 的主动碎片整理功能</li></ul><h2 id="redis-持久化" tabindex="-1"><a class="header-anchor" href="#redis-持久化" aria-hidden="true">#</a> Redis 持久化</h2><h3 id="【中等】redis-支持哪些持久化方式" tabindex="-1"><a class="header-anchor" href="#【中等】redis-支持哪些持久化方式" aria-hidden="true">#</a> 【中等】Redis 支持哪些持久化方式？</h3><p>为了追求性能，Redis 的读写都是在内存中完成的。一旦重启，内存中的数据就会清空，为了保证数据不丢失，Redis 支持持久化机制。</p><p>Redis 有三种持久化方式</p><ul><li>RDB 快照</li><li>AOF 日志</li><li>混合持久化</li></ul><h4 id="rdb" tabindex="-1"><a class="header-anchor" href="#rdb" aria-hidden="true">#</a> RDB</h4><blockquote><ul><li>RDB 的实现原理是什么？</li><li>生成 RDB 快照时，Redis 可以响应请求吗？</li></ul></blockquote>`,58),R={href:"https://redis.io/commands/save",target:"_blank",rel:"noopener noreferrer"},b=e("strong",null,[e("code",null,"SAVE")],-1),k={href:"https://redis.io/commands/bgsave",target:"_blank",rel:"noopener noreferrer"},f=e("strong",null,[e("code",null,"BGSAVE")],-1),y={href:"https://redis.io/commands/save",target:"_blank",rel:"noopener noreferrer"},v=e("strong",null,[e("code",null,"SAVE")],-1),_=e("strong",null,"该命令“会阻塞”服务器",-1),O={href:"https://redis.io/commands/bgsave",target:"_blank",rel:"noopener noreferrer"},A=e("strong",null,[e("code",null,"BGSAVE")],-1),x=e("strong",null,"派生",-1),S=e("strong",null,"该命令“不会阻塞”服务器",-1),E=t('<figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272238061.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><blockquote><p>🔔 <strong>【注意】</strong></p><p><code>BGSAVE</code> 命令的实现采用的是写时复制技术（Copy-On-Write，缩写为 CoW）。</p><p><code>BGSAVE</code> 命令执行期间，<code>SAVE</code>、<code>BGSAVE</code>、<code>BGREWRITEAOF</code> 三个命令会被拒绝，以免与当前的 <code>BGSAVE</code> 操作产生竞态条件，降低性能。</p></blockquote><h4 id="aof" tabindex="-1"><a class="header-anchor" href="#aof" aria-hidden="true">#</a> AOF</h4><blockquote><ul><li>AOF 的实现原理是什么？</li><li>为什么先执行命令，再把数据写入日志呢？</li></ul></blockquote><p><strong>Redis 命令请求会先保存到 AOF 缓冲区，再定期写入并同步到 AOF 文件</strong>。</p><p>AOF 的实现可以分为命令追加（append）、文件写入、文件同步（sync）三个步骤。</p><ul><li><strong>命令追加</strong> - 当 Redis 服务器开启 AOF 功能时，服务器在执行完一个写命令后，会以 Redis 命令协议格式将被执行的写命令追加到 AOF 缓冲区的末尾。</li><li><strong>文件写入</strong>和<strong>文件同步</strong><ul><li>Redis 的服务器进程就是一个事件循环，这个循环中的文件事件负责接收客户端的命令请求，以及向客户端发送命令回复。而时间事件则负责执行想 <code>serverCron</code> 这样的定时运行的函数。</li><li>因为服务器在处理文件事件时可能会执行写命令，这些写命令会被追加到 AOF 缓冲区，服务器每次结束事件循环前，都会根据 <code>appendfsync</code> 选项来判断 AOF 缓冲区内容是否需要写入和同步到 AOF 文件中。</li></ul></li></ul><p>先执行命令，再把数据写入 AOF 日志有两个好处：</p><ul><li><strong>避免额外的检查开销</strong></li><li><strong>不会阻塞当前写操作命令的执行</strong></li></ul><p>当然，这样做也会有弊端：</p><ul><li><strong>数据可能会丢失：</strong></li><li><strong>可能阻塞其他操作：</strong></li></ul><p><strong>Redis 命令请求会先保存到 AOF 缓冲区，再定期写入并同步到 AOF 文件</strong>。</p><p><code>appendfsync</code> 不同选项决定了不同的持久化行为：</p><ul><li><strong><code>always</code></strong> - 将 AOF 缓冲区中所有内容写入并同步到 AOF 文件。这种方式是最数据最安全的，但也是性能最差的。</li><li><strong><code>no</code></strong> - 将 AOF 缓冲区所有内容写入到 AOF 文件，但并不对 AOF 文件进行同步，何时同步由操作系统决定。这种方式是数据最不安全的，一旦出现故障，未来得及同步的所有数据都会丢失。</li><li><strong><code>everysec</code></strong> - <code>appendfsync</code> 默认选项。将 AOF 缓冲区所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟，那么再次对 AOF 文件进行同步，这个同步操作是有一个线程专门负责执行的。这张方式是前面两种的这种方案——性能足够好，且即使出现故障，仅丢失一秒钟内的数据。</li></ul><p><code>appendfsync</code> 选项的不同值对 AOF 持久化功能的安全性、以及 Redis 服务器的性能有很大的影响。</p><h4 id="混合持久化" tabindex="-1"><a class="header-anchor" href="#混合持久化" aria-hidden="true">#</a> 混合持久化</h4><p>Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p><p><strong>混合持久化的工作机制</strong></p><ul><li><strong>触发时机</strong>：在 AOF 重写过程中启用。</li><li><strong>执行流程</strong>： <ol><li><strong>子进程</strong>将共享内存数据以 <strong>RDB 格式</strong>写入 AOF 文件（全量数据）。</li><li><strong>主线程</strong>将操作命令记录到重写缓冲区，再以 <strong>AOF 格式</strong>追加到 AOF 文件（增量数据）。</li><li>替换旧 AOF 文件，新文件包含 <strong>RDB（前半部分） + AOF（后半部分）</strong>。</li></ol></li></ul><p><strong>混合持久化的优点</strong></p><ul><li><strong>重启速度快</strong>：优先加载 RDB 部分（全量数据恢复快）。</li><li><strong>数据丢失少</strong>：后续加载 AOF 部分（增量数据补充）。</li></ul><p><strong>混合持久化的缺点</strong></p><ul><li><strong>可读性差</strong>：AOF 文件包含二进制 RDB 数据，不易阅读。</li><li><strong>兼容性差</strong>：仅支持 Redis 4.0+ 版本，旧版本无法识别。</li></ul><h3 id="【中等】aof-的重写机制是怎样的" tabindex="-1"><a class="header-anchor" href="#【中等】aof-的重写机制是怎样的" aria-hidden="true">#</a> 【中等】AOF 的重写机制是怎样的？</h3><ul><li>AOF 日志过大时，怎么办？</li><li>AOF 重写流程是怎样的？</li><li>AOF 重写时，可以处理请求吗？</li></ul><p><strong>知识点</strong></p><p>当 AOF 日志过大时，恢复过程就会很久。为了避免此问题，Redis 提供了 AOF 重写机制，即 AOF 日志大小超过所设阈值后，启动 AOF 重写，压缩 AOF 文件。</p><p>AOF 重写机制是，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到新的 AOF 日志中，等到全部记录完成后，就使用新的 AOF 日志替换现有的 AOF 日志。</p><p>作为一种辅助性功能，显然 Redis 并不想在 AOF 重写时阻塞 Redis 服务接收其他命令。因此，Redis 决定通过 <code>BGREWRITEAOF</code> 命令创建一个子进程，然后由子进程负责对 AOF 文件进行重写，这与 <code>BGSAVE</code> 原理类似。</p><ul><li>在执行 <code>BGREWRITEAOF</code> 命令时，Redis 服务器会维护一个 AOF 重写缓冲区。当 AOF 重写子进程开始工作后，Redis 每执行完一个写命令，会同时将这个命令发送给 AOF 缓冲区和 AOF 重写缓冲区。</li><li>由于彼此不是在同一个进程中工作，AOF 重写不影响 AOF 写入和同步。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新旧两个 AOF 文件所保存的数据库状态一致。</li><li>最后，服务器用新的 AOF 文件替换就的 AOF 文件，以此来完成 AOF 重写操作。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272248959.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="redis-批处理" tabindex="-1"><a class="header-anchor" href="#redis-批处理" aria-hidden="true">#</a> Redis 批处理</h2><h3 id="【中等】redis-支持事务吗" tabindex="-1"><a class="header-anchor" href="#【中等】redis-支持事务吗" aria-hidden="true">#</a> 【中等】Redis 支持事务吗？</h3><div class="hint-container info"><p class="hint-container-title">Redis 支持事务吗？</p></div>',34),F={href:"https://redis.io/commands/multi",target:"_blank",rel:"noopener noreferrer"},B=e("code",null,"MULTI",-1),w={href:"https://redis.io/commands/exec",target:"_blank",rel:"noopener noreferrer"},L=e("code",null,"EXEC",-1),C={href:"https://redis.io/commands/discard",target:"_blank",rel:"noopener noreferrer"},I=e("code",null,"DISCARD",-1),q={href:"https://redis.io/commands/watch",target:"_blank",rel:"noopener noreferrer"},T=e("code",null,"WATCH",-1),N={href:"https://redis.io/commands/multi",target:"_blank",rel:"noopener noreferrer"},D=e("code",null,"MULTI",-1),G=e("code",null,"MULTI",-1),K={href:"https://redis.io/commands/exec",target:"_blank",rel:"noopener noreferrer"},P=e("code",null,"EXEC",-1),M=e("ul",null,[e("li",null,[s("如果客户端在使用 "),e("code",null,"MULTI"),s(" 开启了一个事务之后，却因为断线而没有成功执行 "),e("code",null,"EXEC"),s(" ，那么事务中的所有命令都不会被执行。")]),e("li",null,[s("另一方面，如果客户端成功在开启事务之后执行 "),e("code",null,"EXEC"),s(" ，那么事务中的所有命令都会被执行。")])],-1),z={href:"https://redis.io/commands/discard",target:"_blank",rel:"noopener noreferrer"},H=e("code",null,"DISCARD",-1),U={href:"https://redis.io/commands/watch",target:"_blank",rel:"noopener noreferrer"},W=e("code",null,"WATCH",-1),V=e("code",null,"WATCH",-1),X=e("code",null,"EXEC",-1),Z=e("code",null,"EXEC",-1),Y=e("code",null,"nil-reply",-1),J=t(`<p><code>WATCH</code> 可以用于创建 Redis 没有内置的原子操作。</p><p>举个例子，以下代码实现了原创的 <code>ZPOP</code> 命令，它可以原子地弹出有序集合中分值（<code>score</code>）最小的元素：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>WATCH zset
element <span class="token operator">=</span> ZRANGE zset <span class="token number">0</span> <span class="token number">0</span>
MULTI
ZREM zset element
EXEC
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container info"><p class="hint-container-title">Redis 事务是严格意义的事务吗？</p></div><p>ACID 是数据库事务正确执行的四个基本要素。</p><ul><li><strong>原子性（Atomicity）</strong><ul><li>事务被视为不可分割的最小单元，事务中的所有操作<strong>要么全部提交成功，要么全部失败回滚</strong>。</li><li>回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。</li></ul></li><li><strong>一致性（Consistency）</strong><ul><li>数据库在事务执行前后都保持一致性状态。</li><li>在一致性状态下，所有事务对一个数据的读取结果都是相同的。</li></ul></li><li><strong>隔离性（Isolation）</strong><ul><li>一个事务所做的修改在最终提交以前，对其它事务是不可见的。</li></ul></li><li><strong>持久性（Durability）</strong><ul><li>一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。</li><li>可以通过数据库备份和恢复来实现，在系统发生奔溃时，使用备份的数据库进行数据恢复。</li></ul></li></ul><p><strong>一个支持事务（Transaction）中的数据库系统，必需要具有这四种特性，否则在事务过程（Transaction processing）当中无法保证数据的正确性。</strong></p><p><strong>Redis 仅支持“非严格”的事务</strong>。所谓“非严格”是指：</p><ul><li><strong>Redis 事务保证全部执行命令</strong> - Redis 事务中的多个命令会被打包到事务队列中，然后按先进先出（FIFO）的顺序执行。事务在执行过程中不会被中断，当事务队列中的所有命令都被执行完毕之后，事务才会结束。</li><li><strong>Redis 事务不支持回滚</strong> - 如果命令执行失败不会回滚，而是会继续执行下去。</li></ul>`,9),j={href:"https://redis.io/docs/interact/transactions/",target:"_blank",rel:"noopener noreferrer"},Q=t('<ul><li>Redis 命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面。</li><li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。</li></ul><h3 id="【中等】redis-pipeline-能保证原子性吗" tabindex="-1"><a class="header-anchor" href="#【中等】redis-pipeline-能保证原子性吗" aria-hidden="true">#</a> 【中等】Redis Pipeline 能保证原子性吗？</h3><p>先说结论：<strong>Redis Pipeline 不保证原子性</strong>。</p><p>Redis Pipeline（管道）是一种<strong>客户端技术</strong>，用于将多个 Redis 命令批量发送到服务器，减少网络往返时间（RTT），提高吞吐量。</p><ul><li><strong>传统模式</strong>：客户端发送一条命令 → 等待响应 → 再发送下一条（高延迟）。</li><li><strong>Pipeline 模式</strong>：客户端一次性发送多条命令 → 服务器按顺序执行 → 一次性返回所有结果（低延迟）。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272224006.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>核心特性</strong></p><table><thead><tr><th style="text-align:left;"><strong>特性</strong></th><th style="text-align:left;"><strong>说明</strong></th></tr></thead><tbody><tr><td style="text-align:left;"><strong>批量发送</strong></td><td style="text-align:left;">客户端打包多条命令，一次性发送，减少网络开销</td></tr><tr><td style="text-align:left;"><strong>非原子性</strong></td><td style="text-align:left;">Pipeline 只是批量发送，不保证所有命令连续执行（可能被其他客户端命令打断）</td></tr><tr><td style="text-align:left;"><strong>高性能</strong></td><td style="text-align:left;">相比单条命令模式，吞吐量可提升 5~10 倍</td></tr><tr><td style="text-align:left;"><strong>无回滚</strong></td><td style="text-align:left;">如果某条命令失败，不会影响其他命令的执行</td></tr></tbody></table><p><strong>注意事项</strong></p><ul><li><strong>命令数量控制</strong>：避免单次 Pipeline 发送过多命令（建议每批 ≤ 1 万条），否则可能阻塞 Redis。</li><li><strong>集群模式限制</strong>：Redis Cluster 要求 Pipeline 的所有 Key 必须在<strong>同一个 Slot</strong>（可用 <code>{hash_tag}</code> 确保，如 <code>user:{123}:name</code>）。</li><li><strong>错误处理</strong>：Pipeline 返回的是一个列表，需逐条检查命令是否成功。</li><li><strong>与事务的区别</strong>：Pipeline 不保证原子性。</li></ul><p><strong>适用场景</strong></p><p>✅ <strong>适合</strong>：</p><ul><li>批量写入（如日志上报、缓存预热）</li><li>批量查询（如获取多个 Key 的值）</li><li>对原子性无要求的高并发场景</li></ul><p>❌ <strong>不适合</strong>：</p><ul><li>需要事务保证原子性的操作（改用 <code>MULTI/EXEC</code>）</li><li>命令之间有依赖关系（如后一条命令依赖前一条的结果）</li></ul><h3 id="【中等】redis-lua-脚本有什么用" tabindex="-1"><a class="header-anchor" href="#【中等】redis-lua-脚本有什么用" aria-hidden="true">#</a> 【中等】Redis Lua 脚本有什么用？</h3><p>Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。Redis 的 Lua 脚本提供了一种<strong>原子性执行多个命令</strong>的方式。也就是说，一段 <strong>Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行</strong>，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。</p><p>并且，Lua 脚本中支持一些简单的逻辑处理比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。</p><p>不过， Lua 脚本依然存在下面这些缺陷：</p><ul><li><strong>如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销</strong>，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。</li><li><strong>Redis Cluster 下 Lua 脚本的原子操作也无法保证</strong>，原因同样是无法保证所有的 key 都在同一个 hash slot（哈希槽）上。</li></ul>',20),$={href:"https://redis.io/docs/manual/programmability/functions-intro/",target:"_blank",rel:"noopener noreferrer"},ee=t('<h2 id="redis-高可用" tabindex="-1"><a class="header-anchor" href="#redis-高可用" aria-hidden="true">#</a> Redis 高可用</h2><h3 id="【中等】redis-如何实现主从复制" tabindex="-1"><a class="header-anchor" href="#【中等】redis-如何实现主从复制" aria-hidden="true">#</a> 【中等】Redis 如何实现主从复制？</h3><blockquote><ul><li>Redis 复制的工作原理？Redis 旧版复制和新版复制有何不同？</li><li>Redis 主从节点间如何复制数据？</li><li>Redis 的数据一致性是强一致性吗？</li></ul></blockquote><p>（1）旧版复制基于 <code>SYNC</code> 命令实现。分为同步（sync）和命令传播（command propagate）两个操作。这种方式存在缺陷：不能高效处理断线重连后的复制情况。</p><p>（2）新版复制基于 <code>PSYNC</code> 命令实现。同步操作分为了两块：</p><ul><li><strong><code>完整重同步（full resychronization）</code></strong> 用于初次复制；</li><li><strong><code>部分重同步（partial resychronization）</code></strong> 用于断线后重复制。 <ul><li>主从服务器的<strong>复制偏移量（replication offset）</strong></li><li>主服务器的<strong>复制积压缓冲区（replication backlog）</strong></li><li><strong>服务器的运行 ID</strong></li></ul></li></ul><p>（3）Redis 集群主从节点复制的工作流程：</p><ol><li>设置主从服务器</li><li>主从服务器建立 TCP 连接。</li><li>发送 PING 检查通信状态。</li><li>身份验证。</li><li>发送端口信息。</li><li>同步。</li><li>命令传播。</li></ol><p>（4）由于主从复制是<strong>异步</strong>的，具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。所以，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。</p><h3 id="【中等】redis-哨兵是如何工作的" tabindex="-1"><a class="header-anchor" href="#【中等】redis-哨兵是如何工作的" aria-hidden="true">#</a> 【中等】Redis 哨兵是如何工作的？</h3><blockquote><ul><li>Redis 哨兵的功能？</li><li>Redis 哨兵的原理？</li><li>Redis 哨兵如何选举 Leader？</li><li>Redis 如何实现故障转移？</li></ul></blockquote><p>（1）Redis 主从复制模式无法自动故障转移，也就是说，一旦主服务器宕机，需要手动恢复。为了解决此问题，Redis 增加了哨兵模式（Sentinel）。</p><p>（2）由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意多个主服务器，以及这些主服务器的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503282134261.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【中等】redis-集群是如何工作的" tabindex="-1"><a class="header-anchor" href="#【中等】redis-集群是如何工作的" aria-hidden="true">#</a> 【中等】Redis 集群是如何工作的？</h3><p><strong>集群架构</strong></p><ul><li><strong>节点类型</strong>： <ul><li>主节点 (master)：负责处理槽</li><li>从节点 (slave)：复制主节点，主节点下线时可接管</li></ul></li><li><strong>节点通信</strong>：使用 Gossip 协议 (PING/PONG/MEET/FAIL/PUBLISH 消息）</li><li><strong>数据分区</strong>： <ul><li>哈希槽分配：CRC16(key) mod 16384</li><li>槽指派命令：CLUSTER ADDSLOTS</li><li>所有槽必须分配，否则集群下线</li></ul></li></ul><p><strong>关键机制</strong></p><ul><li><strong>请求路由</strong>： <ul><li>计算 key 所属槽</li><li>MOVED 错误重定向（永久重定向）</li><li>ASK 错误重定向（临时重定向，迁移过程中使用）</li></ul></li><li><strong>故障转移</strong>： <ul><li>故障检测：PING 消息+半数以上主节点确认为 FAIL 状态</li><li>选主流程：基于 Raft 协议，需要获得 N/2+1 票</li><li>转移步骤：从节点升级为主节点并接管槽</li></ul></li><li><strong>重新分区</strong>： <ul><li>在线迁移槽和键值对</li><li>使用 redis-trib 工具操作</li></ul></li></ul><p><strong>使用限制</strong></p><ul><li><strong>功能限制</strong>： <ul><li>批量操作/事务/Pipeline/lua 仅支持相同 slot 的 key</li><li>不支持多数据库（仅 db0)</li><li>复制结构只支持一层</li></ul></li><li><strong>规模限制</strong>： <ul><li>适合中小规模集群（几个到几十个节点）</li><li>Gossip 协议在大规模集群中传播效率低</li></ul></li></ul><h3 id="【困难】redis-中的脑裂问题是如何产生的" tabindex="-1"><a class="header-anchor" href="#【困难】redis-中的脑裂问题是如何产生的" aria-hidden="true">#</a> 【困难】Redis 中的脑裂问题是如何产生的？</h3><p>在 Redis 主从架构中，部署方式一般是“一主多从”，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程 A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。</p><p>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在“从节点”中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。</p><p>然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。</p><p>总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p><p>分布式系统的脑裂问题（Split-Brain Problem）是一个严重的一致性问题，通常发生在分布式系统中的节点之间失去通信或部分通信时。这个问题的名称源自脑裂的比喻，就像一个分布式系统被分成多个部分的&quot;脑&quot;，每个部分独立运行，而没有协调一致的方式。</p><p>脑裂问题通常发生在以下情况下：</p><ol><li><strong>网络分区</strong>：当分布式系统中的网络发生问题，导致节点之间无法互相通信或只能部分通信时。这可能是由于网络故障、硬件故障、防火墙配置问题等原因引起的。</li><li><strong>节点故障</strong>：当分布式系统的某个节点崩溃或出现故障，但其他节点无法确定该节点的状态，可能导致脑裂问题。</li></ol><p>脑裂问题的典型情况是，在网络分区或节点故障后，分布式系统的一部分节点认为另一部分节点已经不可用，因此开始采取某种措施，比如选举新的领袖或切换到备份模式。然而，在某些情况下，网络分区可能会解除，或者节点故障可能会自行修复，导致系统中存在多个独立运行的子系统，每个子系统都认为自己是正确的。</p><p>这种情况下，脑裂问题可能导致以下问题：</p><ol><li><strong>数据不一致性</strong>：不同子系统可能具有不同的数据状态，这可能会导致数据不一致性和冲突。</li><li><strong>资源冲突</strong>：如果不同的子系统尝试访问相同的资源，可能会发生资源冲突和竞争条件。</li><li><strong>性能问题</strong>：系统中的资源可能被多次分配，从而浪费了资源并降低了性能。</li></ol><p>为了解决脑裂问题，分布式系统通常需要采用一些机制，如投票算法、选举协议、心跳检测等，以确保在出现网络分区或节点故障时，系统能够正确地识别和处理问题，并维护一致性。这些机制可以帮助系统中的节点协同工作，避免脑裂问题的发生。然而，脑裂问题是分布式系统设计和管理中的复杂挑战之一，需要细致的规划和测试来确保系统的可靠性和稳定性。</p><h3 id="【困难】如何解决-redis-中的脑裂问题" tabindex="-1"><a class="header-anchor" href="#【困难】如何解决-redis-中的脑裂问题" aria-hidden="true">#</a> 【困难】如何解决 Redis 中的脑裂问题？</h3><p>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p><p>在 Redis 的配置文件中有两个参数我们可以设置：</p><ul><li><code>min-slaves-to-write x</code>，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li><li><code>min-slaves-max-lag x</code>，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li></ul><p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。</p><p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。</p><p>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。</p><p><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</strong></p><p>再来举个例子。</p><p>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。</p><p>同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。</p><p>这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p><h2 id="redis-架构" tabindex="-1"><a class="header-anchor" href="#redis-架构" aria-hidden="true">#</a> Redis 架构</h2><h3 id="【中等】redis-为什么快" tabindex="-1"><a class="header-anchor" href="#【中等】redis-为什么快" aria-hidden="true">#</a> 【中等】Redis 为什么快？</h3>',47),se={href:"https://redis.io/docs/management/optimization/benchmarks/",target:"_blank",rel:"noopener noreferrer"},ne=t('<figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503270821660.png" alt="Redis 官方 Benchmark QPS 图" tabindex="0" loading="lazy"><figcaption>Redis 官方 Benchmark QPS 图</figcaption></figure><p>Redis 是单线程模型（Redis 6.0 已经支持多线程模型），为什么还能有这么高的并发？</p><ul><li><strong>Redis 读写基于内存</strong></li><li><strong>IO 多路复用</strong> + <strong>读写单线程模型</strong><ul><li>IO 多路复用是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。</li><li>单线程模型避免了由于并发而产生的线程切换、锁竞争等开销。</li><li>由于，Redis 读写基于内存，性能很高，所以 CPU 并不是制约 Redis 性能表现的瓶颈所在。更多情况下是受到内存大小和网络 I/O 的限制，所以 Redis 核心网络模型使用单线程并没有什么问题。</li></ul></li><li><strong>高效的数据结构</strong></li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202503272229177.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',4),ie={href:"https://blog.bytebytego.com/p/why-is-redis-so-fast",target:"_blank",rel:"noopener noreferrer"},te=e("strong",null,"扩展",-1),le={href:"https://www.youtube.com/shorts/x8lcdDbKZto",target:"_blank",rel:"noopener noreferrer"},oe=t('<h3 id="【中等】redis-单线程模式是怎样的" tabindex="-1"><a class="header-anchor" href="#【中等】redis-单线程模式是怎样的" aria-hidden="true">#</a> 【中等】Redis 单线程模式是怎样的？</h3><p>Redis 单线程模式指的是其核心网络模型为单线程模式。这个模式为 IO 多路复用+单线程读写请求，其中，IO 多路复用使得 Redis 可以同时处理多个客户端连接。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309241133046.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><blockquote><p>Redis 真的只有单线程吗？</p></blockquote><p>Redis 并非真的只有单线。</p><ul><li>Redis 的主要工作包括接收客户端请求、解析请求和进行数据读写等操作，是由单线程来执行的，这也是常说 Redis 是单线程程序的原因。</li><li>Redis 还启动了 3 个线程来执行<strong>文件关闭</strong>、<strong>AOF 同步写</strong>和<strong>惰性删除</strong>等操作。</li><li>此外，Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）。</li></ul><h3 id="【中等】redis-6-0-之后为什么引入了多线程" tabindex="-1"><a class="header-anchor" href="#【中等】redis-6-0-之后为什么引入了多线程" aria-hidden="true">#</a> 【中等】Redis 6.0 之后为什么引入了多线程？</h3><p>随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 IO 的处理上，也就是说，<strong>单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</strong></p><p>为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。但是，对于命令的执行，Redis 仍然使用单线程来处理。</p><p>Redis 官方表示，<strong>Redis 6.0 版本引入的多线程 I/O 特性对性能提升至少是一倍以上</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202309241148273.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【中等】什么是-redis-模块-有什么用" tabindex="-1"><a class="header-anchor" href="#【中等】什么是-redis-模块-有什么用" aria-hidden="true">#</a> 【中等】什么是 Redis 模块？有什么用？</h3><p>Redis 从 4.0 版本开始，支持通过 Module 来扩展其功能以满足特殊的需求。这些 Module 以动态链接库（so 文件）的形式被加载到 Redis 中，这是一种非常灵活的动态扩展功能的实现方式，值得借鉴学习！</p><p>我们每个人都可以基于 Redis 去定制化开发自己的 Module，比如实现搜索引擎功能、自定义分布式锁和分布式限流。</p><p>目前，被 Redis 官方推荐的 Module 有：</p>',15),re={href:"https://github.com/RediSearch/RediSearch",target:"_blank",rel:"noopener noreferrer"},ae={href:"https://github.com/RedisJSON/RedisJSON",target:"_blank",rel:"noopener noreferrer"},de={href:"https://github.com/RedisGraph/RedisGraph",target:"_blank",rel:"noopener noreferrer"},ce={href:"https://github.com/RedisTimeSeries/RedisTimeSeries",target:"_blank",rel:"noopener noreferrer"},ge={href:"https://github.com/RedisBloom/RedisBloom",target:"_blank",rel:"noopener noreferrer"},pe={href:"https://github.com/RedisAI/RedisAI",target:"_blank",rel:"noopener noreferrer"},ue={href:"https://github.com/brandur/redis-cell",target:"_blank",rel:"noopener noreferrer"},he={href:"https://redis.io/modules%E3%80%82",target:"_blank",rel:"noopener noreferrer"},me=t(`<h3 id="【困难】redis-有哪些巧妙的设计" tabindex="-1"><a class="header-anchor" href="#【困难】redis-有哪些巧妙的设计" aria-hidden="true">#</a> 【困难】Redis 有哪些巧妙的设计？</h3><p>Redis 的巧妙设计体现在：</p><ul><li><strong>单线程 + 非阻塞 I/O</strong> → 高吞吐、低延迟。</li><li><strong>精细优化的数据结构</strong> → 节省内存，提升访问速度。</li><li><strong>异步化处理</strong>（持久化、删除、复制）→ 减少主线程阻塞。</li><li><strong>扩展性设计</strong>（模块化、集群）→ 适应不同场景需求。</li></ul><p>Redis 作为高性能的内存数据库，有许多巧妙的设计理念和实现细节，使其在性能、简洁性和功能性之间取得平衡。以下是 Redis 的一些巧妙设计：</p><h4 id="单线程模型-核心命令处理" tabindex="-1"><a class="header-anchor" href="#单线程模型-核心命令处理" aria-hidden="true">#</a> 单线程模型（核心命令处理）</h4><p>Redis 采用<strong>单线程处理命令</strong>（6.0+ 后支持多线程 I/O，但核心逻辑仍单线程），避免了锁竞争和上下文切换的开销，同时利用以下优化：</p><ul><li><strong>非阻塞 I/O</strong>：基于 <code>epoll/kqueue</code> 实现高效事件驱动模型。</li><li><strong>纯内存操作</strong>：绝大多数操作在内存中完成，单线程即可高效处理。</li><li><strong>原子性保证</strong>：单线程天然支持原子操作，简化了事务、Lua 脚本等实现。</li></ul><p><strong>巧妙点</strong>：牺牲多线程并行性换取无锁设计的简单性和高性能。</p><h4 id="高效数据结构实现" tabindex="-1"><a class="header-anchor" href="#高效数据结构实现" aria-hidden="true">#</a> 高效数据结构实现</h4><p>Redis 的核心数据结构经过高度优化：</p><ul><li><strong>SDS (Simple Dynamic String)</strong>： <ul><li>预分配内存、惰性释放，减少内存重分配。</li><li>二进制安全（可存储任意数据，不像 C 字符串以 <code>\\0</code> 结尾）。</li></ul></li><li><strong>压缩列表 (ziplist)</strong>： <ul><li>对小数据（如短列表、小哈希）使用紧凑存储，节省内存。</li></ul></li><li><strong>快速列表 (quicklist)</strong>： <ul><li>结合 <code>ziplist</code> 和双向链表，优化 <code>List</code> 的内存和访问效率。</li></ul></li><li><strong>跳跃表 (skiplist)</strong>： <ul><li>实现 <code>ZSET</code>，支持 <code>O(logN)</code> 范围查询和高效插入。</li></ul></li><li><strong>渐进式 Rehash</strong>： <ul><li><code>Hash</code> 扩容时不阻塞服务，分批次迁移数据。</li></ul></li></ul><p><strong>巧妙点</strong>：针对不同场景选择最优底层结构，平衡内存和速度。</p><h4 id="异步持久化" tabindex="-1"><a class="header-anchor" href="#异步持久化" aria-hidden="true">#</a> 异步持久化</h4><p>Redis 提供两种持久化方式：</p><ul><li><strong>RDB （快照）</strong>： <ul><li><code>fork()</code> 子进程生成快照，主进程继续服务。</li><li>使用 <code>Copy-On-Write (COW)</code> 机制减少内存开销。</li></ul></li><li><strong>AOF （日志追加）</strong>： <ul><li>先执行命令再记录日志，避免日志错误影响数据。</li><li>支持 <code>AOF Rewrite</code> 压缩日志（类似 RDB 的快照逻辑）。</li></ul></li></ul><p><strong>巧妙点</strong>：通过 <code>fork()</code> + <code>COW</code> 实现后台持久化，避免阻塞主线程。</p><h4 id="多路复用-零拷贝" tabindex="-1"><a class="header-anchor" href="#多路复用-零拷贝" aria-hidden="true">#</a> 多路复用+零拷贝</h4><ul><li><strong>I/O 多路复用</strong>： <ul><li>使用 <code>epoll/kqueue</code> 监听大量连接，避免线程/进程切换。</li></ul></li><li><strong>零拷贝优化</strong>： <ul><li>网络发送数据时，直接引用内存缓冲区，减少拷贝（如 <code>sendfile</code>）。</li></ul></li></ul><p><strong>巧妙点</strong>：最大化利用系统调用，减少 CPU 和内存开销。</p><h4 id="惰性删除-lazy-free" tabindex="-1"><a class="header-anchor" href="#惰性删除-lazy-free" aria-hidden="true">#</a> 惰性删除 (Lazy Free)</h4><ul><li><strong>DEL 命令不立即释放内存</strong>，而是异步回收（避免大 Key 删除卡住主线程）。</li><li>适用于 <code>UNLINK</code>、<code>FLUSHDB ASYNC</code> 等场景。</li></ul><p><strong>巧妙点</strong>：用空间换时间，避免同步删除导致服务延迟。</p><h4 id="过期键的混合淘汰策略" tabindex="-1"><a class="header-anchor" href="#过期键的混合淘汰策略" aria-hidden="true">#</a> 过期键的混合淘汰策略</h4><ul><li><strong>定期删除</strong>：随机抽查部分 Key，清理已过期的。</li><li><strong>惰性删除</strong>：访问 Key 时检查是否过期，再决定删除。</li></ul><p><strong>巧妙点</strong>：平衡 CPU 和内存，避免全局扫描影响性能。</p><h4 id="模块化设计-redis-modules" tabindex="-1"><a class="header-anchor" href="#模块化设计-redis-modules" aria-hidden="true">#</a> 模块化设计 (Redis Modules)</h4><ul><li>支持动态加载模块（如 <code>RedisSearch</code>、<code>RedisGraph</code>），扩展功能而不改核心代码。</li></ul><p><strong>巧妙点</strong>：保持核心精简，通过插件机制扩展能力。</p><h4 id="集群分片的无中心化设计" tabindex="-1"><a class="header-anchor" href="#集群分片的无中心化设计" aria-hidden="true">#</a> 集群分片的无中心化设计</h4><ul><li><strong>Gossip 协议</strong>：节点间自动发现和状态同步。</li><li><strong>哈希槽 (Hash Slot)</strong>：数据分片到 16384 个槽，而非一致性哈希，简化迁移。</li></ul><p><strong>巧妙点</strong>：去中心化设计，避免单点瓶颈，支持动态扩缩容。</p><h2 id="redis-优化" tabindex="-1"><a class="header-anchor" href="#redis-优化" aria-hidden="true">#</a> Redis 优化</h2><h3 id="【中等】为什么会有慢查询命令" tabindex="-1"><a class="header-anchor" href="#【中等】为什么会有慢查询命令" aria-hidden="true">#</a> 【中等】为什么会有慢查询命令？</h3><p>一个 Redis 命令的执行可以简化为以下 4 步：</p><ol><li>发送命令</li><li>命令排队</li><li>命令执行</li><li>返回结果</li></ol><p>Redis 慢查询统计的是命令执行这一步骤的耗时，慢查询命令也就是那些命令执行时间较长的命令。</p><p>Redis 为什么会有慢查询命令呢？</p><p>Redis 中的大部分命令都是 O(1) 时间复杂度，但也有少部分 O(n) 时间复杂度的命令，例如：</p><ul><li><code>KEYS *</code>：会返回所有符合规则的 key。</li><li><code>HGETALL</code>：会返回一个 Hash 中所有的键值对。</li><li><code>LRANGE</code>：会返回 List 中指定范围内的元素。</li><li><code>SMEMBERS</code>：返回 Set 中的所有元素。</li><li><code>SINTER</code>/<code>SUNION</code>/<code>SDIFF</code>：计算多个 Set 的交集/并集/差集。</li><li>……</li></ul><p>由于这些命令时间复杂度是 O(n)，有时候也会全表扫描，随着 n 的增大，执行耗时也会越长。不过，这些命令并不是一定不能使用，但是需要明确 N 的值。另外，有遍历的需求可以使用 <code>HSCAN</code>、<code>SSCAN</code>、<code>ZSCAN</code> 代替。</p><p>除了这些 O(n) 时间复杂度的命令可能会导致慢查询之外，还有一些时间复杂度可能在 O(N) 以上的命令，例如：</p><ul><li><code>ZRANGE</code>/<code>ZREVRANGE</code>：返回指定 Sorted Set 中指定排名范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量，m 为返回的元素数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。</li><li><code>ZREMRANGEBYRANK</code>/<code>ZREMRANGEBYSCORE</code>：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量，m 被删除元素的数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。</li><li>……</li></ul><h3 id="【中等】如何找到慢查询命令" tabindex="-1"><a class="header-anchor" href="#【中等】如何找到慢查询命令" aria-hidden="true">#</a> 【中等】如何找到慢查询命令？</h3><p>在 <code>redis.conf</code> 文件中，我们可以使用 <code>slowlog-log-slower-than</code> 参数设置耗时命令的阈值，并使用 <code>slowlog-max-len</code> 参数设置耗时命令的最大记录条数。</p><p>当 Redis 服务器检测到执行时间超过 <code>slowlog-log-slower-than</code>阈值的命令时，就会将该命令记录在慢查询日志 (slow log) 中，这点和 MySQL 记录慢查询语句类似。当慢查询日志超过设定的最大记录条数之后，Redis 会把最早的执行命令依次舍弃。</p><p>⚠️注意：由于慢查询日志会占用一定内存空间，如果设置最大记录条数过大，可能会导致内存占用过高的问题。</p><p><code>slowlog-log-slower-than</code>和<code>slowlog-max-len</code>的默认配置如下（可以自行修改）：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># The following time is expressed in microseconds, so 1000000 is equivalent</span>
<span class="token comment"># to one second. Note that a negative number disables the slow log, while</span>
<span class="token comment"># a value of zero forces the logging of every command.</span>
slowlog-log-slower-than <span class="token number">10000</span>

<span class="token comment"># There is no limit to this length. Just be aware that it will consume memory.</span>
<span class="token comment"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span>
slowlog-max-len <span class="token number">128</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>除了修改配置文件之外，你也可以直接通过 <code>CONFIG</code> 命令直接设置：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 命令执行耗时超过 10000 微妙（即 10 毫秒）就会被记录</span>
CONFIG SET slowlog-log-slower-than <span class="token number">10000</span>
<span class="token comment"># 只保留最近 128 条耗时命令</span>
CONFIG SET slowlog-max-len <span class="token number">128</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>获取慢查询日志的内容很简单，直接使用<code>SLOWLOG GET</code> 命令即可。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> SLOWLOG GET <span class="token comment">#慢日志查询</span>
 <span class="token number">1</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">5</span>
   <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1684326682</span>
   <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">12000</span>
   <span class="token number">4</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">&quot;KEYS&quot;</span>
      <span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">&quot;*&quot;</span>
   <span class="token number">5</span><span class="token punctuation">)</span> <span class="token string">&quot;172.17.0.1:61152&quot;</span>
   <span class="token number">6</span><span class="token punctuation">)</span> <span class="token string">&quot;&quot;</span>
  // <span class="token punctuation">..</span>.
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>慢查询日志中的每个条目都由以下六个值组成：</p><ol><li>唯一渐进的日志标识符。</li><li>处理记录命令的 Unix 时间戳。</li><li>执行所需的时间量，以微秒为单位。</li><li>组成命令参数的数组。</li><li>客户端 IP 地址和端口。</li><li>客户端名称。</li></ol><p><code>SLOWLOG GET</code> 命令默认返回最近 10 条的的慢查询命令，你也自己可以指定返回的慢查询命令的数量 <code>SLOWLOG GET N</code>。</p><p>下面是其他比较常用的慢查询相关的命令：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 返回慢查询命令的数量</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> SLOWLOG LEN
<span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">128</span>
<span class="token comment"># 清空慢查询命令</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> SLOWLOG RESET
OK
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="【中等】redis-中的-big-key-问题是什么-如何解决" tabindex="-1"><a class="header-anchor" href="#【中等】redis-中的-big-key-问题是什么-如何解决" aria-hidden="true">#</a> 【中等】Redis 中的 Big Key 问题是什么？如何解决？</h3><blockquote><p>什么是 Redis Big Key？</p></blockquote><p>Big Key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p><p>一般而言，下面这两种情况被称为 Big Key：</p><ul><li>String 类型的值大于 10 KB；</li><li>Hash、List、Set、ZSet 类型的元素的个数超过 5000 个，或总大小超过 10MB</li></ul><blockquote><p>Big Key 会造成什么问题？</p></blockquote><p>Big Key 会带来以下四种影响：</p><ul><li><strong>内存分布不均</strong>：集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有 Big Key 的 Redis 节点占用内存多，QPS 也会比较大。</li><li><strong>命令阻塞</strong>：Redis 单线程模型，操作大 Key 耗时，阻塞其他命令。</li><li><strong>网络传输压力</strong>：每次获取 Big Key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li><strong>客户端超时</strong>：由于 Redis 执行命令是单线程处理，然后在操作 Big Key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li></ul><p><strong>解决方案</strong></p><p><strong>（1）开发优化</strong></p><ul><li><strong>数据压缩</strong>：存储前压缩 Value（如 Gzip、Snappy）。</li><li><strong>拆分大对象</strong>：将单个大 Key 拆分为多个小 Key（如 <code>user:1000:info</code> → <code>user:1000:basic</code> + <code>user:1000:details</code>）。</li><li><strong>优化数据结构</strong>： <ul><li>避免巨型 String，改用 Hash、List 等分片存储。</li><li>使用 <code>ziplist</code>、<code>quicklist</code> 等紧凑结构。</li></ul></li></ul><p><strong>（2）业务调整</strong></p><ul><li><strong>精简存储数据</strong>：仅保留高频访问字段（如不存用户全部信息，只存 ID + 核心字段）。</li><li><strong>逻辑优化</strong>：避免业务层生成大 Key（如限制缓存数据大小、分页查询）。</li></ul><p><strong>（3）数据分布优化</strong></p><ul><li><strong>集群分片</strong>：通过 Redis Cluster 分散大 Key 到不同节点。</li><li><strong>本地缓存</strong>：对冷数据使用本地缓存（如 Caffeine），减少 Redis 压力。</li></ul><p><strong>关键点</strong></p><ul><li><strong>预防优于治理</strong>：在设计和开发阶段规避大 Key。</li><li><strong>监控与巡检</strong>：通过 <code>redis-cli --bigkeys</code> 或自定义脚本定期检测大 Key。</li></ul><blockquote><p><strong>如何查找 Redis Big Key？</strong></p></blockquote><p><strong>（1）使用 <code>redis-cli --bigkeys</code></strong></p><p><strong>命令</strong>：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>redis-cli <span class="token parameter variable">-h</span> <span class="token number">127.0</span>.0.1 <span class="token parameter variable">-p</span> <span class="token number">6379</span> <span class="token parameter variable">-a</span> <span class="token string">&quot;password&quot;</span> <span class="token parameter variable">--bigkeys</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>注意事项</strong>：</p><ul><li><strong>推荐在从节点执行</strong>（主节点执行可能阻塞业务）</li><li><strong>低峰期执行</strong> 或 <strong>加 <code>-i</code> 参数控制扫描间隔</strong>（如 <code>-i 0.1</code> 表示每 100ms 扫描一次）</li></ul><p><strong>缺点</strong>：</p><ul><li>只能返回<strong>每种数据类型最大的 1 个 Key</strong>（无法获取 Top N）</li><li>对集合类型<strong>只统计元素个数</strong>，而非实际内存占用</li></ul><p><strong>（2）使用 <code>SCAN</code> + 内存分析命令</strong></p><p><strong>遍历所有 Key</strong>（避免 <code>KEYS *</code> 阻塞 Redis）：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>redis-cli <span class="token parameter variable">--scan</span> <span class="token parameter variable">--pattern</span> <span class="token string">&quot;*&quot;</span> <span class="token operator">|</span> <span class="token keyword">while</span> <span class="token builtin class-name">read</span> key<span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token punctuation">..</span>.<span class="token punctuation">;</span> <span class="token keyword">done</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>分析 Key 大小</strong>：</p><ul><li><strong>String</strong>：<code>STRLEN $key</code>（字节数）</li><li><strong>集合类型</strong>（List/Hash/Set/ZSet）： <ul><li><strong>方法 1</strong>：<code>LLEN</code>/<code>HLEN</code>/<code>SCARD</code>/<code>ZCARD</code>（元素个数 × 预估元素大小）</li><li><strong>方法 2</strong>（Redis 4.0+）：<code>MEMORY USAGE $key</code>（精确内存占用）</li></ul></li></ul><p><strong>优点</strong>：</p><ul><li>可自定义筛选条件（如大小 Top 10）</li><li>精确计算内存占用</li></ul><p><strong>（3）使用 <code>RdbTools</code> 分析 RDB 文件</strong></p><p><strong>命令</strong>：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>rdb dump.rdb <span class="token parameter variable">-c</span> memory <span class="token parameter variable">--bytes</span> <span class="token number">10240</span> <span class="token parameter variable">-f</span> redis.csv  <span class="token comment"># 导出 &gt;10KB 的 Key 到 CSV</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>适用场景</strong>：</p><ul><li>离线分析，不影响线上 Redis</li><li>精准统计<strong>所有 Key 的内存分布</strong></li></ul><p><strong>缺点</strong>：需要 Redis 生成 RDB 快照</p><p><strong>总结：3 种方法对比</strong></p><table><thead><tr><th>方法</th><th>适用场景</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td><strong><code>--bigkeys</code></strong></td><td>快速找出最大 Key</td><td>简单易用</td><td>结果不全面</td></tr><tr><td><strong><code>SCAN</code>+命令</strong></td><td>精确分析内存</td><td>可定制化</td><td>需脚本支持</td></tr><tr><td><strong><code>RdbTools</code></strong></td><td>离线全面分析</td><td>精准无遗漏</td><td>依赖 RDB 文件</td></tr></tbody></table><p><strong>推荐组合</strong>：</p><ul><li>日常监控用 <code>--bigkeys</code>（低峰期执行）</li><li>深度分析用 <code>RdbTools</code>（定期检查 RDB）</li><li>排查问题时用 <code>SCAN</code>+<code>MEMORY USAGE</code>（实时精准定位）</li></ul><h3 id="【中等】如何解决-redis-中的热点-key-问题" tabindex="-1"><a class="header-anchor" href="#【中等】如何解决-redis-中的热点-key-问题" aria-hidden="true">#</a> 【中等】如何解决 Redis 中的热点 key 问题？</h3><p>解决 Redis 中的热点 key 问题的方法：</p><ul><li><p><strong>热点 Key 拆分</strong></p><ul><li><strong>垂直分片</strong>：<code>user:123</code> → <code>user:123:base</code> + <code>user:123:detail</code></li><li><strong>水平分片</strong>：<code>product:views</code> → <code>product:views:shard1</code>/<code>shard2</code></li></ul></li><li><p><strong>多级缓存</strong>：CDN → 本地缓存（Caffeine/Guava） → Redis → DB</p></li><li><p><strong>读写分离</strong>：读请求分流到从节点（配置 <code>replica-read-only yes</code>）</p></li><li><p><strong>流量控制</strong>：</p><ul><li><strong>Sentinel / Hystrix 等流控中间件</strong></li><li><strong>Redis + Lua 限流</strong></li></ul><div class="language-lua line-numbers-mode" data-ext="lua"><pre class="language-lua"><code><span class="token comment">-- 示例：每秒限 100 次访问</span>
<span class="token keyword">local</span> count <span class="token operator">=</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;INCR&#39;</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> count <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">then</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;EXPIRE&#39;</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">end</span>
<span class="token keyword">return</span> count <span class="token operator">&lt;=</span> <span class="token number">100</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>数据预热</strong>：定时任务提前加载热点数据到缓存</p></li><li><p><strong>负载均衡</strong>：</p><ul><li><strong>Redis Cluster</strong>：分散热点 Key 到不同节点</li><li><strong>代理层</strong>：Twemproxy / Redis Proxy / Nginx 实现负载均衡</li></ul></li></ul><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料" aria-hidden="true">#</a> 参考资料</h2>`,103),Re={href:"https://juejin.im/post/5ad6e4066fb9a028d82c4b66",target:"_blank",rel:"noopener noreferrer"},be={href:"https://github.com/doocs/advanced-java#%E7%BC%93%E5%AD%98",target:"_blank",rel:"noopener noreferrer"},ke={href:"https://xiaolincoding.com/redis/base/redis_interview.html",target:"_blank",rel:"noopener noreferrer"};function fe(ye,ve){const n=o("ExternalLinkIcon");return r(),a("div",null,[c,e("p",null,[e("em",null,[s("图来自 "),e("a",g,[s("Redis Explained"),i(n)])])]),p,e("blockquote",null,[e("p",null,[u,s("："),e("a",h,[s("《脚踏两只船的困惑 - Memcached 与 Redis》"),i(n)])])]),m,e("p",null,[s("有两个 Redis 命令可以用于生成 RDB 文件："),e("a",R,[b,i(n)]),s(" 和 "),e("a",k,[f,i(n)]),s("。")]),e("p",null,[e("a",y,[v,i(n)]),s(" 命令由服务器进程直接执行保存操作，直到 RDB 创建完成为止。所以"),_,s("，在阻塞期间，服务器不能响应任何命令请求。")]),e("p",null,[e("a",O,[A,i(n)]),s(" 命令会"),x,s("（fork）一个子进程，由子进程负责创建 RDB 文件，服务器进程继续处理命令请求，所以"),S,s("。")]),E,e("p",null,[s("Redis 支持事务。"),e("a",F,[B,i(n)]),s("、"),e("a",w,[L,i(n)]),s("、"),e("a",C,[I,i(n)]),s(" 和 "),e("a",q,[T,i(n)]),s(" 是 Redis 事务相关的命令。")]),e("p",null,[e("strong",null,[e("a",N,[D,i(n)]),s(" 命令用于开启一个事务，它总是返回 OK。")]),G,s(" 执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当 EXEC 命令被调用时，所有队列中的命令才会被执行。")]),e("p",null,[e("strong",null,[e("a",K,[P,i(n)]),s(" 命令负责触发并执行事务中的所有命令。")])]),M,e("p",null,[e("strong",null,[s("当执行 "),e("a",z,[H,i(n)]),s(" 命令时，事务会被放弃，事务队列会被清空，并且客户端会从事务状态中退出。")])]),e("p",null,[e("strong",null,[e("a",U,[W,i(n)]),s(" 命令可以为 Redis 事务提供 check-and-set （CAS）行为")]),s("。被 "),V,s(" 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 "),X,s(" 执行之前被修改了，那么整个事务都会被取消，"),Z,s(" 返回 "),Y,s(" 来表示事务已经失败。")]),J,e("p",null,[s("Redis 官方的 "),e("a",j,[s("事务特性文档"),i(n)]),s(" 给出的不支持回滚的理由是：")]),Q,e("p",null,[s("另外，Redis 7.0 新增了 "),e("a",$,[s("Redis functions"),i(n)]),s(" 特性，你可以将 Redis functions 看作是比 Lua 更强大的脚本。")]),ee,e("p",null,[s("根据 "),e("a",se,[s("Redis 官方 Benchmark"),i(n)]),s(" 文档的描述，Redis 单机 QPS 能达到 10w+，将近是 Mysql 的 10 倍。")]),ne,e("p",null,[s("图来自 "),e("a",ie,[s("Why is redis so fast?"),i(n)])]),e("blockquote",null,[e("p",null,[te,s("："),e("a",le,[s("【视频】Why is Redis so FAST"),i(n)])])]),oe,e("ul",null,[e("li",null,[e("a",re,[s("RediSearch"),i(n)]),s("：用于实现搜索引擎的模块。")]),e("li",null,[e("a",ae,[s("RedisJSON"),i(n)]),s("：用于处理 JSON 数据的模块。")]),e("li",null,[e("a",de,[s("RedisGraph"),i(n)]),s("：用于实现图形数据库的模块。")]),e("li",null,[e("a",ce,[s("RedisTimeSeries"),i(n)]),s("：用于处理时间序列数据的模块。")]),e("li",null,[e("a",ge,[s("RedisBloom"),i(n)]),s("：用于实现布隆过滤器的模块。")]),e("li",null,[e("a",pe,[s("RedisAI"),i(n)]),s("：用于执行深度学习/机器学习模型并管理其数据的模块。")]),e("li",null,[e("a",ue,[s("RedisCell"),i(n)]),s("：用于实现分布式限流的模块。")])]),e("p",null,[s("关于 Redis 模块的详细介绍，可以查看官方文档："),e("a",he,[s("https://redis.io/modules。"),i(n)])]),me,e("ul",null,[e("li",null,[e("a",Re,[s("面试中关于 Redis 的问题看这篇就够了"),i(n)])]),e("li",null,[e("a",be,[s("advanced-java"),i(n)])]),e("li",null,[e("a",ke,[s("Redis 常见面试题"),i(n)])])])])}const Ae=l(d,[["render",fe],["__file","index.html.vue"]]);export{Ae as default};
