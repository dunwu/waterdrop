import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as i,c as n,a,b as t,d as l,e as s}from"./app-db9f6e62.js";const d={},c=s(`<h1 id="kafka-面试" tabindex="-1"><a class="header-anchor" href="#kafka-面试" aria-hidden="true">#</a> Kafka 面试</h1><h2 id="kafka-简介" tabindex="-1"><a class="header-anchor" href="#kafka-简介" aria-hidden="true">#</a> Kafka 简介</h2><h3 id="【简单】kafka-是什么-kafka-有哪些应用场景" tabindex="-1"><a class="header-anchor" href="#【简单】kafka-是什么-kafka-有哪些应用场景" aria-hidden="true">#</a> 【简单】Kafka 是什么？Kafka 有哪些应用场景？</h3><p><strong>Apache Kafka 是一款开源的消息引擎系统，也是一个分布式流计算平台，此外，还可以作为数据存储</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070719480.gif" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>Kafka 的核心功能如下：</p><ul><li><strong>消息队列</strong>：用作高吞吐量的消息系统，将消息从一个系统传递到另一个系统</li><li><strong>日志收集</strong>：集中收集日志数据，然后通过 Kafka 传递到实时监控系统或存储系统</li><li><strong>流计算</strong>：处理实时数据流，将数据传递给实时计算系统，如 Apache Storm 或 Apache Flink</li><li><strong>指标收集和监控</strong>：收集来自不同服务的监控指标，统一存储和处理</li><li><strong>事件溯源</strong>：记录事件发生的历史，以便稍后进行数据回溯或重新处理</li></ul><h3 id="【简单】kafka-有哪些核心术语" tabindex="-1"><a class="header-anchor" href="#【简单】kafka-有哪些核心术语" aria-hidden="true">#</a> 【简单】Kafka 有哪些核心术语？</h3><p>Kafka 的核心术语如下：</p><ul><li><strong>消息</strong> - Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。</li><li><strong>主题</strong> - Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。</li><li><strong>分区</strong> - Partition。一个有序不变的消息序列。每个主题下可以有多个分区。</li><li><strong>消息位移</strong> - Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。</li><li><strong>副本</strong> - Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。</li><li><strong>生产者</strong> - Producer。向主题发布新消息的应用程序。</li><li><strong>消费者</strong> - Consumer。从主题订阅新消息的应用程序。</li><li><strong>消费者位移</strong> - Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。</li><li><strong>消费者组</strong> - Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。</li><li><strong>分区再均衡</strong> - Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070720162.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Kafka 的三层消息架构：</p><ul><li>第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。</li><li>第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。</li><li>第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。</li><li>最后，客户端程序只能与分区的领导者副本进行交互。</li></ul><h2 id="kafka-存储" tabindex="-1"><a class="header-anchor" href="#kafka-存储" aria-hidden="true">#</a> Kafka 存储</h2><h3 id="【中等】kafka-是如何存储数据的" tabindex="-1"><a class="header-anchor" href="#【中等】kafka-是如何存储数据的" aria-hidden="true">#</a> 【中等】Kafka 是如何存储数据的？</h3><h4 id="kafka-逻辑存储" tabindex="-1"><a class="header-anchor" href="#kafka-逻辑存储" aria-hidden="true">#</a> Kafka 逻辑存储</h4><p>Kafka 的数据结构采用三级结构，即：主题（Topic）、分区（Partition）、消息（Record）。</p><p>在 Kafka 中，任意一个 Topic 维护了一组 Partition 日志，如下所示：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070720162.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>请注意：这里的主题只是一个逻辑上的抽象概念，实际上，<strong>Kafka 的基本存储单元是 Partition</strong>。Partition 无法在多个 Broker 间进行再细分，也无法在同一个 Broker 的多个磁盘上进行再细分。所以，分区的大小受到单个挂载点可用空间的限制。</p><p>Partiton 命名规则为 Topic 名称 + 有序序号，第一个 Partiton 序号从 0 开始，序号最大值为 Partition 数量减 1。</p><h4 id="kafka-物理存储" tabindex="-1"><a class="header-anchor" href="#kafka-物理存储" aria-hidden="true">#</a> Kafka 物理存储</h4><p><code>Log</code> 是 Kafka 用于表示日志文件的组件。每个 Partiton 对应一个 <code>Log</code> 对象，在物理磁盘上则对应一个目录。如：创建一个双分区的主题 <code>test</code>，那么，Kafka 会在磁盘上创建两个子目录：<code>test-0</code> 和 <code>test-1</code>；而在服务器端，这就对应两个 <code>Log</code> 对象。</p><p>因为在一个大文件中查找和删除消息是非常耗时且容易出错的。所以，Kafka 将每个 Partition 切割成若干个片段，即日志段（Log Segment）。<strong>默认每个 Segment 大小不超过 1G，且只包含 7 天的数据</strong>。如果 Segment 的消息量达到 1G，那么该 Segment 会关闭，同时打开一个新的 Segment 进行写入。</p><p>Broker 会为 Partition 里的每个 Segment 打开一个文件句柄（包括不活跃的 Segment），因此打开的文件句柄数通常会比较多，这个需要适度调整系统的进程文件句柄参数。<strong>正在写入的分片称为活跃片段（active segment），活跃片段永远不会被删除</strong>。</p><p>Segment 文件命名规则：Partition 全局的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070721654.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Segment 文件可以分为两类：</p><ul><li>索引文件 <ul><li>偏移量索引文件（ <code>.index</code> ）</li><li>时间戳索引文件（ <code>.timeindex</code> ）</li><li>已终止事务的索引文件（<code>.txnindex</code>）：如果没有使用 Kafka 事务，则不会创建该文件</li></ul></li><li>日志数据文件（<code>.log</code>）</li></ul><h3 id="【困难】kafka-的存储是如何设计的-日志文件的存储格式是什么-如何保证存储效率" tabindex="-1"><a class="header-anchor" href="#【困难】kafka-的存储是如何设计的-日志文件的存储格式是什么-如何保证存储效率" aria-hidden="true">#</a> 【困难】Kafka 的存储是如何设计的？日志文件的存储格式是什么？如何保证存储效率？</h3><p><strong>性能优化组合拳</strong></p><ul><li>写：<strong>顺序追加</strong> + <strong>零拷贝</strong> + <strong>分段管理</strong><ul><li>顺序追加：日志追加写入到磁盘（顺序 I/O），提高写入性能</li><li>零拷贝：<code>sendfile</code> 系统调用，数据直接从磁盘→网络，减少 CPU 拷贝开销</li><li>分段管理： <ul><li>Topic→Partitions</li><li>Partition→有序 Log</li><li>Log→Segments</li></ul></li></ul></li><li>读：<strong>页缓存</strong> + <strong>双索引</strong><ul><li>页缓存：缓存热点数据，减少磁盘 IO</li><li>双索引：xxx.index（偏移量索引） + xxx.timeindex（时间索引），加速查询</li></ul></li><li>存：<strong>压缩</strong> + <strong>双维度保留策略</strong><ul><li>批量压缩：支持 GZIP、Snappy 等算法</li><li>默认超出 7 天或 1GB 删除</li></ul></li></ul><p><strong>扩展+高可用</strong></p><ul><li>分区+副本，支持水平扩展与容错。</li><li>ISR 机制保证一致性</li></ul><h3 id="【中等】kafka-的消息是如何持久化的-它默认的存储机制是什么" tabindex="-1"><a class="header-anchor" href="#【中等】kafka-的消息是如何持久化的-它默认的存储机制是什么" aria-hidden="true">#</a> 【中等】Kafka 的消息是如何持久化的？它默认的存储机制是什么？</h3><p>Kafka 的持久化设计使其兼具 <strong>高吞吐、低延迟、高可靠</strong> 特性，适用于大规模消息处理场景。</p><p>Kafka 使用 <strong>磁盘存储</strong> 消息，采用 <strong>顺序写入</strong> 方式，提高 I/O 效率。消息以 <strong>追加（append-only）</strong> 方式写入当前日志文件末尾。</p><p><strong>日志分段（Log Segmentation）</strong></p><ul><li>日志文件被划分为多个 <strong>段（segment）</strong>，每个段大小可配置（如 1GB）。</li><li>当前段写满后，Kafka 创建新段继续写入，便于日志管理和清理。</li></ul><p><strong>日志清理（Log Compaction）</strong></p><p>有两种日志清理策略：</p><ul><li><strong>基于时间</strong>：删除超过保留时间（如 7 天）的日志段。</li><li><strong>基于键值（Log Compaction）</strong>：对相同 Key 的消息，仅保留最新版本，减少存储占用。</li></ul><p><strong>零拷贝（Zero-Copy）</strong></p><p>利用 Linux 零拷贝技术，数据从 <strong>磁盘 → 网络</strong> 直接在内核态传输，避免用户态数据复制，提升传输效率。</p><p><strong>页缓存（Page Cache）</strong></p><ul><li>消息先写入操作系统的 <strong>页缓存</strong>，再批量刷盘，减少磁盘 I/O。</li><li>读取时优先从页缓存获取，提高性能。</li></ul><p><strong>分区（Partition）和副本（Replica）</strong></p><ul><li>数据按 <strong>分区（Partition）</strong> 存储，每个分区是一个独立日志文件。</li><li><strong>副本机制</strong>：分区数据复制到多个节点（Leader + Followers），确保 <strong>高可用</strong> 和 <strong>数据可靠性</strong>。</li></ul><h3 id="【困难】kafka-如何检索数据" tabindex="-1"><a class="header-anchor" href="#【困难】kafka-如何检索数据" aria-hidden="true">#</a> 【困难】Kafka 如何检索数据？</h3><ul><li><strong>动态消费起点</strong><ul><li>支持从任意有效偏移量开始消费</li></ul></li><li><strong>稀疏索引设计</strong><ul><li>索引文件（<code>.index</code>）存储 offset→position 映射</li><li>采用<strong>间隔存储</strong>（可配置<code>index.interval.bytes</code>）</li><li>每个条目包含： <ul><li>消息偏移量（offset）</li><li>物理位置（position）</li></ul></li></ul></li><li><strong>索引自愈能力</strong><ul><li>索引无校验和，损坏后自动重建</li><li>删除索引文件安全（Kafka 自动重新生成）</li></ul></li><li><strong>文件对应关系</strong><ul><li>每个日志分段（Segment）对应：</li><li>数据文件（<code>.log</code>）</li><li>索引文件（<code>.index</code>）</li><li>按起始偏移量命名（如 <code>00000000000000368769.index</code>）</li></ul></li></ul><p>下面是 Kafka 中分段的日志数据文件和偏移量索引文件的对应映射关系图（其中也说明了如何按照起始偏移量来定位到日志数据文件中的具体消息）。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070722556.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【困难】kafka-如何清理数据" tabindex="-1"><a class="header-anchor" href="#【困难】kafka-如何清理数据" aria-hidden="true">#</a> 【困难】Kafka 如何清理数据？</h3><p><strong>日志分段结构</strong></p><ul><li><strong>干净段</strong>：这部分消息之前已经被清理过，每个键只存在一个值。</li><li><strong>污浊段</strong>：在上一次清理后写入的新消息。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200621135557.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>如果 Kafka 启用了清理功能（通过 <code>log.cleaner.enabled</code> 配置），每个 Broker 启动清理管理线程 + N 个清理线程（按分区分配）</p><p><strong>内存映射构建</strong>：</p><ul><li>Key 结构：16 字节哈希 + 8 字节位移（24 字节/记录）</li><li>1GB 日志段≈1 百万消息→仅需 24MB 内存映射</li></ul><p>对于一个段，清理前后的效果如下：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200621140117.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p><strong>特殊删除操作</strong></p><ul><li><strong>逻辑删除</strong>：生产者发送<code>key+null</code>消息</li><li><strong>保留期</strong>：延迟物理删除确保消费者感知</li><li><strong>最终清除</strong>：超时后彻底移除键</li></ul><p><strong>资源控制</strong></p><ul><li>全局内存池分配（如 1GB 内存/5 线程→200MB 每线程）</li><li>分批次处理（优先清理最老污浊段）</li></ul><h2 id="生产者和消费者" tabindex="-1"><a class="header-anchor" href="#生产者和消费者" aria-hidden="true">#</a> 生产者和消费者</h2><h3 id="todo" tabindex="-1"><a class="header-anchor" href="#todo" aria-hidden="true">#</a> TODO</h3><p>【简单】Kafka 中的 Producer 和 Consumer 分别是什么角色？它们如何进行消息的生产和消费？<br> 【简单】Kafka 中的 Consumer Group 是什么？它在消息消费中起到什么作用？<br> 【中等】Kafka 的 Producer 是如何发送消息的？如何通过批量发送提高吞吐量？<br> 【中等】Kafka 中的 Consumer 是如何订阅 Topic 的？它的消费模式有哪些？<br> 【中等】Kafka 中的 Consumer Group 是如何进行负载均衡的？它如何保证高效消费？<br> 【中等】Kafka 中的批量消费是如何工作的？如何通过批量消费提高处理效率？<br> 【困难】在 Kafka 中，如何实现消息的过滤？常见的消息过滤策略有哪些？<br> 【中等】Kafka 的反压机制是如何实现的？如何避免生产者压垮消费者？<br> 【困难】在 Kafka 中，如何通过配置优化 Producer 和 Consumer 的性能？<br> 【困难】在 Kafka 中，如何进行批量消息发送和消费？如何优化批量操作的性能？<br> 【困难】Kafka 的内部状态是如何管理的？如何通过状态管理优化性能？<br> 【困难】在 Kafka 中，如何实现幂等性 Producer？它对消息处理的意义是什么？</p><h3 id="【中等】kafka-发送消息的工作流程是怎样的" tabindex="-1"><a class="header-anchor" href="#【中等】kafka-发送消息的工作流程是怎样的" aria-hidden="true">#</a> 【中等】Kafka 发送消息的工作流程是怎样的？</h3><p>Kafka 生产者用一个 <code>ProducerRecord</code> 对象来抽象一条要发送的消息， <code>ProducerRecord</code> 对象需要包含目标主题和要发送的内容，还可以指定键或分区。其发送消息流程如下：</p><p>（1）<strong>序列化</strong> - 生产者要先把键和值序列化成字节数组，这样它们才能够在网络中传输。</p><p>（2）<strong>分区</strong> - 数据被传给分区器。如果在 <code>ProducerRecord</code> 中已经指定了分区，那么分区器什么也不会做；否则，分区器会根据 <code>ProducerRecord</code> 的键来选择一个分区。选定分区后，生产者就知道该把消息发送给哪个主题的哪个分区。</p><p>（3）<strong>批次传输</strong> - 接着，这条记录会被添加到一个记录批次中。这个批次中的所有消息都会被发送到相同的主题和分区上。有一个独立的线程负责将这些记录批次发送到相应 Broker 上。</p><ul><li><strong>批次，就是一组消息，这些消息属于同一个主题和分区</strong>。</li><li>发送时，会把消息分成批次传输，如果每次只发送一个消息，会占用大量的网路开销。</li></ul><p>（4）<strong>响应</strong> - 服务器收到消息会返回一个响应。</p><ul><li>如果<strong>成功</strong>，则返回一个 <code>RecordMetaData</code> 对象，它包含了主题、分区、偏移量；</li><li>如果<strong>失败</strong>，则返回一个错误。生产者在收到错误后，可以进行重试，重试次数可以在配置中指定。失败一定次数后，就返回错误消息。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200528224323.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>生产者向 Broker 发送消息时是怎么确定向哪一个 Broker 发送消息？</p><ul><li>生产者会向任意 broker 发送一个元数据请求（<code>MetadataRequest</code>），获取到每一个分区对应的 Leader 信息，并缓存到本地。</li><li>生产者在发送消息时，会指定 Partition 或者通过 key 得到到一个 Partition，然后根据 Partition 从缓存中获取相应的 Leader 信息。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200621113043.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h3 id="【简单】kafka-为什么要支持消费者群组" tabindex="-1"><a class="header-anchor" href="#【简单】kafka-为什么要支持消费者群组" aria-hidden="true">#</a> 【简单】Kafka 为什么要支持消费者群组？</h3><h4 id="消费者" tabindex="-1"><a class="header-anchor" href="#消费者" aria-hidden="true">#</a> 消费者</h4><p>每个 Consumer 的唯一元数据是该 Consumer 在日志中消费的位置。这个偏移量是由 Consumer 控制的：Consumer 通常会在读取记录时线性的增加其偏移量。但实际上，由于位置由 Consumer 控制，所以 Consumer 可以采用任何顺序来消费记录。</p><p><strong>一条消息只有被提交，才会被消费者获取到</strong>。如下图，只能消费 Message0、Message1、Message2：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200621113917.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h4 id="消费者群组" tabindex="-1"><a class="header-anchor" href="#消费者群组" aria-hidden="true">#</a> 消费者群组</h4><p><strong>Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制</strong>。</p><p>Kafka 的写入数据量很庞大，如果只有一个消费者，消费消息速度很慢，时间长了，就会造成数据积压。为了减少数据积压，Kafka 支持消费者群组，可以让多个消费者并发消费消息，对数据进行分流。</p><p>Kafka 消费者从属于消费者群组，<strong>一个群组里的 Consumer 订阅同一个 Topic，一个主题有多个 Partition，每一个 Partition 只能隶属于消费者群组中的一个 Consumer</strong>。</p><p>如果超过主题的分区数量，那么有一部分消费者就会被闲置，不会接收到任何消息。</p><p>同一时刻，<strong>一条消息只能被同一消费者组中的一个消费者实例消费</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070722981.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>不同消费者群组之间互不影响</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070723165.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【中等】如何消费-kafka-消息" tabindex="-1"><a class="header-anchor" href="#【中等】如何消费-kafka-消息" aria-hidden="true">#</a> 【中等】如何消费 Kafka 消息？</h3><p>Kafka 消费者通过 <code>pull</code> 模式来获取消息，但是获取消息时并不是立刻返回结果，需要考虑两个因素：</p><ul><li>消费者通过 <code>customer.poll(time)</code> 中设置等待时间</li><li>Broker 会等待累计一定量数据，然后发送给消费者。这样可以减少网络开销。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070724283.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><code>pull</code> 除了获取消息外，还有其他作用：</p><ul><li><strong>发送心跳信息</strong>。消费者通过向被指派为群组协调器的 Broker 发送心跳来维护他和群组的从属关系，当机器宕掉后，群组协调器触发再均衡。</li></ul><h2 id="分区" tabindex="-1"><a class="header-anchor" href="#分区" aria-hidden="true">#</a> 分区</h2><h3 id="todo-1" tabindex="-1"><a class="header-anchor" href="#todo-1" aria-hidden="true">#</a> TODO</h3><p>【中等】Kafka 中的分区副本机制是如何工作的？如何设置副本数？<br> 【困难】Kafka 中的 Controller 是什么角色？它在集群中的作用是什么？<br> 【困难】Kafka 的集群如何进行扩展？扩展过程中需要注意哪些问题？<br> 【困难】Kafka 中的分区分配策略有哪些？如何选择合适的策略？<br> 【困难】在 Kafka 中，如何设计合理的分区策略来优化消息的读写性能？<br> 【困难】在 Kafka 中，如何优化分区的读写性能？有哪些常见的调优策略？<br> 【困难】Kafka 是如何处理消费者再均衡的？Rebalance 的代价和优化策略有哪些？</p><h3 id="【中等】什么是分区-为什么要分区" tabindex="-1"><a class="header-anchor" href="#【中等】什么是分区-为什么要分区" aria-hidden="true">#</a> 【中等】什么是分区？为什么要分区？</h3><p>Kafka 的数据结构采用三级结构，即：主题（Topic）、分区（Partition）、消息（Record）。</p><p>在 Kafka 中，任意一个 Topic 维护了一组 Partition 日志，如下所示：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/mq/kafka/kafka-log-anatomy.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>每个 Partition 都是一个单调递增的、不可变的日志记录，以不断追加的方式写入数据。Partition 中的每条记录会被分配一个单调递增的 id 号，称为偏移量（Offset），用于唯一标识 Partition 内的每条记录。</p><p>为什么 Kafka 的数据结构采用三级结构？</p><p><strong>分区的作用就是提供负载均衡的能力</strong>，以实现系统的高伸缩性（Scalability）。</p><p>不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，我们还可以通过添加新的机器节点来增加整体系统的吞吐量。</p><h3 id="【中等】kafka-的分区策略是怎样的" tabindex="-1"><a class="header-anchor" href="#【中等】kafka-的分区策略是怎样的" aria-hidden="true">#</a> 【中等】Kafka 的分区策略是怎样的？</h3><p>所谓分区策略是决定生产者将消息发送到哪个分区的算法，也就是负载均衡算法。</p><p>Kafka 生产者发送消息使用的对象 <code>ProducerRecord</code> ，可以选填 Partition 和 Key。不过，大多数应用会用到 key。key 有两个作用：作为消息的附加信息；也可以用来决定消息该被写到 Topic 的哪个 Partition，拥有相同 key 的消息将被写入同一个 Partition。</p><p><strong>如果 <code>ProducerRecord</code> 指定了 Partition，则分区器什么也不做</strong>，否则分区器会根据 key 选择一个 Partition 。</p><ul><li>没有 key 时的分发逻辑：每隔 <code>topic.metadata.refresh.interval.ms</code> 的时间，随机选择一个 partition。这个时间窗口内的所有记录发送到这个 partition。发送数据出错后会重新选择一个 partition。</li><li>根据 key 分发：Kafka 的选择分区策略是：根据 key 求 hash 值，然后将 hash 值对 partition 数量求模。这里的关键点在于，<strong>同一个 key 总是被映射到同一个 Partition 上</strong>。所以，在选择分区时，Kafka 会使用 Topic 的所有 Partition ，而不仅仅是可用的 Partition。这意味着，<strong>如果写入数据的 Partition 是不可用的，那么就会出错</strong>。</li></ul><h3 id="【中等】如何自定义分区策略" tabindex="-1"><a class="header-anchor" href="#【中等】如何自定义分区策略" aria-hidden="true">#</a> 【中等】如何自定义分区策略？</h3><p>如果 Kafka 的默认分区策略无法满足实际需要，可以自定义分区策略。需要显式地配置生产者端的参数 <code>partitioner.class</code>。这个参数该怎么设定呢？</p><p>首先，要实现 <code>org.apache.kafka.clients.producer.Partitioner</code> 接口。这个接口定义了两个方法：<code>partition</code> 和 <code>close</code>，通常只需要实现最重要的 <code>partition</code> 方法。我们来看看这个方法的方法签名：</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token keyword">int</span> <span class="token function">partition</span><span class="token punctuation">(</span><span class="token class-name">String</span> topic<span class="token punctuation">,</span> <span class="token class-name">Object</span> key<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> keyBytes<span class="token punctuation">,</span> <span class="token class-name">Object</span> value<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> valueBytes<span class="token punctuation">,</span> <span class="token class-name">Cluster</span> cluster<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这里的 <code>topic</code>、<code>key</code>、<code>keyBytes</code>、<code>value</code>和 <code>valueBytes</code> 都属于消息数据，<code>cluster</code> 则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。Kafka 给你这么多信息，就是希望让你能够充分地利用这些信息对消息进行分区，计算出它要被发送到哪个分区中。</p><p>接着，设置 <code>partitioner.class</code> 参数为自定义类的全限定名，那么生产者程序就会按照你的代码逻辑对消息进行分区。</p><p>负载均衡算法常见的有：</p><ul><li>随机算法</li><li>轮询算法</li><li>最小活跃数算法</li><li>源地址哈希算法</li></ul><p>可以根据实际需要去实现。</p><h3 id="【困难】kafka-如何实现分区再均衡" tabindex="-1"><a class="header-anchor" href="#【困难】kafka-如何实现分区再均衡" aria-hidden="true">#</a> 【困难】Kafka 如何实现分区再均衡？</h3><h4 id="什么是分区再均衡" tabindex="-1"><a class="header-anchor" href="#什么是分区再均衡" aria-hidden="true">#</a> 什么是分区再均衡</h4><p>分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为<strong>分区再均衡（Rebalance）</strong>。<strong>Rebalance 实现了消费者群组的高可用性和伸缩性</strong>。</p><p><strong>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区</strong>。比如某个 Group 下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的 Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5 个分区。这个分配的过程就叫 Rebalance。</p><p>当在群组里面新增/移除消费者或者新增/移除 kafka 集群 broker 节点时，群组协调器 Broker 会触发再均衡，重新为每一个 Partition 分配消费者。<strong>Rebalance 期间，消费者无法读取消息，造成整个消费者群组一小段时间的不可用。</strong></p><h4 id="何时生分区再均衡" tabindex="-1"><a class="header-anchor" href="#何时生分区再均衡" aria-hidden="true">#</a> 何时生分区再均衡</h4><p>分区再均衡的触发时机有三种：</p><ul><li><strong>消费者群组成员数发生变更</strong>。比如有新的 Consumer 加入群组或者离开群组，或者是有 Consumer 实例崩溃被“踢出”群组。 <ul><li>新增消费者。consumer 订阅主题之后，第一次执行 poll 方法</li><li>移除消费者。执行 <code>consumer.close()</code> 操作或者消费客户端宕机，就不再通过 poll 向群组协调器发送心跳了，当群组协调器检测次消费者没有心跳，就会触发再均衡。</li></ul></li><li><strong>订阅主题数发生变更</strong>。Consumer Group 可以使用正则表达式的方式订阅主题，比如 <code>consumer.subscribe(Pattern.compile(“t.*c”))</code> 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生 Rebalance。</li><li><strong>订阅主题的分区数发生变更</strong>。Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。 <ul><li>新增 broker。如重启 broker 节点</li><li>移除 broker。如 kill 掉 broker 节点。</li></ul></li></ul><h4 id="分区再均衡的过程" tabindex="-1"><a class="header-anchor" href="#分区再均衡的过程" aria-hidden="true">#</a> 分区再均衡的过程</h4><p><strong>Rebalance 是通过消费者群组中的称为“群主”消费者客户端进行的</strong>。</p><p>（1）选择群主</p><p>当消费者要加入群组时，会向群组协调器发送一个 JoinGroup 请求。第一个加入群组的消费者将成为“群主”。<strong>群主从协调器那里获取群组的活跃成员列表，并负责给每一个消费者分配分区</strong>。</p><blockquote><p>所谓协调者，在 Kafka 中对应的术语是 Coordinator，它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。具体来讲，Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。</p></blockquote><p>（2）消费者通过向被指派为群组协调器（Coordinator）的 Broker 定期发送心跳来维持它们和群组的从属关系以及它们对分区的所有权。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070723810.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>（3）群主从群组协调器获取群组成员列表，然后给每一个消费者进行分配分区 Partition。有两种分配策略：Range 和 RoundRobin。</p><ul><li><strong>Range 策略</strong>，就是把若干个连续的分区分配给消费者，如存在分区 1-5，假设有 3 个消费者，则消费者 1 负责分区 1-2, 消费者 2 负责分区 3-4，消费者 3 负责分区 5。</li><li><strong>RoundRoin 策略</strong>，就是把所有分区逐个分给消费者，如存在分区 1-5，假设有 3 个消费者，则分区 1-&gt;消费 1，分区 2-&gt;消费者 2，分区 3&gt;消费者 3，分区 4&gt;消费者 1，分区 5-&gt;消费者 2。</li></ul><p>（4）群主分配完成之后，把分配情况发送给群组协调器。</p><p>（5）群组协调器再把这些信息发送给消费者。<strong>每个消费者只能看到自己的分配信息，只有群主知道所有消费者的分配信息</strong>。</p><h4 id="如何判定消费者已经死亡" tabindex="-1"><a class="header-anchor" href="#如何判定消费者已经死亡" aria-hidden="true">#</a> 如何判定消费者已经死亡</h4><p>消费者通过向被指定为群组协调器的 Broker 发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的。消费者会在轮询消息或提交偏移量时发送心跳。如果消费者超时未发送心跳，会话就会过期，群组协调器认定它已经死亡，就会触发一次再均衡。</p><p>当一个消费者要离开群组时，会通知协调器，协调器会立即触发一次再均衡，尽量降低处理停顿。</p><h4 id="查找协调者" tabindex="-1"><a class="header-anchor" href="#查找协调者" aria-hidden="true">#</a> 查找协调者</h4><p>所有 Broker 在启动时，都会创建和开启相应的 Coordinator 组件。也就是说，<strong>所有 Broker 都有各自的 Coordinator 组件</strong>。那么，Consumer Group 如何确定为它服务的 Coordinator 在哪台 Broker 上呢？答案就在我们之前说过的 Kafka 内部位移主题 <code>__consumer_offsets</code> 身上。</p><p>目前，Kafka 为某个 Consumer Group 确定 Coordinator 所在的 Broker 的算法有 2 个步骤。</p><ol><li><p>第 1 步：确定由位移主题的哪个分区来保存该 Group 数据：<code>partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)</code>。</p></li><li><p>第 2 步：找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。</p></li></ol><h3 id="【困难】分区再均衡存在什么问题-如何避免分区再均衡" tabindex="-1"><a class="header-anchor" href="#【困难】分区再均衡存在什么问题-如何避免分区再均衡" aria-hidden="true">#</a> 【困难】分区再均衡存在什么问题？如何避免分区再均衡？</h3><h4 id="分区再均衡的问题" tabindex="-1"><a class="header-anchor" href="#分区再均衡的问题" aria-hidden="true">#</a> 分区再均衡的问题</h4><ul><li>首先，Rebalance 过程对 Consumer Group 消费过程有极大的影响。在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。</li><li>其次，目前 Rebalance 的设计是所有 Consumer 实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。</li><li>最后，Rebalance 实在是太慢了。</li></ul><h4 id="避免分区再均衡" tabindex="-1"><a class="header-anchor" href="#避免分区再均衡" aria-hidden="true">#</a> 避免分区再均衡</h4><p>通过前文，我们已经知道了：分区再均衡的代价很高，应该尽量避免不必要的分区再均衡，以整体提高 Consumer 的吞吐量。</p><p>分区再均衡发生的时机有三个：</p><ul><li><strong>消费群组成员数量发生变化</strong></li><li><strong>订阅主题数量发生变化</strong></li><li><strong>订阅主题的分区数发生变化</strong></li></ul><p>后面两个通常都是运维的主动操作，所以它们引发的 Rebalance 大都是不可避免的。实际上，大部分情况下，导致分区再均衡的原因是：消费群组成员数量发生变化。</p><p>有两种情况，消费者并没有宕机，但也被视为消亡：</p><ul><li>未及时发送心跳</li><li>Consumer 消费时间过长</li></ul><h5 id="未及时发送心跳" tabindex="-1"><a class="header-anchor" href="#未及时发送心跳" aria-hidden="true">#</a> 未及时发送心跳</h5><p><strong>第一类非必要 Rebalance 是因为未能及时发送心跳</strong>，导致 Consumer 被“踢出”Group 而引发的。因此，<strong>需要合理设置会话超时时间</strong>。这里给出一些推荐数值，你可以“无脑”地应用在你的生产环境中。</p><ul><li>设置 <code>session.timeout.ms</code> = 6s。</li><li>设置 <code>heartbeat.interval.ms</code> = 2s。</li><li>要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 <code>session.timeout.ms</code> &gt;= 3 * <code>heartbeat.interval.ms</code>。</li></ul><p>将 <code>session.timeout.ms</code> 设置成 6s 主要是为了让 Coordinator 能够更快地定位已经挂掉的 Consumer。毕竟，我们还是希望能尽快揪出那些“尸位素餐”的 Consumer，早日把它们踢出 Group。希望这份配置能够较好地帮助你规避第一类“不必要”的 Rebalance。</p><h5 id="consumer-消费时间过长" tabindex="-1"><a class="header-anchor" href="#consumer-消费时间过长" aria-hidden="true">#</a> Consumer 消费时间过长</h5><p><strong>第二类非必要 Rebalance 是 Consumer 消费时间过长导致的</strong>。此时，<strong><code>max.poll.interval.ms</code></strong> 参数值的设置显得尤为关键。如果要避免非预期的 Rebalance，你最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。</p><h5 id="gc-参数" tabindex="-1"><a class="header-anchor" href="#gc-参数" aria-hidden="true">#</a> GC 参数</h5><p>如果你按照上面的推荐数值恰当地设置了这几个参数，却发现还是出现了 Rebalance，那么我建议你去排查一下 <strong>Consumer 端的 GC 表现</strong>，比如是否出现了频繁的 Full GC 导致的长时间停顿，从而引发了 Rebalance。为什么特意说 GC？那是因为在实际场景中，我见过太多因为 GC 设置不合理导致程序频发 Full GC 而引发的非预期 Rebalance 了。</p><h2 id="复制" tabindex="-1"><a class="header-anchor" href="#复制" aria-hidden="true">#</a> 复制</h2><h3 id="todo-2" tabindex="-1"><a class="header-anchor" href="#todo-2" aria-hidden="true">#</a> TODO</h3><p>【简单】Kafka 的副本机制是如何实现的？它对数据可靠性有何保障？<br> 【中等】在 Kafka 中，什么是 Leader 和 Follower？它们在副本机制中如何协同工作？</p><h3 id="【中等】kafka-如何管理副本" tabindex="-1"><a class="header-anchor" href="#【中等】kafka-如何管理副本" aria-hidden="true">#</a> 【中等】Kafka 如何管理副本？</h3><p>副本机制是分布式系统实现高可用的不二法门，Kafka 也不例外。</p><p>副本机制有哪些好处？</p><ol><li><strong>提供可用性</strong>：有句俗语叫：鸡蛋不要放在一个篮子里。副本机制也是一个道理——当部分节点宕机时，系统仍然可以依靠其他正常运转的节点，从整体上对外继续提供服务。</li><li><strong>提供伸缩性</strong>：通过增加、减少机器可以控制系统整体的吞吐量。</li><li><strong>改善数据局部性</strong>：允许将数据放入与用户地理位置相近的地方，从而降低系统延时。</li></ol><p>但是，Kafka 只实现了第一个好处，原因后面会阐述。</p><ul><li>每个 Partition 都有一个 Leader，零个或多个 Follower。</li><li>Leader 处理一切对 Partition （分区）的读写请求；而 Follower 只需被动的同步 Leader 上的数据。</li><li>同一个 Topic 的不同 Partition 会分布在多个 Broker 上，而且一个 Partition 还会在其他的 Broker 上面进行备份。</li></ul><h4 id="kafka-副本角色" tabindex="-1"><a class="header-anchor" href="#kafka-副本角色" aria-hidden="true">#</a> Kafka 副本角色</h4><p>Kafka 使用 Topic 来组织数据，每个 Topic 被分为若干个 Partition，每个 Partition 有多个副本。每个 Broker 可以保存成百上千个属于不同 Topic 和 Partition 的副本。<strong>Kafka 副本的本质是一个只能追加写入的提交日志</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070726284.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Kafka 副本有两种角色：</p><ul><li><strong>Leader 副本（主）</strong>：每个 Partition 都有且仅有一个 Leader 副本。为了保证数据一致性，<strong>Leader 处理一切对 Partition （分区）的读写请求</strong>；</li><li><strong>Follower 副本（从）</strong>：Leader 副本以外的副本都是 Follower 副本。<strong>Follower 唯一的任务就是从 Leader 那里复制消息，保持与 Leader 一致的状态</strong>。</li><li>如果 Leader 宕机，其中一个 Follower 会被选举为新的 Leader。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070726185.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>为了与 Leader 保持同步，Follower 向 Leader 发起获取数据的请求，这种请求与消费者为了读取消息而发送的请求是一样的。请求消息里包含了 Follower 想要获取消息的偏移量，而这些偏移量总是有序的。</p><p>Leader 另一个任务是搞清楚哪个 Follower 的状态与自己是一致的。通过查看每个 Follower 请求的最新偏移量，Leader 就会知道每个 Follower 复制的进度。如果跟随者在 10s 内没有请求任何消息，或者虽然在请求消息，但是在 10s 内没有请求最新的数据，那么它就会被认为是<strong>不同步</strong>的。<strong>如果一个副本是不同步的，在 Leader 失效时，就不可能成为新的 Leader</strong>——毕竟它没有包含全部的消息。</p><p>除了当前首领之外，每个分区都有一个首选首领——创建 Topic 时选定的首领就是分区的首选首领。之所以叫首选 Leader，是因为在创建分区时，需要在 Broker 之间均衡 Leader。</p><h4 id="isr" tabindex="-1"><a class="header-anchor" href="#isr" aria-hidden="true">#</a> ISR</h4><p>ISR 即 In-sync Replicas，表示同步副本。Follower 副本不提供服务，只是定期地异步拉取领导者副本中的数据而已。既然是异步的，说明和 Leader 并非数据强一致性的。</p><p><strong>判断 Follower 是否与 Leader 同步的标准</strong>：</p><p>Kafka Broker 端参数 <code>replica.lag.time.max.ms</code> 参数，指定了 Follower 副本能够落后 Leader 副本的最长时间间隔，默认为 10s。这意味着：只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是<strong>同步</strong>的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。</p><p>ISR 是一个动态调整的集合，会不断将同步副本加入集合，将不同步副本移除集合。Leader 副本天然就在 ISR 中。</p><h4 id="unclean-领导者选举" tabindex="-1"><a class="header-anchor" href="#unclean-领导者选举" aria-hidden="true">#</a> Unclean 领导者选举</h4><p>因为 Leader 副本天然就在 ISR 中，如果 ISR 为空了，就说明 Leader 副本也“挂掉”了，Kafka 需要重新选举一个新的 Leader。</p><p><strong>Kafka 把所有不在 ISR 中的存活副本都称为非同步副本</strong>。通常来说，非同步副本落后 Leader 太多，因此，如果选择这些副本作为新 Leader，就可能出现数据的丢失。毕竟，这些副本中保存的消息远远落后于老 Leader 中的消息。在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。<strong>Broker 端参数 <code>unclean.leader.election.enable</code> 控制是否允许 Unclean 领导者选举</strong>。</p><p><strong>开启 Unclean 领导者选举可能会造成数据丢失</strong>，但好处是：它使得 Partition Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。</p><h2 id="可靠传输" tabindex="-1"><a class="header-anchor" href="#可靠传输" aria-hidden="true">#</a> 可靠传输</h2><h3 id="todo-3" tabindex="-1"><a class="header-anchor" href="#todo-3" aria-hidden="true">#</a> TODO</h3><p>【简单】Kafka 是如何保证消息顺序性的？在什么场景下顺序性是必须的？<br> 【中等】Kafka 如何保证消息的持久性和高可用性？<br> 【中等】Kafka 中的 ISR（In-Sync Replica）是什么？它如何保证消息的可靠性？<br> 【中等】在 Kafka 中，如何处理消息重复消费的问题？有哪些解决方案？<br> 【中等】在 Kafka 中，如何通过 Acks 配置提高数据可靠性？Acks 的值如何影响性能？<br> 【中等】在 Kafka 中，如何处理消息丢失问题？有哪些常见的应对策略？<br> 【中等】Kafka 中 Zookeeper 是做什么的？它在集群管理中起到什么作用？<br> 【困难】Kafka 如何保证消息的严格顺序性？在高并发场景下如何优化顺序消费？</p><h3 id="【困难】如何保证-kafka-消息不丢失" tabindex="-1"><a class="header-anchor" href="#【困难】如何保证-kafka-消息不丢失" aria-hidden="true">#</a> 【困难】如何保证 Kafka 消息不丢失？</h3><p>如何保证消息的可靠性传输，或者说，如何保证消息不丢失？这对于任何 MQ 都是核心问题。</p><p>一条消息从生产到消费，可以划分三个阶段：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070727544.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li><strong>生产阶段</strong>：Producer 创建消息，并通过网络发送给 Broker。</li><li><strong>存储阶段</strong>：Broker 收到消息并存储，如果是集群，还要同步副本给其他 Broker。</li><li><strong>消费阶段</strong>：Consumer 向 Broker 请求消息，Broker 通过网络传输给 Consumer。</li></ul><p>这三个阶段都可能丢失数据，所以要保证消息丢失，就需要任意一环都保证可靠。</p><h4 id="存储阶段不丢消息" tabindex="-1"><a class="header-anchor" href="#存储阶段不丢消息" aria-hidden="true">#</a> 存储阶段不丢消息</h4><p>存储阶段指的是 Kafka Server，也就是 Broker 如何保证消息不丢失。</p><p>一句话概括，<strong>Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证</strong>。</p><p>上面的话可以解读为：</p><ul><li><strong>已提交</strong>：<strong>只有当消息被写入分区的若干同步副本时，才被认为是已提交的</strong>。为什么是若干个 Broker 呢？这取决于你对“已提交”的定义。你可以选择只要 Leader 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。</li><li><strong>持久化</strong>：Kafka 的数据存储在磁盘上，所以只要写入成功，天然就是持久化的。</li><li><strong>只要还有一个副本是存活的，那么已提交的消息就不会丢失</strong>。</li><li><strong>消费者只能读取已提交的消息</strong>。</li></ul><p><strong>Kafka 的副本机制是 kafka 可靠性保证的核心</strong>。</p><p>Kafka 的主题被分为多个分区，分区是基本的数据块。每个分区可以有多个副本，有一个是 Leader（主副本），其他是 Follower（从副本）。所有数据都直接发送给 Leader，或者直接从 Leader 读取事件。Follower 只需要与 Leader 保持同步，并及时复制最新的数据。当 Leader 宕机时，从 Follower 中选举一个成为新的 Leader。</p><p>Broker 有 3 个配置参数会影响 Kafka 消息存储的可靠性。</p><ul><li><strong>副本数</strong> - <strong><code>replication.factor</code> 的作用是设置每个分区的副本数</strong>。<code>replication.factor</code> 是主题级别配置； <code>default.replication.factor</code> 是 broker 级别配置。副本数越多，数据可靠性越高；但由于副本数增多，也会增加同步副本的开销，可能会降低集群的可用性。一般，建议设为 3，这也是 Kafka 的默认值。</li><li><strong>不完全的选主</strong> - <code>unclean.leader.election.enable</code> 用于控制是否支持不同步的副本参与选举 Leader。<code>unclean.leader.election.enable</code> 是 broker 级别（实际上是集群范围内）配置，默认值为 true。 <ul><li>如果设为 true，代表着<strong>允许不同步的副本成为主副本</strong>（即不完全的选举），那么将<strong>面临丢失消息的风险</strong>；</li><li>如果设为 false，就要<strong>等待原先的主副本重新上线</strong>，从而降低了可用性。</li></ul></li><li><strong>最少同步副本</strong> - <strong><code>min.insync.replicas</code> 控制的是消息至少要被写入到多少个副本才算是“已提交”</strong>。<code>min.insync.replicas</code> 是主题级别和 broker 级别配置。尽管可以为一个主题配置 3 个副本，但还是可能会出现只有一个同步副本的情况。如果这个同步副本变为不可用，则必须在可用性和数据一致性之间做出选择。Kafka 中，消息只有被写入到所有的同步副本之后才被认为是已提交的。但如果只有一个同步副本，那么在这个副本不可用时，则数据就会丢失。 <ul><li>如果要确保已经提交的数据被已写入不止一个副本，就需要把最小同步副本的设置为大一点的值。</li><li>注意：要确保 <code>replication.factor</code> &gt; <code>min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</li></ul></li></ul><h4 id="生产阶段不丢消息" tabindex="-1"><a class="header-anchor" href="#生产阶段不丢消息" aria-hidden="true">#</a> 生产阶段不丢消息</h4><p>在生产消息阶段，消息队列一般通过请求确认机制，来保证消息的可靠传递，Kafka 也不例外。</p><p>Kafka 有三种发送方式：同步、异步、异步回调。同步方式能保证消息不丢失，但性能太差；异步方式发送消息，通常会立即返回，但消息可能丢失。</p><p>解决生产者丢失消息的方案：</p><p>生产者使用异步回调方式 <code>producer.send(msg, callback)</code> 发送消息。callback（回调）能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。</p><ul><li>如果是因为那些瞬时错误，那么仅仅让 Producer 重试就可以了；</li><li>如果是消息不合格造成的，那么可以调整消息格式后再次发送。</li></ul><p>然后，需要基于以下几点来保证 Kafka 生产者的可靠性：</p><ul><li><strong>ACK</strong> - 生产者可选的确认模式有三种：<code>acks=0</code>、<code>acks=1</code>、<code>acks=all</code>。 <ul><li><code>acks=0</code>、<code>acks=1</code> 都有丢失数据的风险。</li><li><code>acks=all</code> 意味着会等待所有同步副本都收到消息。再结合 <code>min.insync.replicas</code> ，就可以决定在得到确认响应前，至少有多少副本能够收到消息。这是最保险的做法，但也会降低吞吐量。</li></ul></li><li><strong>重试</strong> - 如果 broker 返回的错误可以通过<strong>重试</strong>来解决，生产者会自动处理这些错误。需要注意的是：有时可能因为网络问题导致没有收到确认，但实际上消息已经写入成功。生产者会认为出现临时故障，重试发送消息，这样就会出现重复记录。所以，尽可能在业务上保证幂等性。设置 <code>retries</code> 为一个较大的值。这里的 <code>retries</code> 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失。 <ul><li><strong>可重试错误</strong>，如：<code>LEADER_NOT_AVAILABLE</code>，主副本不可用，可能过一段时间，集群就会选举出新的主副本，重试可以解决问题。</li><li><strong>不可重试错误</strong>，如：<code>INVALID_CONFIG</code>，即使重试，也无法改变配置选项，重试没有意义。</li></ul></li><li><strong>错误处理</strong> - 开发者需要自行处理的错误： <ul><li>不可重试的 broker 错误，如消息大小错误、认证错误等；</li><li>消息发送前发生的错误，如序列化错误；</li><li>生产者达到重试次数上限或消息占用的内存达到上限时发生的错误。</li></ul></li></ul><h4 id="消费阶段不丢消息" tabindex="-1"><a class="header-anchor" href="#消费阶段不丢消息" aria-hidden="true">#</a> 消费阶段不丢消息</h4><p>前文已经提到，<strong>消费者只能读取已提交的消息</strong>。这就保证了消费者接收到消息时已经具备了数据一致性。</p><p>消费者唯一要做的是确保哪些消息是已经读取过的，哪些是没有读取过的（通过提交偏移量给 Broker 来确认）。如果消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这也是消费者丢失消息的主要原因。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200727140159.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>消费者的可靠性配置：</p><ul><li><code>group.id</code> - 如果希望消费者可以看到主题的所有消息，那么需要为它们设置唯一的 <code>group.id</code>。</li><li><code>auto.offset.reset</code> - 有两个选项： <ul><li><code>earliest</code> - 消费者会从分区的开始位置读取数据</li><li><code>latest</code> - 消费者会从分区末尾位置读取数据</li></ul></li><li><code>enable.auto.commit</code> - 消费者自动提交偏移量。如果设为 true，处理流程更简单，但无法保证重复处理消息。</li><li><code>auto.commit.interval.ms</code> - 自动提交的频率，默认为每 5 秒提交一次。</li></ul><p>如果 <code>enable.auto.commit</code> 设为 true，即自动提交，就无需考虑提交偏移量的问题。</p><p>如果选择显示提交偏移量，需要考虑以下问题：</p><ul><li>必须在处理完消息后再发送确认（提交偏移量），不要收到消息立即确认。</li><li>提交频率是性能和重复消息数之间的权衡</li><li>分区再均衡</li><li>消费可能需要重试机制</li><li>超时处理</li><li>消费者可能需要维护消费状态，如：处理完消息后，记录在数据库中。</li><li>幂等性设计 <ul><li>写数据库：根据主键判断记录是否存在</li><li>写 Redis：set 操作天然具有幂等性</li><li>复杂的逻辑处理，则可以在消息中加入全局 ID</li></ul></li></ul><h3 id="【困难】如何保证-kafka-消息不重复" tabindex="-1"><a class="header-anchor" href="#【困难】如何保证-kafka-消息不重复" aria-hidden="true">#</a> 【困难】如何保证 Kafka 消息不重复？</h3><p>在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：</p><ul><li><strong>At most once</strong>：至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。</li><li><strong>At least once</strong>: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。</li><li><strong>Exactly once</strong>：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。</li></ul><p>绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。也就是说，消息队列很难保证消息不重复。</p><p>一般解决重复消息的办法是，在消费端，<strong>保证消费消息的操作具备幂等性</strong>。</p><p><strong>幂等</strong>（idempotent、idempotence）是一个数学与计算机学概念，指的是：<strong>一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。</strong></p><p>常用的实现幂等操作的方法：</p><ul><li><strong>利用数据库的唯一约束实现幂等</strong> - 关系型数据库可以使用 <code>INSERT IF NOT EXIST</code> 语句防止重复；Redis 可以使用 <code>SETNX</code> 命令来防止重复；其他数据库只要支持类似语义，也是一个道理。</li><li><strong>为更新的数据设置前置条件</strong> - 如果满足条件就更新数据，否则拒绝更新数据，在更新数据的时候，同时变更前置条件中需要判断的数据。这样，重复执行这个操作时，由于第一次更新数据的时候已经变更了前置条件中需要判断的数据，不满足前置条件，则不会重复执行更新数据操作。但是，如果我们要更新的数据不是数值，或者我们要做一个比较复杂的更新操作怎么办？用什么作为前置判断条件呢？更加通用的方法是，给数据增加一个版本号属性，每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号 +1，一样可以实现幂等更新。</li><li><strong>记录并检查操作</strong>- 也称为“Token 机制或者 GUID（全局唯一 ID）机制”，通用性最强，适用范围最广。实现的思路特别简单，在执行数据更新操作之前，先检查一下是否执行过这个更新操作。 <ul><li>具体的实现方法是，在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。</li><li>需要注意的是，“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug。这一组操作可以通过分布式事务或分布式锁来保证其原子性。</li></ul></li></ul><h3 id="【困难】如何保证-kafka-消息有序" tabindex="-1"><a class="header-anchor" href="#【困难】如何保证-kafka-消息有序" aria-hidden="true">#</a> 【困难】如何保证 Kafka 消息有序？</h3><p>某些场景下，可能会要求按序发送消息。</p><p>方案一、单 Partition</p><p>Kafka 每一个 Partition 只能隶属于消费者群组中的一个 Consumer，换句话说，每个 Partition 只能被一个 Consumer 消费。所以，如果 Topic 是单 Partition，自然是有序的。</p><p>方案分析</p><p>优点：简单粗暴。开发者什么也不用做。</p><p>缺点：<strong>Kafka 基于 Partition 实现其高并发</strong>能力，如果使用单 Partition，会严重限制 Kafka 的吞吐量。</p><p>结论：作为分布式消息引擎，限制并发能力，显然等同于自废武功，所以，这个方案几乎是不可接受的。</p><p>方案二、同一个 key 的消息发送给指定 Partition</p><p>（1）生产者端显示指定 key 发往一个指定的 Partition，就可以保证同一个 key 在这个 Partition 中是有序的。</p><p>（2）接下来，消费者端为每个 key 设定一个缓存队列，然后让一个独立线程负责消费指定 key 的队列，这就保证了消费消息也是有序的。</p><h3 id="【困难】如何应对-kafka-消息积压" tabindex="-1"><a class="header-anchor" href="#【困难】如何应对-kafka-消息积压" aria-hidden="true">#</a> 【困难】如何应对 Kafka 消息积压？</h3><p>先修复消费者，然后停掉当前所有消费者。</p><p>新建 Topic，扩大分区，以提高并发处理能力。</p><p>创建临时消费者程序，并部署在多节点上，扩大消费处理能力。</p><p>最后处理完积压消息后，恢复原先部署架构。</p><h2 id="高可用" tabindex="-1"><a class="header-anchor" href="#高可用" aria-hidden="true">#</a> 高可用</h2><p>【困难】Kafka 的高可用性是如何实现的？当 Broker 宕机时，如何保证服务不受影响？<br> 【困难】Kafka 如何保证在集群扩展或缩容时数据的安全性和一致性？<br> 【困难】Kafka 的优先副本选举机制是如何工作的？如何配置它？<br> 【困难】在 Kafka 中，如何实现多集群的数据同步？跨集群复制的实现原理是什么？<br> 【困难】Kafka 是如何通过 Zookeeper 管理集群元数据的？如何处理 Zookeeper 故障？<br> 【困难】Kafka 的 Controller Failover 是如何设计的？在 Controller 宕机时如何进行故障恢复？</p><h2 id="事务" tabindex="-1"><a class="header-anchor" href="#事务" aria-hidden="true">#</a> 事务</h2><h3 id="todo-4" tabindex="-1"><a class="header-anchor" href="#todo-4" aria-hidden="true">#</a> TODO</h3><p>【简单】Kafka 的基本架构包括哪些组件？各组件的作用是什么？<br> 【困难】Kafka 的事务机制是如何实现的？它如何保证消息的一致性？<br> 【困难】Kafka 的事务机制与幂等性机制如何协同工作？它们在保证消息一致性上有什么作用？<br> 【困难】Kafka 的 Exactly Once 语义在分布式系统中是如何实现的？如何处理分布式事务中的异常情况？<br> 【困难】Kafka 是如何保证 Exactly Once 语义的？它的实现原理是什么？</p><h3 id="【中等】kafka-是否支持事务-如何支持事务" tabindex="-1"><a class="header-anchor" href="#【中等】kafka-是否支持事务-如何支持事务" aria-hidden="true">#</a> 【中等】Kafka 是否支持事务？如何支持事务？</h3><p><strong>Kafka 的事务概念是指一系列的生产者生产消息和消费者提交偏移量的操作在一个事务，或者说是是一个原子操作），同时成功或者失败</strong>。</p><p>消息可靠性保障，由低到高为：</p><ul><li>最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。</li><li>至少一次（at least once）：消息不会丢失，但有可能被重复发送。</li><li>精确一次（exactly once）：消息不会丢失，也不会被重复发送。</li></ul><p>Kafka 支持事务功能主要是为了实现精确一次处理语义的，而精确一次处理是实现流处理的基石。</p><p>Kafka 自 0.11 版本开始提供了对事务的支持，目前主要是在 read committed 隔离级别上做事情。它能<strong>保证多条消息原子性地写入到目标分区，同时也能保证 Consumer 只能看到事务成功提交的消息</strong>。</p><h4 id="事务型-producer" tabindex="-1"><a class="header-anchor" href="#事务型-producer" aria-hidden="true">#</a> 事务型 Producer</h4><p>事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。另外，事务型 Producer 也不惧进程的重启。Producer 重启回来后，Kafka 依然保证它们发送消息的精确一次处理。</p><p><strong>事务属性实现前提是幂等性</strong>，即在配置事务属性 <code>transaction.id</code> 时，必须还得配置幂等性；但是幂等性是可以独立使用的，不需要依赖事务属性。</p><p>在事务属性之前先引入了生产者幂等性，它的作用为：</p><ul><li><strong>生产者多次发送消息可以封装成一个原子操作</strong>，要么都成功，要么失败。</li><li>consumer-transform-producer 模式下，因为消费者提交偏移量出现问题，导致<strong>重复消费</strong>。需要将这个模式下消费者提交偏移量操作和生产者一系列生成消息的操作封装成一个原子操作。</li></ul><p><strong>消费者提交偏移量导致重复消费消息的场景</strong>：消费者在消费消息完成提交便宜量 o2 之前挂掉了（假设它最近提交的偏移量是 o1），此时执行再均衡时，其它消费者会重复消费消息 (o1 到 o2 之间的消息）。</p><h4 id="kafka-事务相关配置" tabindex="-1"><a class="header-anchor" href="#kafka-事务相关配置" aria-hidden="true">#</a> Kafka 事务相关配置</h4><p>使用 kafka 的事务 api 时的一些注意事项：</p><ul><li>需要消费者的自动模式设置为 false，并且不能子再手动的进行执行 <code>consumer#commitSync</code> 或者 <code>consumer#commitAsyc</code></li><li>设置 Producer 端参数 <code>transctional.id</code>。最好为其设置一个有意义的名字。</li><li>和幂等性 Producer 一样，开启 <code>enable.idempotence = true</code>。如果配置了 <code>transaction.id</code>，则此时 <code>enable.idempotence</code> 会被设置为 true</li><li>消费者需要配置事务隔离级别 <code>isolation.level</code>。在 <code>consume-trnasform-produce</code> 模式下使用事务时，必须设置为 <code>READ_COMMITTED</code>。 <ul><li><code>read_uncommitted</code>：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取。很显然，如果你用了事务型 Producer，那么对应的 Consumer 就不要使用这个值。</li><li><code>read_committed</code>：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息。当然了，它也能看到非事务型 Producer 写入的所有消息。</li></ul></li></ul><h2 id="架构" tabindex="-1"><a class="header-anchor" href="#架构" aria-hidden="true">#</a> 架构</h2><h3 id="todo-5" tabindex="-1"><a class="header-anchor" href="#todo-5" aria-hidden="true">#</a> TODO</h3><p>【中等】Kafka 是如何实现横向扩展的？它如何处理大规模集群中的负载均衡？<br> 【中等】Kafka 的日志压缩功能是如何实现的？它在什么场景下使用？<br> 【困难】Kafka 的流量控制是如何实现的？如何通过流量控制避免系统过载？<br> 【困难】Kafka 的幂等性是如何保证的？它在消息处理中的作用是什么？<br> 【困难】Kafka 在高吞吐量场景下如何保持低延迟？有哪些性能调优的策略？<br> 【困难】Kafka 如何处理数据倾斜问题？有哪些优化手段可以均衡负载？<br> 【困难】Kafka 与 Flink 的集成是如何实现的？如何优化 Flink 与 Kafka 之间的数据流动？<br> 【困难】在 Kafka 中，如何优化磁盘 I/O 性能？有哪些策略可以减少 I/O 开销？<br> 【困难】Kafka 的多租户支持是如何实现的？如何通过配额控制各租户的资源使用？<br> 【困难】Kafka 的 Stream 和 Table 是如何相互转换的？它们在 Kafka Streams 中的应用场景是什么？</p><h3 id="【简单】kafka-的设计目标" tabindex="-1"><a class="header-anchor" href="#【简单】kafka-的设计目标" aria-hidden="true">#</a> 【简单】Kafka 的设计目标</h3><ul><li><strong>高性能</strong><ul><li><strong>分区、分段、索引</strong>：基于分区机制提供并发处理能力。分段、索引提升了数据读写的查询效率。</li><li><strong>顺序读写</strong>：使用顺序读写提升磁盘 IO 性能。</li><li><strong>零拷贝</strong>：利用零拷贝技术，提升网络 I/O 效率。</li><li><strong>页缓存</strong>：利用操作系统的 PageCache 来缓存数据（典型的利用空间换时间）</li><li><strong>批量读写</strong>：批量读写可以有效提升网络 I/O 效率。</li><li><strong>数据压缩</strong>：Kafka 支持数据压缩，可以有效提升网络 I/O 效率。</li><li><strong>pull 模式</strong>：Kafka 架构基于 pull 模式，可以自主控制消费策略，提升传输效率。</li></ul></li><li><strong>高可用</strong><ul><li><strong>持久化</strong>：Kafka 所有的消息都存储在磁盘，天然支持持久化。</li><li><strong>副本机制</strong>：Kafka 的 Broker 集群支持副本机制，可以通过冗余，来保证其整体的可用性。</li><li><strong>选举 Leader</strong>：Kafka 基于 ZooKeeper 支持选举 Leader，实现了故障转移能力。</li></ul></li><li><strong>伸缩性</strong><ul><li><strong>分区</strong>：Kafka 的分区机制使得其具有良好的伸缩性。</li></ul></li></ul><h3 id="【困难】kafka-的数据存储在磁盘上-为什么还能这么快" tabindex="-1"><a class="header-anchor" href="#【困难】kafka-的数据存储在磁盘上-为什么还能这么快" aria-hidden="true">#</a> 【困难】Kafka 的数据存储在磁盘上，为什么还能这么快？</h3><p>说 Kafka 很快时，他们通常指的是 Kafka 高效移动大量数据的能力。</p><p>Kafka 为了提高传输效率，做了很多精妙的设计。</p><p>核心设计：</p><ul><li><strong>顺序 I/O</strong> - 磁盘读写有两种方式：顺序读写或者随机读写。在顺序读写的情况下，磁盘的顺序读写速度和内存接近。因为磁盘是机械结构，每次读写都会寻址写入，其中寻址是一个“机械动作”。Kafka 利用了一种分段式的、只追加 (Append-Only) 的日志，基本上把自身的读写操作限制为<strong>顺序 I/O</strong>，也就使得它在各种存储介质上能有很快的速度。</li><li><strong>零拷贝</strong> - Kafka 数据传输是一个从网络到磁盘，再由磁盘到网络的过程。在网络和磁盘之间传输数据时，消除多余的复制是提高效率的关键。<strong>Kafka 利用零拷贝技术来消除传输过程中的多余复制</strong>。 <ul><li>如果不采用零拷贝，Kafka 将数据同步给消费者的大致流程是： <ol><li>从磁盘加载数据到 os buffer</li><li>拷贝数据到 app buffer</li><li>再拷贝数据到 socket buffer</li><li>接下来，将数据拷贝到网卡 buffer</li><li>最后，通过网络传输，将数据发送到消费者</li></ol></li><li>采用零拷贝技术，Kafka 使用 <code>sendfile()</code> 系统方法，将数据从 os buffer 直接复制到网卡 buffer。这个过程中，唯一一次复制数据是从 os buffer 到网卡 buffer。这个复制过程是通过 DMA（Direct Memory Access，直接内存访问） 完成的。使用 DMA 时，CPU 不参与，这使得它非常高效。</li></ul></li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202502070727055.webp" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>其他设计：</p><ul><li><strong>页缓存</strong> - Kafka 的数据并不是实时的写入磁盘，它充分利用了现代操作系统分页存储来利用内存提高 I/O 效率。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问。Kafka 接收来自 socket buffer 的网络数据，应用进程不需要中间处理、直接进行持久化时。可以使用 mmap 内存文件映射。</li><li><strong>压缩</strong> - Kafka 内置了几种压缩算法，并允许定制化压缩算法。通过压缩算法，可以有效减少传输数据的大小，从而提升传输效率。</li><li><strong>批处理</strong> - Kafka 的 Clients 和 Brokers 会把多条读写的日志记录合并成一个批次，然后才通过网络发送出去。日志记录的批处理通过使用更大的包以及提高带宽效率来摊薄网络往返的开销。</li><li><strong>分区</strong> - Kafka 将 Topic 分区，每个分区对应一个名为的 Log 的磁盘目录，而 Log 又根据大小，可以分为多个 Log Segment 文件。这种分而治之的策略，使得 Kafka 可以<strong>并发</strong>读，以支撑非常高的吞吐量。此外，Kafka 支持负载均衡机制，将数据分区近似均匀地分配给消费者群组的各个消费者。</li></ul><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料" aria-hidden="true">#</a> 参考资料</h2>`,289),g={href:"https://xie.infoq.cn/article/49bc80d683c373db93d017a99",target:"_blank",rel:"noopener noreferrer"};function p(u,f){const e=o("ExternalLinkIcon");return i(),n("div",null,[c,a("ul",null,[a("li",null,[a("a",g,[t("聊聊 Kafka： Kafka 为啥这么快？"),l(e)])])])])}const m=r(d,[["render",p],["__file","index.html.vue"]]);export{m as default};
