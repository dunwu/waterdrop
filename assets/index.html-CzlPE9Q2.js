import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,a as r,o as i}from"./app-McUEOEAZ.js";const s={};function o(a,t){return i(),e("div",null,[...t[0]||(t[0]=[r('<h1 id="分布式存储面试" tabindex="-1"><a class="header-anchor" href="#分布式存储面试"><span>分布式存储面试</span></a></h1><h2 id="缓存" tabindex="-1"><a class="header-anchor" href="#缓存"><span>缓存</span></a></h2><div class="hint-container tip"><p class="hint-container-title">扩展</p><ul><li><a href="https://item.jd.com/11322972.html" target="_blank" rel="noopener noreferrer">《大型网站技术架构：核心原理与案例分析》</a></li><li><a href="https://link.juejin.im/?target=https%3A%2F%2Fjuejin.im%2Fpost%2F5b7593496fb9a009b62904fa" target="_blank" rel="noopener noreferrer">你应该知道的缓存进化史</a></li><li><a href="https://link.juejin.im/?target=https%3A%2F%2Fjuejin.im%2Fpost%2F5b849878e51d4538c77a974a" target="_blank" rel="noopener noreferrer">如何优雅的设计和使用缓存？</a></li><li><a href="https://www.jianshu.com/p/73ce0ef820f9" target="_blank" rel="noopener noreferrer">理解分布式系统中的缓存架构（上）</a></li><li><a href="https://tech.meituan.com/2017/03/17/cache-about.html" target="_blank" rel="noopener noreferrer">缓存那些事</a></li><li><a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener noreferrer">分布式之数据库和缓存双写一致性方案解析 </a></li><li><a href="https://zhuanlan.zhihu.com/p/102293437" target="_blank" rel="noopener noreferrer">Cache 的基本原理</a></li><li><a href="https://segmentfault.com/a/1190000021716418" target="_blank" rel="noopener noreferrer">5 分钟看懂系列：HTTP 缓存机制详解</a></li><li><a href="https://zhuanlan.zhihu.com/p/60950750" target="_blank" rel="noopener noreferrer">浏览器缓存看这一篇就够了</a></li></ul></div><h3 id="【简单】什么是缓存-为什么需要缓存" tabindex="-1"><a class="header-anchor" href="#【简单】什么是缓存-为什么需要缓存"><span>【简单】什么是缓存？为什么需要缓存？</span></a></h3><p><strong>缓存就是数据交换的缓冲区，用于将频繁访问的数据暂存在访问速度快的存储介质</strong>。</p><p>缓存的本质是一种利用<strong>空间换时间</strong>的设计：牺牲一定的数据实时性，使得访问<strong>更快</strong>、<strong>更近</strong>：</p><ul><li>将数据存储到读取速度<strong>更快</strong>的存储（设备）；</li><li>将数据存储到<strong>离应用最近</strong>的位置；</li><li>将数据存储到<strong>离用户最近</strong>的位置。</li></ul><p>缓存是用于存储数据的硬件或软件的组成部分，以使得后续更快访问相应的数据。缓存中的数据可能是提前计算好的结果、数据的副本等。典型的应用场景：有 cpu cache, 磁盘 cache 等。本文中提及到缓存主要是指互联网应用中所使用的缓存组件。</p><p><strong>缓存命中率</strong>是缓存的重要度量指标，命中率越高越好。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>缓存命中率 = 从缓存中读取次数 / 总读取次数</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="【简单】何时需要缓存" tabindex="-1"><a class="header-anchor" href="#【简单】何时需要缓存"><span>【简单】何时需要缓存？</span></a></h3><p>引入缓存，会增加系统的复杂度，并牺牲一定的数据实时性。所以，引入缓存前，需要先权衡是否值得，考量点如下：</p><ul><li><strong>CPU 开销</strong> - 如果应用某个计算需要消耗大量 CPU，可以考虑缓存其计算结果。典型场景：复杂的、频繁调用的正则计算；分布式计算中间状态等。</li><li><strong>IO 开销</strong> - 如果数据库连接池比较繁忙，可以考虑缓存其查询结果。</li></ul><p>在数据层引入缓存，有以下几个好处：</p><ul><li>提升数据读取速度。</li><li>提升系统扩展能力，通过扩展缓存，提升系统承载能力。</li><li>降低存储成本，Cache+DB 的方式可以承担原有需要多台 DB 才能承担的请求量，节省机器成本。</li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151116093.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="【中等】缓存有哪些分类" tabindex="-1"><a class="header-anchor" href="#【中等】缓存有哪些分类"><span>【中等】缓存有哪些分类？</span></a></h3><p>缓存从部署角度，可以分为客户端缓存和服务端缓存。</p><p><strong>客户端缓存</strong></p><ul><li><strong>Http 缓存</strong>：HTTP/1.1 中的 <code>Cache-Control</code>、HTTP/1 中的 <code>Expires</code></li><li><strong>浏览器缓存</strong>：HTML5 提供的 SessionStorage 和 LocalStorage、Cookie</li><li><strong>APP 缓存</strong>：Android、IOS</li></ul><p><strong>服务端缓存</strong></p><ul><li><strong>CDN 缓存</strong> - CDN 将数据缓存到离用户物理距离最近的服务器，使得用户可以就近获取请求内容。CDN 一般缓存静态资源文件（页面，脚本，图片，视频，文件等）。</li><li><strong>反向代理缓存</strong> - 反向代理（Reverse Proxy）方式是指以代理服务器来接受网络连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给客户端，此时代理服务器对外就表现为一个反向代理服务器。反向代理缓存一般针对的是静态资源，而将动态资源请求转发到应用服务器处理。</li><li><strong>数据库缓存</strong> - 数据库（如 Mysql）自身一般也有缓存，但因为命中率和更新频率问题，不推荐使用。</li><li><strong>进程内缓存</strong> - 缓存应用字典等常用数据。</li><li><strong>分布式缓存</strong> - 缓存数据库中的热点数据。</li></ul><blockquote><p>其中，CDN 缓存、反向代理缓存、数据库缓存一般由专职人员维护（运维、DBA）。</p><p>后端开发一般聚焦于进程内缓存、分布式缓存。</p></blockquote><h3 id="【中等】什么是-cdn-cdn-的工作原理是什么" tabindex="-1"><a class="header-anchor" href="#【中等】什么是-cdn-cdn-的工作原理是什么"><span>【中等】什么是 CDN？CDN 的工作原理是什么？</span></a></h3><p><strong>CDN 是一种将内容缓存到离用户更近的节点的分布式网络系统。CDN 一般缓存静态资源文件（页面，脚本，图片，视频，文件等）</strong>。</p><p>国内网络异常复杂，跨运营商的网络访问会很慢。为了解决跨运营商或各地用户访问问题，可以在重要的城市，部署 CDN 应用。使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/1559138689425.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><div class="hint-container info"><p class="hint-container-title">CDN 原理</p></div><ul><li><strong>就近调度</strong>：用户被导向<strong>最近的 CDN 节点</strong></li><li><strong>缓存+回源</strong>：节点有内容直接返回（<strong>缓存命中</strong>）；节点无内容则向源站请求并缓存（<strong>缓存未命中</strong>）</li></ul><div class="hint-container info"><p class="hint-container-title">CDN 特点</p></div><p><strong>优点</strong>：</p><ul><li><strong>缓存加速</strong>：提升访问速度，尤其是含有大量图片和静态页面站点</li><li><strong>带宽优化</strong>：自动生成服务器的远程 Mirror（镜像）cache 服务器，远程用户访问时从 cache 服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点 WEB 服务器负载等功能。</li><li><strong>集群抗攻击</strong> - 广泛分布的 CDN 节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种 D.D.o.S 攻击对网站的影响，同时保证较好的服务质量。</li></ul><p><strong>缺点</strong>：</p><ul><li><strong>不适宜缓存动态资源</strong><ul><li>解决方案：主要缓存静态资源，动态资源建立多级缓存或准实时同步；</li></ul></li><li><strong>存在数据的一致性问题</strong><ul><li>解决方案（主要是在性能和数据一致性二者间寻找一个平衡）</li><li>设置缓存失效时间（1 个小时，过期后同步数据）。</li><li>针对资源设置版本号。</li></ul></li></ul><h3 id="【中等】反向代理缓存的工作原理是什么" tabindex="-1"><a class="header-anchor" href="#【中等】反向代理缓存的工作原理是什么"><span>【中等】反向代理缓存的工作原理是什么？</span></a></h3><p>反向代理服务器部署在应用服务器前端，作为流量入口。既是反向代理（转发请求），也是缓存服务器（缓存响应）。</p><p><strong>反向代理（Reverse Proxy）方式是指以代理服务器来接受网络连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给客户端，此时代理服务器对外就表现为一个反向代理服务器。</strong></p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/web/nginx/reverse-proxy.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>反向代理位于应用服务器同一网络，处理所有对 WEB 服务器的请求。</p><p>反向代理缓存的原理：</p><ul><li>如果用户请求的页面在代理服务器上有缓存的话，代理服务器直接将缓存内容发送给用户。</li><li>如果没有缓存则先向 WEB 服务器发出请求，取回数据，本地缓存后再发送给用户。</li></ul><p>这种方式通过降低向 WEB 服务器的请求数，从而降低了 WEB 服务器的负载。</p><p><strong>反向代理缓存一般针对的是静态资源，而将动态资源请求转发到应用服务器处理</strong>。常用的缓存应用服务器有 Varnish，Ngnix，Squid。</p><h3 id="【中等】缓存有哪些淘汰算法-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】缓存有哪些淘汰算法-⭐⭐⭐"><span>【中等】缓存有哪些淘汰算法？⭐⭐⭐</span></a></h3><div class="hint-container tip"><p class="hint-container-title">扩展</p><ul><li><a href="https://www.youtube.com/watch?v=7lxAfszjy68&amp;list=PLBlnK6fEyqRjdT1xkkBZSXKwFKqQoYhwy&amp;index=23" target="_blank" rel="noopener noreferrer">Cache Replacement Policies - RR, FIFO, LIFO, &amp; Optimal</a></li><li><a href="https://www.youtube.com/watch?v=_Hh-NcdbHCY&amp;list=PLBlnK6fEyqRjdT1xkkBZSXKwFKqQoYhwy&amp;index=25" target="_blank" rel="noopener noreferrer">Cache Replacement Policies - MRU, LRU, Pseudo-LRU, &amp; LFU</a></li></ul></div><div class="hint-container info"><p class="hint-container-title">缓存算法设计思路</p></div><p>缓存一般存于访问速度较快的存储介质，快也就意味着资源昂贵并且有限。正所谓，好钢要用在刀刃上。因此，缓存要合理利用，需要设定一些机制，将一些访问频率偏低或过期的数据淘汰。</p><p>淘汰缓存首先要做的是，确定什么时候触发淘汰缓存，一般有以下几个思路：</p><ul><li><strong>基于空间</strong> - 设置缓存空间大小。</li><li><strong>基于容量</strong> - 设置缓存存储记录数。</li><li><strong>基于时间</strong><ul><li><strong>TTL（Time To Live，即存活期）</strong> - 缓存数据从创建到过期的时间。</li><li><strong>TTI（Time To Idle，即空闲期）</strong> - 缓存数据多久没被访问的时间。</li></ul></li></ul><div class="hint-container info"><p class="hint-container-title">主流缓存算法对比</p></div><p>接下来，就要确定如何淘汰缓存，常见的缓存淘汰算法有以下几个：</p><table><thead><tr><th style="text-align:left;">算法</th><th style="text-align:left;">淘汰策略</th><th style="text-align:left;">优点</th><th style="text-align:left;">缺点</th><th style="text-align:left;">适用场景</th></tr></thead><tbody><tr><td style="text-align:left;"><strong>FIFO</strong>（先进先出）</td><td style="text-align:left;">淘汰<strong>最先进入</strong>的数据（队列结构）</td><td style="text-align:left;"><strong>实现简单</strong></td><td style="text-align:left;"><strong>缓存命中率低</strong>（无视访问频率，可能淘汰热点数据）</td><td style="text-align:left;">数据访问无规律，或实现简单的缓存系统</td></tr><tr><td style="text-align:left;"><strong>LIFO</strong>（后进先出）</td><td style="text-align:left;">淘汰<strong>最后进入</strong>的数据（栈结构）</td><td style="text-align:left;"><strong>实现简单</strong></td><td style="text-align:left;"><strong>缓存命中率低</strong>（无视访问频率，可能淘汰热点数据）</td><td style="text-align:left;">特殊场景（如回退操作，新数据价值低）</td></tr><tr><td style="text-align:left;"><strong>MRU</strong>（最近最多使用）</td><td style="text-align:left;">淘汰<strong>最近最多使用</strong>的数据</td><td style="text-align:left;">适合<strong>访问局部性强</strong>的场景（如用户浏览信息流，看过内容不再看）</td><td style="text-align:left;">可能<strong>频繁淘汰缓存</strong>，降低命中率</td><td style="text-align:left;">数据访问模式具有“看后即弃”特性（如信息流推荐）</td></tr><tr><td style="text-align:left;"><strong>LRU</strong>（最近最少使用）</td><td style="text-align:left;">淘汰<strong>最近最少被使用</strong>的数据（基于访问时间排序）</td><td style="text-align:left;"><strong>避免 FIFO 问题</strong>，对热点数据友好，<strong>综合性能好</strong></td><td style="text-align:left;"><strong>临界区问题</strong>（热点数据在统计窗口末期无访问会被误淘汰）</td><td style="text-align:left;"><strong>通用场景</strong>（Web 缓存、数据库缓存等）</td></tr><tr><td style="text-align:left;"><strong>LFU</strong>（最近最少频率使用）</td><td style="text-align:left;">淘汰<strong>使用频率最低</strong>的数据（额外记录访问频率）</td><td style="text-align:left;"><strong>解决 LRU 临界区问题</strong>，对长期热点数据保护更好</td><td style="text-align:left;"><strong>空间开销大</strong>（需记录频率）；<br><strong>频率衰减问题</strong>（旧热点难以淘汰）</td><td style="text-align:left;">热点数据稳定，访问模式变化慢（如视频热门榜）</td></tr></tbody></table><h3 id="【困难】缓存更新有哪些策略-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【困难】缓存更新有哪些策略-⭐⭐⭐"><span>【困难】缓存更新有哪些策略？⭐⭐⭐</span></a></h3><div class="hint-container tip"><p class="hint-container-title">扩展</p><p><a href="https://www.cnblogs.com/rjzheng/p/9041659.html" target="_blank" rel="noopener noreferrer">分布式之数据库和缓存双写一致性方案解析 </a></p></div><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202601172038278.webp" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>一般来说，系统如果不是严格要求缓存和数据库保持一致性的话，尽量不要将<strong>读请求和写请求串行化</strong>。串行化可以保证一定不会出现数据不一致的情况，但是它会导致系统的吞吐量大幅度下降。缓存更新的常见策略有以下几种：</p><ul><li>Cache Aside</li><li>Wirte Through</li><li>Read Though</li><li>Wirte Behind</li></ul><p>需要注意的是：以上几种缓存更新策略，都无法保证数据强一致。如果一定要保证强一致性，可以通过两阶段提交（2PC）或 Paxos 协议来实现。但是 2PC 太慢，而 Paxos 太复杂，所以如果不是非常重要的数据，不建议使用强一致性方案。</p><div class="hint-container info"><p class="hint-container-title">Cache Aside</p></div><p>Cache Aside 的思路是：<strong>先更新数据库，再删除缓存</strong>。具体来说：</p><ul><li><p><strong>失效</strong>：尝试读缓存，如果不命中，则读数据库，然后更新缓存。</p></li><li><p><strong>命中</strong>：尝试读缓存，命中则直接返回数据。</p></li><li><p><strong>更新</strong>：先更新数据库，再删除缓存。</p></li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151119858.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>为什么不能先更新数据库，再更新缓存</strong>？</p><p><strong>多个并发的写操作可能导致脏数据</strong>：当有多个并发的写请求时，无法保证更新数据库的顺序和更新缓存的顺序一致，从而导致数据库和缓存数据不一致的问题。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220413113825.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>说明：如上图的场景中，两个写线程由于执行顺序，导致数据库中 val = 2，而缓存中 val = 1，数据不一致。</p><p><strong>为什么不能先删缓存，再更新数据库</strong>？</p><p><strong>存在并发读请求和写请求时，可能导致脏数据</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220413113940.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>说明：如上图的场景中，读线程和写线程并行执行，导致数据库中 val = 2，而缓存中 val = 1，数据不一致。</p><p><strong>先更新数据库，再删除缓存就没问题了吗</strong>？</p><p><strong>存在并发读请求和写请求时，可能导致脏数据</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220413115140.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>上图中问题发生的概率非常低：因为通常数据库更新操作比内存操作耗时多出几个数量级，最后一步回写缓存速度非常快，通常会在更新数据库之前完成。所以 Cache Aside 模式选择先更新数据库，再删除缓存，而不是先删缓存，再更新数据库。</p><p>不过，如果真的出现了这种场景，为了避免缓存中一直保留着脏数据，可以为缓存设置过期时间，过期后缓存自动失效。通常，业务系统中允许少量数据短时间出现不一致的情况。</p><div class="hint-container info"><p class="hint-container-title">Read/Write Through</p></div><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151120459.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Read Through 的思路是：<strong>查询时更新缓存</strong>。当缓存失效时，缓存服务自己进行加载。</p><p>Write Through 的思路是：当数据更新时，<strong>缓存服务负责更新缓存</strong>。</p><p>Through vs. Cache Aside</p><p>Read Through vs. Cache Aside</p><ul><li>Cache Aside 模式中，应用需要维护两个数据源头：一个是缓存，一个是数据库。</li><li>Read-Through 模式中，应用无需管理缓存和数据库，只需要将数据库的同步委托给缓存服务即可。</li></ul><div class="hint-container info"><p class="hint-container-title">Write behind</p></div><p>Write Behind 又叫 Write Back。Write Behind 的思路是：应用更新数据时，只更新缓存， 缓存服务每隔一段时间将缓存数据批量更新到数据库中，即延迟写入。这个设计的好处就是让提高 I/O 效率，因为异步，Write Behind 还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。</p><h3 id="【困难】多级缓存架构如何设计-⭐" tabindex="-1"><a class="header-anchor" href="#【困难】多级缓存架构如何设计-⭐"><span>【困难】多级缓存架构如何设计？⭐</span></a></h3><p>一般来说，多级缓存架构使用二级缓存已可以满足大部分业务需求，过多的分级会增加系统的复杂度以及维护的成本。因此，多级缓存不是分级越多越好，需要根据实际情况进行权衡。</p><p>一个典型的二级缓存架构，可以使用进程内缓存（如： Caffeine/Google Guava/Ehcache/HashMap）作为一级缓存；使用分布式缓存（如：Redis/Memcached）作为二级缓存。</p><div class="hint-container info"><p class="hint-container-title">多级缓存查询</p></div><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151118006.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>多级缓存查询流程如下：</p><ol><li>首先，查询 L1 缓存，如果缓存命中，直接返回结果；如果没有命中，执行下一步。</li><li>接下来，查询 L2 缓存，如果缓存命中，直接返回结果并回填 L1 缓存；如果没有命中，执行下一步。</li><li>最后，查询数据库，返回结果并依次回填 L2 缓存、L1 缓存。</li></ol><div class="hint-container info"><p class="hint-container-title">多级缓存更新</p></div><p>对于 L1 缓存，如果有数据更新，只能删除并更新所在机器上的缓存，其他机器只能通过超时机制来刷新缓存。超时设定可以有两种策略：</p><ul><li>设置成写入后多少时间后过期</li><li>设置成写入后多少时间刷新</li></ul><p>对于 L2 缓存，如果有数据更新，其他机器立马可见。但是，也必须要设置超时时间，其时间应该比 L1 缓存的有效时间长。</p><p>为了解决进程内缓存不一致的问题，设计可以进一步优化：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151119761.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>通过消息队列的发布、订阅机制，可以通知其他应用节点对进程内缓存进行更新。使用这种方案，即使消息队列服务挂了或不可靠，由于先执行了数据库更新，但进程内缓存过期，刷新缓存时，也能保证数据的最终一致性。</p><h3 id="【中等】什么是缓存雪崩-如何应对-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】什么是缓存雪崩-如何应对-⭐⭐⭐"><span>【中等】什么是缓存雪崩？如何应对？⭐⭐⭐</span></a></h3><p><strong>“缓存雪崩”是指，缓存不可用或者大量缓存由于超时时间相同在同一时间段失效，大量请求直接访问数据库，数据库压力过大导致系统雪崩</strong>。</p><p>举例来说，对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。</p><p>解决缓存雪崩的主要手段如下：</p><ul><li><strong>增加缓存系统可用性</strong>（事前）。例如：部署 Redis Cluster（主从+哨兵），以实现 Redis 的高可用，避免全盘崩溃。</li><li><strong>采用多级缓存方案</strong>（事中）。例如：本地缓存（<strong>Ehcache</strong>/<strong>Caffine</strong>/<strong>Guava Cache</strong>） + 分布式缓存（<strong>Redis</strong>/ <strong>Memcached</strong>）。</li><li><strong>限流、降级、熔断方案</strong>（事中），避免被流量打死。如：使用 <strong>Hystrix</strong> 进行熔断、降级。</li><li>缓存如果支持<strong>持久化</strong>，可以在恢复工作后恢复数据（事后）。如：<strong>Redis</strong> 支持持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><p>上面的解决方案简单来说，就是多级缓存方案。系统收到一个查询请求，先查本地缓存，再查分布式缓存，最后查数据库，只要命中，立即返回。</p><p>解决缓存雪崩的辅助手段如下：</p><ul><li><strong>监控缓存，弹性扩容</strong>。</li><li><strong>缓存的过期时间可以取个随机值</strong>。这么做是为避免缓存同时失效，使得数据库 IO 骤升。比如：以前是设置 10 分钟的超时时间，那每个 Key 都可以随机 8-13 分钟过期，尽量让不同 Key 的过期时间不同。</li></ul><h3 id="【中等】什么是缓存穿透-如何应对-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】什么是缓存穿透-如何应对-⭐⭐⭐"><span>【中等】什么是缓存穿透？如何应对？⭐⭐⭐</span></a></h3><p><strong>“缓存穿透”是指，查询的数据在数据库中不存在，那么缓存中自然也不存在。所以，应用在缓存中查不到，则会去查询数据库，当这样的请求多了后，数据库的压力就会增大。</strong></p><p>解决缓存穿透，一般有两种方法：</p><p>（一）缓存空值</p><p><strong>对于返回为 NULL 的依然缓存，对于抛出异常的返回不进行缓存</strong>。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151115258.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>采用这种手段的会增加我们缓存的维护成本，需要在插入缓存的时候删除这个空缓存，当然我们可以通过设置较短的超时时间来解决这个问题。</p><p>（二）过滤不可能存在的数据</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506151115189.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>制定一些规则过滤一些不可能存在的数据</strong>。可以使用布隆过滤器（针对二进制操作的数据结构，所以性能高），比如你的订单 ID 明显是在一个范围 1-1000，如果不是 1-1000 之内的数据那其实可以直接给过滤掉。</p><blockquote><p>针对于一些恶意攻击，攻击带过来的大量 key 是不存在的，那么我们采用第一种方案就会缓存大量不存在 key 的数据。</p><p>此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些 key。</p><p>针对这种 key 异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。</p><p>而对于空数据的 key 有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。</p></blockquote><h3 id="【中等】什么是缓存击穿-如何应对-⭐⭐⭐" tabindex="-1"><a class="header-anchor" href="#【中等】什么是缓存击穿-如何应对-⭐⭐⭐"><span>【中等】什么是缓存击穿？如何应对？⭐⭐⭐</span></a></h3><p><strong>“缓存击穿”是指，热点缓存数据失效瞬间，大量请求直接访问数据库</strong>。例如，某些 key 是热点数据，访问非常频繁。如果某个 key 失效的瞬间，大量的请求过来，缓存未命中，然后去数据库访问，此时数据库访问量会急剧增加。</p><p>为了避免这个问题，我们可以采取下面的两个手段：</p><ul><li><strong>分布式锁</strong> - 锁住热点数据的 key，避免大量线程同时访问同一个 key。</li><li><strong>定时异步刷新</strong> - 可以对部分数据采取失效前自动刷新的策略，而不是到期自动淘汰。淘汰其实也是为了数据的时效性，所以采用自动刷新也可以。</li></ul><h2 id="读写分离" tabindex="-1"><a class="header-anchor" href="#读写分离"><span>读写分离</span></a></h2><h3 id="【简单】什么是读写分离-为什么需要读写分离" tabindex="-1"><a class="header-anchor" href="#【简单】什么是读写分离-为什么需要读写分离"><span>【简单】什么是读写分离？为什么需要读写分离？</span></a></h3><p>读写分离将数据库的读操作和写操作分离到不同的数据库实例。</p><div class="hint-container info"><p class="hint-container-title">读写分离作用</p></div><ul><li><strong>有效减少锁竞争</strong> - 主服务器只负责写，从服务器只负责读，能够有效的避免由数据更新导致的行锁竞争，使得整个系统的查询性能得到极大的改善。</li><li><strong>提高查询吞吐量</strong> - 通过一主多从的配置方式，可以将查询请求均匀的分散到多个数据副本，能够进一步的提升系统的处理能力。</li><li><strong>提升数据库可用性</strong> - 使用多主多从的方式，不但能够提升系统的吞吐量，还能够提升数据库的可用性，可以达到在任何一个数据库宕机，甚至磁盘物理损坏的情况下仍然不影响系统的正常运行。</li></ul><div class="hint-container info"><p class="hint-container-title">读写分离工作原理</p></div><ol><li><strong>写操作</strong>：所有写请求（增删改）<strong>只发送到主库</strong></li><li><strong>数据同步</strong>：主库通过<strong>复制机制</strong>将数据变更同步到从库</li><li><strong>读操作</strong>：读请求<strong>分发到多个从库</strong>（负载均衡）</li><li><strong>延迟处理</strong>：需处理<strong>主从同步延迟</strong>带来的数据不一致问题</li></ol><h3 id="【中等】如何实现读写分离" tabindex="-1"><a class="header-anchor" href="#【中等】如何实现读写分离"><span>【中等】如何实现读写分离？</span></a></h3><p><strong>读写分离的基本原理是：主服务器用来处理写操作以及实时性要求比较高的读操作，而从服务器用来处理读操作</strong>。</p><p>读写分离的实现是<strong>根据 SQL 语义分析，将读操作和写操作分别路由至主库与从库</strong>。</p><p>读写分离有两种实现方式：代码封装、中间件。以下是两种方案的对比：</p><table><thead><tr><th style="text-align:left;"><strong>方案</strong></th><th style="text-align:left;"><strong>实现方式</strong></th><th style="text-align:left;"><strong>优点</strong></th><th style="text-align:left;"><strong>缺点</strong></th></tr></thead><tbody><tr><td style="text-align:left;"><strong>代码封装</strong></td><td style="text-align:left;">业务层通过代理类路由读写请求（读走从库，写走主库）。</td><td style="text-align:left;">简单灵活，可定制化 - 适合业务特定需求</td><td style="text-align:left;">主从切换需修改配置并重启 - 多语言需重复开发</td></tr><tr><td style="text-align:left;"><strong>中间件</strong></td><td style="text-align:left;">独立代理服务（如 MySQL-Proxy、ShardingSphere），客户端无感知。</td><td style="text-align:left;">屏蔽多语言差异，统一管理数据源</td><td style="text-align:left;">有额外维护成本，可能成为性能瓶颈</td></tr></tbody></table><blockquote><p>结论：<strong>代码封装</strong>适合简单架构，但扩展性差；<strong>中间件</strong>适合复杂架构，但需维护。</p></blockquote><p><strong>常见的读写分离中间件</strong></p><ul><li><strong>MySQL-Proxy</strong>（官方）</li><li><strong>Atlas</strong>（360）</li><li><strong>ShardingSphere</strong>（Apache）</li><li><strong>Mycat</strong></li></ul><h2 id="分库分表" tabindex="-1"><a class="header-anchor" href="#分库分表"><span>分库分表</span></a></h2><h3 id="【简单】什么是分库分表-为什么需要分库分表" tabindex="-1"><a class="header-anchor" href="#【简单】什么是分库分表-为什么需要分库分表"><span>【简单】什么是分库分表？为什么需要分库分表？</span></a></h3><div class="hint-container info"><p class="hint-container-title">什么是分库分表？</p></div><p><strong>分库分表</strong>是一种数据库水平拆分方案，用于解决单机数据库的<strong>存储瓶颈</strong>和<strong>性能瓶颈</strong>问题。</p><ul><li><strong>分库</strong>：将数据分散到不同的数据库实例（如 <code>DB1</code>、<code>DB2</code>）。</li><li><strong>分表</strong>：将数据分散到同一数据库的不同表（如 <code>order_1</code>、<code>order_2</code>）。</li></ul><div class="hint-container info"><p class="hint-container-title">为何要分库分表？</p></div><p>分库分表主要基于以下理由：</p><ul><li><strong>并发连接</strong> - 一个健康的单库最好保持在每秒 1000 个并发左右，不要太大。</li><li><strong>磁盘容量</strong> - 磁盘容量占满，会导致服务器不可用。</li><li><strong>SQL 性能</strong> - 单表数据量过大，会导致 SQL 执行效率低下。一般，单表超过 1000 万条数据，就可以考虑分表了。</li></ul><table><thead><tr><th>#</th><th>分库分表前</th><th>分库分表后</th></tr></thead><tbody><tr><td>并发支撑情况</td><td>MySQL 单机部署，扛不住高并发</td><td>MySQL 从单机到多机，能承受的并发增加了多倍</td></tr><tr><td>磁盘使用情况</td><td>MySQL 单机磁盘容量几乎撑满</td><td>拆分为多个库，数据库服务器磁盘使用率大大降低</td></tr><tr><td>SQL 执行性能</td><td>单表数据量太大，SQL 越跑越慢</td><td>单表数据量减少，SQL 执行效率明显提升</td></tr></tbody></table><h3 id="【困难】如何实现分库分表-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【困难】如何实现分库分表-⭐⭐"><span>【困难】如何实现分库分表？⭐⭐</span></a></h3><p><strong>分库分表 = 选好拆分键 + 用对路由算法 + 平滑数据迁移 + 改造查询语句，核心是让数据均匀分布且查询能精准定位到分片。</strong></p><p><strong>数值范围路由</strong></p><p>数值范围路由，就是根据 ID、时间范围 这类具有排序性的字段来进行划分。例如：用户 Id 为 1-9999 的记录分到第一个库，10000-20000 的分到第二个库，以此类推。</p><p>按这种策略划分出来的数据，具有数据连续性。</p><p>优点：数据迁移很简单。</p><p>缺点：容易产生热点问题，大量的流量都打在最新的数据上了。</p><p><strong>Hash 路由</strong></p><p>典型的 Hash 路由，如根据数值取模，当需要扩容时，一般以 2 的幂次方进行扩容（这样，扩容时迁移的数据量会小一些）。例如：用户 Id mod n，余数为 0 的记录放到第一个库，余数为 1 的放到第二个库，以此类推。</p><p>一般采用 <strong>预分区</strong> 的方式，提前根据 <strong>数据量</strong> 规划好 <strong>分区数</strong>，比如划分为 <code>512</code> 或 <code>1024</code> 张表，保证可支撑未来一段时间的 <strong>数据容量</strong>，再根据 <strong>负载情况</strong> 将 <strong>表</strong> 迁移到其他 <strong>数据库</strong> 中。扩容时通常采用 <strong>翻倍扩容</strong>，避免 <strong>数据映射</strong> 全部被 <strong>打乱</strong>，导致 <strong>全量迁移</strong> 的情况。</p><p>优点：数据离散分布，不存在热点问题。</p><p>缺点：数据迁移、扩容麻烦（之前的数据需要重新计算 hash 值重新分配到不同的库或表）。当 <strong>节点数量</strong> 变化时，如 <strong>扩容</strong> 或 <strong>收缩</strong> 节点，数据节点 <strong>映射关系</strong> 需要重新计算，会导致数据的 <strong>重新迁移</strong>。</p><p><strong>路由表</strong></p><p>这种策略，就是用一张独立的表记录路由信息。</p><p>优点：简单、灵活，尤其是在扩容、迁移时，只需要迁移指定的数据，然后修改路由表即可。</p><p>缺点：每次查询，必须先查路由表，增加了 IO 开销。并且，如果路由表本身太大，也会面临性能瓶颈，如果想对路由表再做分库分表，将出现死循环式的路由算法选择问题。</p><h3 id="【困难】分库分表存在哪些问题-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【困难】分库分表存在哪些问题-⭐⭐"><span>【困难】分库分表存在哪些问题？⭐⭐</span></a></h3><p>分库分表主要存在以下问题：</p><ul><li><strong>分布式 ID 问题</strong></li><li><strong>分布式事务问题</strong></li><li><strong>跨节点 Join 和聚合</strong></li><li><strong>跨节点的排序分页</strong></li></ul><div class="hint-container info"><p class="hint-container-title">分布式 ID 问题</p></div><p>一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的 ID 无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得 ID，以便进行 SQL 路由。</p><blockquote><p>分布式 ID 的解决方案详见：<a href="https://dunwu.github.io/waterdrop/pages/1050baf5/" target="_blank" rel="noopener noreferrer">分布式 ID</a></p></blockquote><div class="hint-container info"><p class="hint-container-title">分布式事务问题</p></div><p>跨库事务也是分布式的数据库集群要面对的棘手事情。 合理采用分表，可以在降低单表数据量的情况下，尽量使用本地事务，善于使用同库不同表可有效避免分布式事务带来的麻烦。在不能避免跨库事务的场景，有些业务仍然需要保持事务的一致性。 而基于 XA 的分布式事务由于在并发度高的场景中性能无法满足需要，并未被互联网巨头大规模使用，他们大多采用最终一致性的柔性事务代替强一致事务。</p><blockquote><p>分布式事务的解决方案详见：<a href="https://dunwu.github.io/waterdrop/pages/36844fb1/" target="_blank" rel="noopener noreferrer">分布式事务</a></p></blockquote><div class="hint-container info"><p class="hint-container-title">跨节点 Join 和聚合</p></div><p>分库分表后，无法直接跨节点 <code>join</code> 、<code>count</code>、<code>order by</code>、<code>group by</code> 以及聚合。</p><p>针对这类问题，普遍做法是<strong>二次查询</strong>。</p><ul><li><p>在第一次查询时，获取各个节点上的结果。</p></li><li><p>在程序中将这些结果进行合并、筛选。</p></li></ul><div class="hint-container info"><p class="hint-container-title">跨节点的排序分页</p></div><p>一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506050815256.webp" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>上面图中所描述的只是最简单的一种情况（取第一页数据），看起来对性能的影响并不大。但是，如果想取出第 10 页数据，情况又将变得复杂很多，如下图所示：</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/202506050816625.webp" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>有些读者可能并不太理解，为什么不能像获取第一页数据那样简单处理（排序取出前 10 条再合并、排序）。其实并不难理解，因为各分片节点中的数据可能是随机的，为了排序的准确性，必须把所有分片节点的前 N 页数据都排序好后做合并，最后再进行整体的排序。很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差。</p><p>那如何解决分库情况下的分页问题呢？有以下几种办法：</p><ul><li><p>如果是在前台应用提供分页，则限定用户只能看前面 n 页，这个限制在业务上也是合理的，一般看后面的分页意义不大（如果一定要看，可以要求用户缩小范围重新查询）。</p></li><li><p>如果是后台批处理任务要求分批获取数据，则可以加大 page size，比如每次获取 5000 条记录，有效减少分页数（当然离线访问一般走备库，避免冲击主库）。</p></li><li><p>分库设计时，一般还有配套大数据平台汇总所有分库的记录，有些分页查询可以考虑走大数据平台。</p></li></ul><h3 id="【困难】如何实现迁库和扩容-⭐⭐" tabindex="-1"><a class="header-anchor" href="#【困难】如何实现迁库和扩容-⭐⭐"><span>【困难】如何实现迁库和扩容？⭐⭐</span></a></h3><div class="hint-container info"><p class="hint-container-title">停机迁移/扩容（不推荐）</p></div><p>停机迁移/扩容是最暴力、最简单的迁移、扩容方案。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601114836.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>停机迁移/扩容流程</strong>：</p><ol><li>预估停服时间，发布停服公告；停服，不允许数据访问。</li><li>编写临时的数据导入程序，从老数据库中读取数据。</li><li>将数据写入中间件。</li><li>中间件根据分片规则，将数据分发到分库（分表）中。</li><li>应用程序修改配置，重启。</li></ol><p><strong>停机迁移/扩容方案分析</strong>：</p><ul><li><strong>优点</strong>：简单、无数据一致性问题。</li><li><strong>缺点</strong>： <ul><li>停服时间长（数据量大时可能需数小时）。</li><li>风险高，失败后难以回滚。</li></ul></li></ul><p><strong>结论</strong>：代价过高，不推荐使用。</p><div class="hint-container info"><p class="hint-container-title">双写迁移</p></div><p><strong>双写迁移方案核心思想</strong>：</p><ul><li>新旧库同时写入，通过开关控制读写状态（只写旧库、只写新库、双写）。</li><li>逐步切换读请求到新库，确保数据一致性。</li></ul><p><strong>双写迁移方案关键步骤</strong>：</p><ol><li><strong>双写阶段</strong>：先写旧库，再写新库，以旧库结果为准。记录旧库成功但新库失败的日志，用于补偿。</li><li><strong>数据校验</strong>：运行对比程序，检查新旧库数据差异并修复。</li><li><strong>灰度切换读请求</strong>：逐步将读流量切至新库，观察稳定性。</li><li><strong>最终切换</strong>：读写全部切至新库，清理旧库冗余数据。</li></ol><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601135751.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>双写迁移流程</strong>：</p><ol><li>修改应用程序配置，将数据同时写入老数据库和中间件。这就是所谓的<strong>双写</strong>，同时写俩库，老库和新库。</li><li>编写临时程序，读取老数据库。</li><li>将数据写入中间件。如果数据不存在，直接写入；如果数据存在，比较时间戳，只允许新数据覆盖老数据。</li><li>导入数据后，有可能数据还是存在不一致，那么就对数据进行校验，比对新老库的每条数据。如果存在差异，针对差异数据，执行（3）。循环（3）、（4）步骤，直至数据完全一致。</li><li>修改应用程序配置，将数据只写入中间件。</li><li>中间件根据分片规则，将数据分发到分库（分表）中。</li></ol><p><strong>双写迁移方案分析</strong>：</p><p><strong>优点</strong>：</p><ul><li>无需停服，业务影响小。</li><li>可灰度验证，风险可控。</li></ul><p><strong>缺点</strong>：</p><ul><li>实现复杂，需处理双写一致性和补偿逻辑。</li></ul><div class="hint-container info"><p class="hint-container-title">主从替换</p></div><p>生产环境的数据库，为了保证高可用，一般会采用主从架构。主库支持读写操作，从库支持读操作。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601121215.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>由于主从节点数据一致，所以将从库升级为主节点，并修改分片配置，将从节点作为分库之一，就实现了扩容。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601121400.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>主从替换方案流程</strong>：</p><ol><li>解除主从关系，从库升级为主库。</li><li>应用程序，修改配置，读写通过中间件。</li><li>分库分表中间，修改分片配置。将数据按照新的规则分发。</li><li>编写临时程序，清理冗余数据。比如：原来是一个单库，数据量为 400 万。从节点升级为分库之一后，每个分库都有 400 万数据，其中 200 万是冗余数据。清理完后，进行数据校验。</li><li>为每个分库添加新的从库，保证高可用。</li></ol><p><strong>主从替换方案分析</strong>：</p><ul><li><strong>无需停机</strong>，无需全量数据迁移。</li><li>利用现有从库资源，节省成本。</li></ul><div class="hint-container info"><p class="hint-container-title">三种方案对比</p></div><table><thead><tr><th style="text-align:left;"><strong>方案</strong></th><th style="text-align:left;"><strong>适用场景</strong></th><th style="text-align:left;"><strong>优点</strong></th><th style="text-align:left;"><strong>缺点</strong></th></tr></thead><tbody><tr><td style="text-align:left;"><strong>停机迁移</strong></td><td style="text-align:left;">小规模数据，容忍停服</td><td style="text-align:left;">简单，无一致性问题</td><td style="text-align:left;">停服时间长，风险高</td></tr><tr><td style="text-align:left;"><strong>双写迁移</strong></td><td style="text-align:left;">大规模数据，要求高可用</td><td style="text-align:left;">无停服，灰度可控</td><td style="text-align:left;">复杂，需补偿机制</td></tr><tr><td style="text-align:left;"><strong>主从替换</strong></td><td style="text-align:left;">已有主从架构</td><td style="text-align:left;">无需迁移数据，快速扩容</td><td style="text-align:left;">依赖现有从库，清理冗余复杂</td></tr></tbody></table><p><strong>推荐选择</strong>：</p><ul><li><strong>优先双写迁移</strong>：适合大多数业务，平衡风险与复杂度。</li><li><strong>主从升级</strong>：适合已有主从且数据量适中的场景。</li><li><strong>避免停机迁移</strong>：除非数据量极小且可接受停服。</li></ul>',217)])])}const p=n(s,[["render",o]]),c=JSON.parse('{"path":"/pages/ed2c687e/","title":"分布式存储面试","lang":"zh-CN","frontmatter":{"title":"分布式存储面试","date":"2025-01-07T08:01:21.000Z","categories":["分布式","分布式存储"],"tags":["分布式","分布式存储","面试"],"permalink":"/pages/ed2c687e/","description":"分布式存储面试 缓存 扩展 《大型网站技术架构：核心原理与案例分析》 你应该知道的缓存进化史 如何优雅的设计和使用缓存？ 理解分布式系统中的缓存架构（上） 缓存那些事 分布式之数据库和缓存双写一致性方案解析 Cache 的基本原理 5 分钟看懂系列：HTTP 缓存机制详解 浏览器缓存看这一篇就够了 【简单】什么是缓存？为什么需要缓存？ 缓存就是数据交换...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"分布式存储面试\\",\\"image\\":[\\"https://raw.githubusercontent.com/dunwu/images/master/202506151116093.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/1559138689425.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/cs/web/nginx/reverse-proxy.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202601172038278.webp\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506151119858.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/20220413113825.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/20220413113940.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/20220413115140.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506151120459.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506151118006.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506151119761.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506151115258.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506151115189.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506050815256.webp\\",\\"https://raw.githubusercontent.com/dunwu/images/master/202506050816625.webp\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/20200601114836.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/20200601135751.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/20200601121215.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/snap/20200601121400.png\\"],\\"datePublished\\":\\"2025-01-07T08:01:21.000Z\\",\\"dateModified\\":\\"2026-01-21T23:57:06.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"钝悟\\",\\"url\\":\\"https://dunwu.github.io/waterdrop\\"}]}"],["meta",{"property":"og:url","content":"https://dunwu.github.io/waterdrop/waterdrop/pages/ed2c687e/"}],["meta",{"property":"og:site_name","content":"钝悟"}],["meta",{"property":"og:title","content":"分布式存储面试"}],["meta",{"property":"og:description","content":"分布式存储面试 缓存 扩展 《大型网站技术架构：核心原理与案例分析》 你应该知道的缓存进化史 如何优雅的设计和使用缓存？ 理解分布式系统中的缓存架构（上） 缓存那些事 分布式之数据库和缓存双写一致性方案解析 Cache 的基本原理 5 分钟看懂系列：HTTP 缓存机制详解 浏览器缓存看这一篇就够了 【简单】什么是缓存？为什么需要缓存？ 缓存就是数据交换..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dunwu/images/master/202506151116093.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-21T23:57:06.000Z"}],["meta",{"property":"article:tag","content":"面试"}],["meta",{"property":"article:tag","content":"分布式存储"}],["meta",{"property":"article:tag","content":"分布式"}],["meta",{"property":"article:published_time","content":"2025-01-07T08:01:21.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-21T23:57:06.000Z"}]]},"git":{"createdTime":1736208081000,"updatedTime":1769039826000,"contributors":[{"name":"dunwu","username":"dunwu","email":"forbreak@163.com","commits":6,"url":"https://github.com/dunwu"}]},"readingTime":{"minutes":28.93,"words":8679},"filePathRelative":"15.分布式/分布式存储/分布式存储面试.md","excerpt":"\\n<h2>缓存</h2>\\n<div class=\\"hint-container tip\\">\\n<p class=\\"hint-container-title\\">扩展</p>\\n<ul>\\n<li><a href=\\"https://item.jd.com/11322972.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">《大型网站技术架构：核心原理与案例分析》</a></li>\\n<li><a href=\\"https://link.juejin.im/?target=https%3A%2F%2Fjuejin.im%2Fpost%2F5b7593496fb9a009b62904fa\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">你应该知道的缓存进化史</a></li>\\n<li><a href=\\"https://link.juejin.im/?target=https%3A%2F%2Fjuejin.im%2Fpost%2F5b849878e51d4538c77a974a\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">如何优雅的设计和使用缓存？</a></li>\\n<li><a href=\\"https://www.jianshu.com/p/73ce0ef820f9\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">理解分布式系统中的缓存架构（上）</a></li>\\n<li><a href=\\"https://tech.meituan.com/2017/03/17/cache-about.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">缓存那些事</a></li>\\n<li><a href=\\"https://www.cnblogs.com/rjzheng/p/9041659.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">分布式之数据库和缓存双写一致性方案解析 </a></li>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/102293437\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Cache 的基本原理</a></li>\\n<li><a href=\\"https://segmentfault.com/a/1190000021716418\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">5 分钟看懂系列：HTTP 缓存机制详解</a></li>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/60950750\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">浏览器缓存看这一篇就够了</a></li>\\n</ul>\\n</div>","autoDesc":true}');export{p as comp,c as data};
