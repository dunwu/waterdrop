import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as d,o as n,c,a as e,b as o,d as t,e as r}from"./app-0e67a029.js";const p={},i=r('<h1 id="mapreduce" tabindex="-1"><a class="header-anchor" href="#mapreduce" aria-hidden="true">#</a> MapReduce</h1><h2 id="mapreduce-简介" tabindex="-1"><a class="header-anchor" href="#mapreduce-简介" aria-hidden="true">#</a> MapReduce 简介</h2><p>MapReduce 是 Hadoop 项目中的分布式计算框架。它降低了分布式计算的门槛，可以让用户轻松编写程序，让其以可靠、容错的方式运行在大型集群上并行处理海量数据（TB 级）。</p><p>MapReduce 的设计思路是：</p><ul><li>分而治之，并行计算</li><li>移动计算，而非移动数据</li></ul><p>MapReduce 作业通过将输入的数据集拆分为独立的块，这些块由 <code>map</code> 任务以并行的方式处理。框架对 <code>map</code> 的输出进行排序，然后将其输入到 <code>reduce</code> 任务中。作业的输入和输出都存储在文件系统中。该框架负责调度任务、监控任务并重新执行失败的任务。</p><p>通常，计算节点和存储节点是相同的，即 MapReduce 框架和 HDFS 在同一组节点上运行。此配置允许框架在已存在数据的节点上有效地调度任务，从而在整个集群中实现非常高的聚合带宽。</p><p>MapReduce 框架由一个主 <code>ResourceManager</code>、每个集群节点一个工作程序 <code>NodeManager</code> 和每个应用程序的 <code>MRAppMaster</code> （YARN 组件） 组成。</p>',8),u=e("code",null,"<key、value>",-1),s=e("code",null,"<key、value>",-1),h=e("code",null,"<key、value>",-1),_=e("code",null,"键",-1),g=e("code",null,"值",-1),m={href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/Writable.html",target:"_blank",rel:"noopener noreferrer"},f={href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/WritableComparable.html",target:"_blank",rel:"noopener noreferrer"},b=r(`<p>MapReduce 作业的 Input 和 Output 类型：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>MapReduce 的特点</p><ul><li>计算跟着数据走</li><li>良好的扩展性：计算能力随着节点数增加，近似线性递增</li><li>高容错</li><li>状态监控</li><li>适合海量数据的离线批处理</li><li>降低了分布式编程的门槛</li></ul><h2 id="mapreduce-应用场景" tabindex="-1"><a class="header-anchor" href="#mapreduce-应用场景" aria-hidden="true">#</a> MapReduce 应用场景</h2><p>适用场景：</p><ul><li>数据统计，如：网站的 PV、UV 统计</li><li>搜索引擎构建索引</li><li>海量数据查询</li></ul><p>不适用场景：</p><ul><li>OLAP - 要求毫秒或秒级返回结果</li><li>流计算 - 流计算的输入数据集是动态的，而 MapReduce 是静态的</li><li>DAG 计算 <ul><li>多个作业存在依赖关系，后一个的输入是前一个的输出，构成有向无环图 DAG</li><li>每个 MapReduce 作业的输出结果都会落盘，造成大量磁盘 IO，导致性能非常低下</li></ul></li></ul><h2 id="mapreduce-工作流" tabindex="-1"><a class="header-anchor" href="#mapreduce-工作流" aria-hidden="true">#</a> MapReduce 工作流</h2><p>MapReduce 编程模型：MapReduce 程序被分为 Map（映射）阶段和 Reduce（化简）阶段。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200601162305.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><ol><li><strong>input</strong> : 读取文本文件；</li><li><strong>splitting</strong> : 将文件按照行进行拆分，此时得到的 <code>K1</code> 行数，<code>V1</code> 表示对应行的文本内容；</li><li><strong>mapping</strong> : 并行将每一行按照空格进行拆分，拆分得到的 <code>List(K2,V2)</code>，其中 <code>K2</code> 代表每一个单词，由于是做词频统计，所以 <code>V2</code> 的值为 1，代表出现 1 次；</li><li><strong>shuffling</strong>：由于 <code>Mapping</code> 操作可能是在不同的机器上并行处理的，所以需要通过 <code>shuffling</code> 将相同 <code>key</code> 值的数据分发到同一个节点上去合并，这样才能统计出最终的结果，此时得到 <code>K2</code> 为每一个单词，<code>List(V2)</code> 为可迭代集合，<code>V2</code> 就是 Mapping 中的 V2；</li><li><strong>Reducing</strong> : 这里的案例是统计单词出现的总次数，所以 <code>Reducing</code> 对 <code>List(V2)</code> 进行归约求和操作，最终输出。</li></ol><p>MapReduce 编程模型中 <code>splitting</code> 和 <code>shuffing</code> 操作都是由框架实现的，需要我们自己编程实现的只有 <code>mapping</code> 和 <code>reducing</code>，这也就是 MapReduce 这个称呼的来源。</p><h2 id="mapreduce-组件" tabindex="-1"><a class="header-anchor" href="#mapreduce-组件" aria-hidden="true">#</a> MapReduce 组件</h2><p>MapReduce 有以下核心组件：</p>`,16),R=e("strong",null,"Job",-1),M={href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Job.html",target:"_blank",rel:"noopener noreferrer"},k=e("code",null,"Job",-1),x=e("code",null,"Mapper",-1),v=e("code",null,"Partitioner",-1),I=e("code",null,"Reducer",-1),V=e("code",null,"InputFormat",-1),y=e("code",null,"OutputFormat",-1),F=e("strong",null,"Mapper",-1),O={href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Mapper.html",target:"_blank",rel:"noopener noreferrer"},N=e("strong",null,"映射",-1),P=e("li",null,[e("strong",null,"Combiner"),o(" - "),e("code",null,"combiner"),o(" 是 "),e("code",null,"map"),o(" 运算后的可选操作，它实际上是一个本地化的 "),e("code",null,"reduce"),o(" 操作。它执行中间输出的本地聚合，这有助于减少从 "),e("code",null,"Mapper"),o(" 传输到 "),e("code",null,"Reducer"),o(" 的数据量。")],-1),W=e("strong",null,"Reducer",-1),L={href:"http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Reducer.html",target:"_blank",rel:"noopener noreferrer"},S=e("ul",null,[e("li",null,[e("strong",null,"shuffle"),o(" - Reducer 的输入就是 mapper 的排序输出。在这个阶段，框架通过 HTTP 获取所有 mapper 输出的相关分区。")]),e("li",null,[e("strong",null,"sort"),o(" - 在这个阶段中，框架将按照 key （因为不同 mapper 的输出中可能会有相同的 key) 对 Reducer 的输入进行分组。shuffle 和 sort 两个阶段是同时发生的。")]),e("li",null,[e("strong",null,"reduce"),o(" - 对按键分组的数据进行聚合统计。")])],-1),A=e("strong",null,"Partitioner",-1),B={href:"http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Partitioner.html",target:"_blank",rel:"noopener noreferrer"},T=e("ul",null,[e("li",null,"键（或者键的子集）用于产生分区，通常通过一个散列函数。"),e("li",null,"分区总数与作业的 reduce 任务数是一样的。因此，它控制中间输出结果（也就是这条记录）的键发送给 m 个 reduce 任务中的哪一个来进行 reduce 操作。")],-1),w=e("strong",null,"InputFormat",-1),C={href:"http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputFormat.html",target:"_blank",rel:"noopener noreferrer"},D=e("li",null,"确认作业的输入规范。",-1),H={href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/InputSplit.html",target:"_blank",rel:"noopener noreferrer"},J=e("code",null,"Mapper",-1),K={href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/RecordReader.html",target:"_blank",rel:"noopener noreferrer"},E=e("code",null,"InputSplit",-1),z=e("code",null,"<key， value>",-1),G=e("code",null,"Mapper",-1),U=e("strong",null,"OutputFormat",-1),Y={href:"http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/OutputFormat.html",target:"_blank",rel:"noopener noreferrer"},j=e("li",null,"确认作业的输出规范，例如检查输出路径是否已经存在。",-1),q={href:"https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/RecordWriter.html",target:"_blank",rel:"noopener noreferrer"},Q=e("code",null,"<key， value>",-1),X=e("figure",null,[e("img",{src:"https://raw.githubusercontent.com/dunwu/images/master/snap/20200601163846.png",alt:"img",tabindex:"0",loading:"lazy"}),e("figcaption",null,"img")],-1),Z=e("h2",{id:"参考资料",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#参考资料","aria-hidden":"true"},"#"),o(" 参考资料")],-1),$={href:"https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-MapReduce.md",target:"_blank",rel:"noopener noreferrer"},ee={href:"https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html",target:"_blank",rel:"noopener noreferrer"};function oe(ae,te){const a=d("ExternalLinkIcon");return n(),c("div",null,[i,e("p",null,[o("MapReduce 框架仅对 "),u,o(" 对进行作，也就是说，框架将作业的输入视为一组 "),s,o(" 对，并生成一组 "),h,o(" 对作为作业的输出，可以想象是不同的类型。"),_,o("和"),g,o("类必须可由框架序列化，因此需要实现 "),e("a",m,[o("Writable"),t(a)]),o(" 接口。此外，关键类必须实现 "),e("a",f,[o("WritableComparable"),t(a)]),o(" 接口，以便于按框架进行排序。")]),b,e("ul",null,[e("li",null,[R,o(" - "),e("a",M,[o("Job"),t(a)]),o(" 表示 MapReduce 作业配置。"),k,o(" 通常用于指定 "),x,o("、combiner（如果有）、"),v,o("、"),I,o("、"),V,o("、"),y,o(" 实现。")]),e("li",null,[F,o(" - "),e("a",O,[o("Mapper"),t(a)]),o(" 负责将输入键值对"),N,o("到一组中间键值对。转换的中间记录不需要与输入记录具有相同的类型。一个给定的输入键值对可能映射到零个或多个输出键值对。")]),P,e("li",null,[W,o(" - "),e("a",L,[o("Reducer"),t(a)]),o(" 将共享一个 key 的一组中间值归并为一个小的数值集。Reducer 有 3 个主要子阶段：shuffle，sort 和 reduce。 "),S]),e("li",null,[A,o(" - "),e("a",B,[o("Partitioner"),t(a)]),o(" 负责控制 map 中间输出结果的键的分区。 "),T]),e("li",null,[w,o(" - "),e("a",C,[o("InputFormat"),t(a)]),o(" 描述 MapReduce 作业的输入规范。MapReduce 框架依赖作业的 InputFormat 来完成以下工作： "),e("ul",null,[D,e("li",null,[o("把输入文件分割成多个逻辑的 InputSplit 实例，然后将每个实例分配给一个单独的 Mapper。"),e("a",H,[o("InputSplit"),t(a)]),o(" 表示要由单个 "),J,o(" 处理的数据。")]),e("li",null,[o("提供 RecordReader 的实现。"),e("a",K,[o("RecordReader"),t(a)]),o(" 从 "),E,o(" 中读取 "),z,o(" 对，并提供给 "),G,o(" 实现进行处理。")])])]),e("li",null,[U,o(" - "),e("a",Y,[o("OutputFormat"),t(a)]),o(" 描述 MapReduce 作业的输出规范。MapReduce 框架依赖作业的 OutputFormat 来完成以下工作： "),e("ul",null,[j,e("li",null,[o("提供 RecordWriter 实现。"),e("a",q,[o("RecordWriter"),t(a)]),o(" 将输出 "),Q,o(" 对到文件系统。")])])])]),X,Z,e("ul",null,[e("li",null,[e("a",$,[o("分布式计算框架——MapReduce"),t(a)])]),e("li",null,[e("a",ee,[o("MapReduce 官方文档"),t(a)])])])])}const de=l(p,[["render",oe],["__file","index.html.vue"]]);export{de as default};
