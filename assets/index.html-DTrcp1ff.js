import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a as r,o as t}from"./app-D9ZsBuuN.js";const p={};function c(d,e){return t(),o("div",null,[...e[0]||(e[0]=[r('<h1 id="mapreduce" tabindex="-1"><a class="header-anchor" href="#mapreduce"><span>MapReduce</span></a></h1><h2 id="mapreduce-简介" tabindex="-1"><a class="header-anchor" href="#mapreduce-简介"><span>MapReduce 简介</span></a></h2><p>MapReduce 是 Hadoop 项目中的分布式计算框架。它降低了分布式计算的门槛，可以让用户轻松编写程序，让其以可靠、容错的方式运行在大型集群上并行处理海量数据（TB 级）。</p><p>MapReduce 的设计思路是：</p><ul><li>分而治之，并行计算</li><li>移动计算，而非移动数据</li></ul><p>MapReduce 作业通过将输入的数据集拆分为独立的块，这些块由 <code>map</code> 任务以并行的方式处理。框架对 <code>map</code> 的输出进行排序，然后将其输入到 <code>reduce</code> 任务中。作业的输入和输出都存储在文件系统中。该框架负责调度任务、监控任务并重新执行失败的任务。</p><p>通常，计算节点和存储节点是相同的，即 MapReduce 框架和 HDFS 在同一组节点上运行。此配置允许框架在已存在数据的节点上有效地调度任务，从而在整个集群中实现非常高的聚合带宽。</p><p>MapReduce 框架由一个主 <code>ResourceManager</code>、每个集群节点一个工作程序 <code>NodeManager</code> 和每个应用程序的 <code>MRAppMaster</code> （YARN 组件） 组成。</p><p>MapReduce 框架仅对 <code>&lt;key、value&gt;</code> 对进行作，也就是说，框架将作业的输入视为一组 <code>&lt;key、value&gt;</code> 对，并生成一组 <code>&lt;key、value&gt;</code> 对作为作业的输出，可以想象是不同的类型。<code>键</code>和<code>值</code>类必须可由框架序列化，因此需要实现 <a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/Writable.html" target="_blank" rel="noopener noreferrer">Writable</a> 接口。此外，关键类必须实现 <a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/io/WritableComparable.html" target="_blank" rel="noopener noreferrer">WritableComparable</a> 接口，以便于按框架进行排序。</p><p>MapReduce 作业的 Input 和 Output 类型：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-"><span class="line"><span>(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>MapReduce 的特点</p><ul><li>计算跟着数据走</li><li>良好的扩展性：计算能力随着节点数增加，近似线性递增</li><li>高容错</li><li>状态监控</li><li>适合海量数据的离线批处理</li><li>降低了分布式编程的门槛</li></ul><h2 id="mapreduce-应用场景" tabindex="-1"><a class="header-anchor" href="#mapreduce-应用场景"><span>MapReduce 应用场景</span></a></h2><p>适用场景：</p><ul><li>数据统计，如：网站的 PV、UV 统计</li><li>搜索引擎构建索引</li><li>海量数据查询</li></ul><p>不适用场景：</p><ul><li>OLAP - 要求毫秒或秒级返回结果</li><li>流计算 - 流计算的输入数据集是动态的，而 MapReduce 是静态的</li><li>DAG 计算 <ul><li>多个作业存在依赖关系，后一个的输入是前一个的输出，构成有向无环图 DAG</li><li>每个 MapReduce 作业的输出结果都会落盘，造成大量磁盘 IO，导致性能非常低下</li></ul></li></ul><h2 id="mapreduce-工作流" tabindex="-1"><a class="header-anchor" href="#mapreduce-工作流"><span>MapReduce 工作流</span></a></h2><p>MapReduce 编程模型：MapReduce 程序被分为 Map（映射）阶段和 Reduce（化简）阶段。</p><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/archive/2020/06/d939d0d6c2784a3497513f7304c6b126.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ol><li><strong>input</strong> : 读取文本文件；</li><li><strong>splitting</strong> : 将文件按照行进行拆分，此时得到的 <code>K1</code> 行数，<code>V1</code> 表示对应行的文本内容；</li><li><strong>mapping</strong> : 并行将每一行按照空格进行拆分，拆分得到的 <code>List(K2,V2)</code>，其中 <code>K2</code> 代表每一个单词，由于是做词频统计，所以 <code>V2</code> 的值为 1，代表出现 1 次；</li><li><strong>shuffling</strong>：由于 <code>Mapping</code> 操作可能是在不同的机器上并行处理的，所以需要通过 <code>shuffling</code> 将相同 <code>key</code> 值的数据分发到同一个节点上去合并，这样才能统计出最终的结果，此时得到 <code>K2</code> 为每一个单词，<code>List(V2)</code> 为可迭代集合，<code>V2</code> 就是 Mapping 中的 V2；</li><li><strong>Reducing</strong> : 这里的案例是统计单词出现的总次数，所以 <code>Reducing</code> 对 <code>List(V2)</code> 进行归约求和操作，最终输出。</li></ol><p>MapReduce 编程模型中 <code>splitting</code> 和 <code>shuffing</code> 操作都是由框架实现的，需要我们自己编程实现的只有 <code>mapping</code> 和 <code>reducing</code>，这也就是 MapReduce 这个称呼的来源。</p><h2 id="mapreduce-组件" tabindex="-1"><a class="header-anchor" href="#mapreduce-组件"><span>MapReduce 组件</span></a></h2><p>MapReduce 有以下核心组件：</p><ul><li><strong>Job</strong> - <a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Job.html" target="_blank" rel="noopener noreferrer">Job</a> 表示 MapReduce 作业配置。<code>Job</code> 通常用于指定 <code>Mapper</code>、combiner（如果有）、<code>Partitioner</code>、<code>Reducer</code>、<code>InputFormat</code>、<code>OutputFormat</code> 实现。</li><li><strong>Mapper</strong> - <a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Mapper.html" target="_blank" rel="noopener noreferrer">Mapper</a> 负责将输入键值对<strong>映射</strong>到一组中间键值对。转换的中间记录不需要与输入记录具有相同的类型。一个给定的输入键值对可能映射到零个或多个输出键值对。</li><li><strong>Combiner</strong> - <code>combiner</code> 是 <code>map</code> 运算后的可选操作，它实际上是一个本地化的 <code>reduce</code> 操作。它执行中间输出的本地聚合，这有助于减少从 <code>Mapper</code> 传输到 <code>Reducer</code> 的数据量。</li><li><strong>Reducer</strong> - <a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Reducer.html" target="_blank" rel="noopener noreferrer">Reducer</a> 将共享一个 key 的一组中间值归并为一个小的数值集。Reducer 有 3 个主要子阶段：shuffle，sort 和 reduce。 <ul><li><strong>shuffle</strong> - Reducer 的输入就是 mapper 的排序输出。在这个阶段，框架通过 HTTP 获取所有 mapper 输出的相关分区。</li><li><strong>sort</strong> - 在这个阶段中，框架将按照 key （因为不同 mapper 的输出中可能会有相同的 key) 对 Reducer 的输入进行分组。shuffle 和 sort 两个阶段是同时发生的。</li><li><strong>reduce</strong> - 对按键分组的数据进行聚合统计。</li></ul></li><li><strong>Partitioner</strong> - <a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Partitioner.html" target="_blank" rel="noopener noreferrer">Partitioner</a> 负责控制 map 中间输出结果的键的分区。 <ul><li>键（或者键的子集）用于产生分区，通常通过一个散列函数。</li><li>分区总数与作业的 reduce 任务数是一样的。因此，它控制中间输出结果（也就是这条记录）的键发送给 m 个 reduce 任务中的哪一个来进行 reduce 操作。</li></ul></li><li><strong>InputFormat</strong> - <a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputFormat.html" target="_blank" rel="noopener noreferrer">InputFormat</a> 描述 MapReduce 作业的输入规范。MapReduce 框架依赖作业的 InputFormat 来完成以下工作： <ul><li>确认作业的输入规范。</li><li>把输入文件分割成多个逻辑的 InputSplit 实例，然后将每个实例分配给一个单独的 Mapper。<a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/InputSplit.html" target="_blank" rel="noopener noreferrer">InputSplit</a> 表示要由单个 <code>Mapper</code> 处理的数据。</li><li>提供 RecordReader 的实现。<a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/RecordReader.html" target="_blank" rel="noopener noreferrer">RecordReader</a> 从 <code>InputSplit</code> 中读取 <code>&lt;key， value&gt;</code> 对，并提供给 <code>Mapper</code> 实现进行处理。</li></ul></li><li><strong>OutputFormat</strong> - <a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/OutputFormat.html" target="_blank" rel="noopener noreferrer">OutputFormat</a> 描述 MapReduce 作业的输出规范。MapReduce 框架依赖作业的 OutputFormat 来完成以下工作： <ul><li>确认作业的输出规范，例如检查输出路径是否已经存在。</li><li>提供 RecordWriter 实现。<a href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/RecordWriter.html" target="_blank" rel="noopener noreferrer">RecordWriter</a> 将输出 <code>&lt;key， value&gt;</code> 对到文件系统。</li></ul></li></ul><figure><img src="https://raw.githubusercontent.com/dunwu/images/master/archive/2020/06/6e4555f1d0074087b51138005cba74d2.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ul><li><a href="https://github.com/heibaiying/BigData-Notes/blob/master/notes/Hadoop-MapReduce.md" target="_blank" rel="noopener noreferrer">分布式计算框架——MapReduce</a></li><li><a href="https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" target="_blank" rel="noopener noreferrer">MapReduce 官方文档</a></li></ul>',29)])])}const l=a(p,[["render",c]]),u=JSON.parse('{"path":"/pages/5383c8e8/","title":"MapReduce","lang":"zh-CN","frontmatter":{"icon":"devicon:hadoop","title":"MapReduce","date":"2020-06-22T00:22:25.000Z","categories":["大数据","Hadoop"],"tags":["大数据","Hadoop","mapreduce"],"permalink":"/pages/5383c8e8/","description":"MapReduce MapReduce 简介 MapReduce 是 Hadoop 项目中的分布式计算框架。它降低了分布式计算的门槛，可以让用户轻松编写程序，让其以可靠、容错的方式运行在大型集群上并行处理海量数据（TB 级）。 MapReduce 的设计思路是： 分而治之，并行计算 移动计算，而非移动数据 MapReduce 作业通过将输入的数据集拆分...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"MapReduce\\",\\"image\\":[\\"https://raw.githubusercontent.com/dunwu/images/master/archive/2020/06/d939d0d6c2784a3497513f7304c6b126.png\\",\\"https://raw.githubusercontent.com/dunwu/images/master/archive/2020/06/6e4555f1d0074087b51138005cba74d2.png\\"],\\"datePublished\\":\\"2020-06-22T00:22:25.000Z\\",\\"dateModified\\":\\"2026-02-11T15:41:54.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"钝悟\\",\\"url\\":\\"https://dunwu.github.io/waterdrop\\"}]}"],["meta",{"property":"og:url","content":"https://dunwu.github.io/waterdrop/waterdrop/pages/5383c8e8/"}],["meta",{"property":"og:site_name","content":"钝悟"}],["meta",{"property":"og:title","content":"MapReduce"}],["meta",{"property":"og:description","content":"MapReduce MapReduce 简介 MapReduce 是 Hadoop 项目中的分布式计算框架。它降低了分布式计算的门槛，可以让用户轻松编写程序，让其以可靠、容错的方式运行在大型集群上并行处理海量数据（TB 级）。 MapReduce 的设计思路是： 分而治之，并行计算 移动计算，而非移动数据 MapReduce 作业通过将输入的数据集拆分..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://raw.githubusercontent.com/dunwu/images/master/archive/2020/06/d939d0d6c2784a3497513f7304c6b126.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-02-11T15:41:54.000Z"}],["meta",{"property":"article:tag","content":"mapreduce"}],["meta",{"property":"article:tag","content":"Hadoop"}],["meta",{"property":"article:tag","content":"大数据"}],["meta",{"property":"article:published_time","content":"2020-06-22T00:22:25.000Z"}],["meta",{"property":"article:modified_time","content":"2026-02-11T15:41:54.000Z"}]]},"git":{"createdTime":1739978163000,"updatedTime":1770824514000,"contributors":[{"name":"dunwu","username":"dunwu","email":"forbreak@163.com","commits":6,"url":"https://github.com/dunwu"}]},"readingTime":{"minutes":5.19,"words":1558},"filePathRelative":"16.大数据/Hadoop/MapReduce.md","excerpt":"\\n<h2>MapReduce 简介</h2>\\n<p>MapReduce 是 Hadoop 项目中的分布式计算框架。它降低了分布式计算的门槛，可以让用户轻松编写程序，让其以可靠、容错的方式运行在大型集群上并行处理海量数据（TB 级）。</p>\\n<p>MapReduce 的设计思路是：</p>\\n<ul>\\n<li>分而治之，并行计算</li>\\n<li>移动计算，而非移动数据</li>\\n</ul>\\n<p>MapReduce 作业通过将输入的数据集拆分为独立的块，这些块由 <code>map</code> 任务以并行的方式处理。框架对 <code>map</code> 的输出进行排序，然后将其输入到 <code>reduce</code> 任务中。作业的输入和输出都存储在文件系统中。该框架负责调度任务、监控任务并重新执行失败的任务。</p>","autoDesc":true}');export{l as comp,u as data};
